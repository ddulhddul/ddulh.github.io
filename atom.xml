<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ddulh&#39;s</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://ddulhddul.github.io/"/>
  <updated>2019-06-06T10:04:52.487Z</updated>
  <id>https://ddulhddul.github.io/</id>
  
  <author>
    <name>ddulh</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>케라스맛 Chapter7] 케라스로 구현하는 GAN (생성적 적대 신경망)</title>
    <link href="https://ddulhddul.github.io/2018/05/04/DeepLearning/ml027/"/>
    <id>https://ddulhddul.github.io/2018/05/04/DeepLearning/ml027/</id>
    <published>2018-05-04T08:00:52.000Z</published>
    <updated>2019-06-06T10:04:52.487Z</updated>
    
    <content type="html"><![CDATA[<ul><li>경쟁하여 최적화를 수행하는 생성형 신경망.</li><li>내부의 두 신경망이 상호 경쟁하면서 학습.<ul><li>하나는 생성망, 하나는 판별망</li></ul></li></ul><h1 id="7-1-GAN의-원리"><a href="#7-1-GAN의-원리" class="headerlink" title="7.1 GAN의 원리"></a>7.1 GAN의 원리</h1><p>경쟁적 학습 방법을 이용하는 생성형 인공지능</p><h2 id="7-1-1-GAN-의-목적과-개념"><a href="#7-1-1-GAN-의-목적과-개념" class="headerlink" title="7.1.1 GAN 의 목적과 개념"></a>7.1.1 GAN 의 목적과 개념</h2><ul><li>실제 데이터와 비슷한 확률분포를 가지는 허구데이터를 생성</li><li><p>실제 데이터로 얼굴 사진을 제공하면, 비슷한 확률분포를 가지는 새로운 허구 사진을 생성</p></li><li><p>레이블이 없는 정보를 다루는 비지도학습</p></li><li>입력데이터는 무작위 잡음. 출력데이터와 상광벗이 때문에 비지도형의 생성형 신경망이다.</li><li>출력데이터를 특정 분포도를 갖는 데이터로 가정. (ex_ 필기체 숫자, 사람얼굴사진)</li><li>잡음은 무한한 변위가 가능하므로, 학습에 사용한 어떤 데이터와도 완전히 같지 않다.</li></ul><h2 id="7-1-2-GAN의-구조"><a href="#7-1-2-GAN의-구조" class="headerlink" title="7.1.2 GAN의 구조"></a>7.1.2 GAN의 구조</h2><ul><li>경쟁적인 방법으로 학습을 수행<ul><li>판별망은 실제 데이터인지 허구데이터인지 더 잘 구분하도록 학습</li><li>생성망은 판별망을 더 잘 속이도록 학습</li><li>두 과정을 계속 순환</li></ul></li><li>목적은 학습한 실제 데이터와 같은 확률 분포를 가지는 새로운 허구 데이터를 만들도록 생성망을 학습시키는 것.</li></ul><p><img src="https://www.naverlabs.com/naverlabs_/story/201712/1513772298204_%EB%8F%84%EC%8B%9D1.jpg" alt="https://www.naverlabs.com/naverlabs_/story/201712/1513772298204_%EB%8F%84%EC%8B%9D1.jpg"><br><code>출처 : https://www.naverlabs.com/storyDetail/44</code></p><h2 id="7-1-3-GAN의-동작-원리"><a href="#7-1-3-GAN의-동작-원리" class="headerlink" title="7.1.3 GAN의 동작 원리"></a>7.1.3 GAN의 동작 원리</h2><ul><li>생성망<ul><li>생성망은 저차원 무작위 잡음을 입력받아 고차원 허구이미지를 생성</li><li>실제 이미지를 학습하여 실제 이미지와 확률 분포가 최대한 비슷하도록 허구 이미지를 만든다.</li><li>생성망이 만든 허구이미지를 판별망이 실제 이미지로 착각하도록 만드는 방향으로 생성망 학습이 이루어진다.</li></ul></li><li>판별망<ul><li>입력된 이미지가 실제인지 허구인지 판별</li><li>문제는 실제 이미지는 변하지 않지만 허구 이미지는 생성망의 학습이 진행됨에 따라 점점 실제 이미지와 유사해진다는 것</li><li>그래서 앞서 만들어진 이미지를 판별할 수 있도록 점진적으로 학습이 진행된다.</li><li>상호 공진화 하는 방식</li></ul></li><li>판별과 생성시 합성곱 계층을 활용하면 완전 연결 계층보다 효율적 처리 가능.</li></ul><h2 id="7-1-4-GAN의-동작-사례"><a href="#7-1-4-GAN의-동작-사례" class="headerlink" title="7.1.4 GAN의 동작 사례"></a>7.1.4 GAN의 동작 사례</h2><p><img src="http://img1.daumcdn.net/thumb/R1920x0/?fname=http%3A%2F%2Fcfile10.uf.tistory.com%2Fimage%2F99ED60435A3BB17430B8B9" alt="http://img1.daumcdn.net/thumb/R1920x0/?fname=http%3A%2F%2Fcfile10.uf.tistory.com%2Fimage%2F99ED60435A3BB17430B8B9"><br><code>출처 : http://artoria.us/7</code></p><ul><li><p>판별망의 동작</p><ul><li>무작위 잡음 벡터 Z를 입력받아 생성망의 결과를 판별</li><li>개별 이미지가 아닌 이미지의 확률분포를 판별</li><li><p>실제 데이터와 생성망이 만든 허구 데이터의 확률 분포 차이를 판별하도록 학습</p></li><li><p>a. 실제 데이터를 1로 판별하는 과정    </p><ul><li>데이터로부터 가져온 샘플<ul><li>일반적인 배치처리.</li></ul></li><li>미분 가능한 판별 함수 D</li><li>1을 출력하려고 노력하는 판별 함수 D<ul><li>정확도가 높은 판별을 위해 신경망으로 구성</li></ul></li></ul></li><li><p>b. 허구 데이터를 0으로 판별하는 과정</p><ul><li>무작위 잡음 벡터 Z (생성)</li><li>미분 가능한 생성 함수 G<ul><li>복잡한 확률분포를 변환하기 위해 생성 함수 G를 신경망으로 구성</li></ul></li><li>모델로부터 가져온 샘플</li><li>미분 가능한 판별 함수 D</li><li>0을 출력하려고 노력하는 판별 함수 D</li></ul></li><li><p>판별값은 실제 데이터를 입력하면 1, 생성데이터를 입력하면 0이어야 한다.</p></li><li>생성망의 가중치는 학습이 되지 않도록 고정.</li><li>판별망에 들어가는 데이터는 실제 데이터에서 추출한 배치데이터와 생성망에서 만든 허구 데이터로 구성된다.</li><li>판별망 학습 이후 생성망이 진화하기 때문에 순환적으로 계속 판별망을 학습시킨다.</li></ul></li><li><p>생성망의 동작</p><ul><li>생성망의 결과가 판별망으로 들어가도록 가상 신경망 모델을 구성</li><li>학습용 생성망은 새로운 신경망이 아니라 기존의 생성망과 판별망이 합쳐진 가상 신경망이다.</li><li>학습용 생성망 부분에서 판별망 부분은 학습되지 않도록 가중치를 고정.</li><li>판별망은 무작위 잡음 벡터 Z로부터 생성된 허구 이미지가 얼마나 실제 이미지와 유사한지 판별한 결과를 내게 된다.</li><li>판별한 결과가 모두 실제가 되도록 생성망을 학습</li></ul></li><li><p>진화된 생성망은 또다시 무작위 입력벡터 Z에 대해 이미지 변환을 수행.</p></li><li>이렇게 판별망과 생성망 학습이 한번씩 실행되면 GAN 전체 학습이 한번 수행된 것.</li><li>최적화가 완전히 끝나면 이론적으로 생성망의 결과와 실제 이미지를 판별망이 구분하지 못하게 된다.</li></ul><h1 id="7-2-확률분포-생성을-위한-완전-연결-계층-GAN-구현"><a href="#7-2-확률분포-생성을-위한-완전-연결-계층-GAN-구현" class="headerlink" title="7.2 확률분포 생성을 위한 완전 연결 계층 GAN 구현"></a>7.2 확률분포 생성을 위한 완전 연결 계층 GAN 구현</h1><ul><li>처음 제안된 논문의 예제를 구현하자.</li><li>생성에 사용하는 무작위 잡음 벡터 Z는 균등분포 확률신호, 출력은 정규분포 확률 신호</li></ul><h2 id="7-2-1-패키지-임포트"><a href="#7-2-1-패키지-임포트" class="headerlink" title="7.2.1 패키지 임포트"></a>7.2.1 패키지 임포트</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Conv1D, Reshape, Flatten, Lambda</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_decorate</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    axis = -1 --&gt; last dimension in an array</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    m = K.mean(x, axis=<span class="number">-1</span>, keepdims=<span class="keyword">True</span>)</span><br><span class="line">    d = K.square(x - m)</span><br><span class="line">    <span class="keyword">return</span> K.concatenate([x, d], axis=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_decorate_shape</span><span class="params">(input_shape)</span>:</span></span><br><span class="line">    shape = list(input_shape)</span><br><span class="line">    <span class="keyword">assert</span> len(shape) == <span class="number">2</span></span><br><span class="line">    shape[<span class="number">1</span>] *= <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> tuple(shape)</span><br><span class="line"></span><br><span class="line"> model.add(Lambda(antirectifier, output_shape=antirectifier_output_shape))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lr = <span class="number">2e-4</span>   <span class="number">0.0002</span></span><br><span class="line">adam = Adam(lr=lr, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_compile</span><span class="params">(model)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=adam, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GAN</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, ni_D, nh_D, nh_G)</span>:</span></span><br><span class="line">        self.ni_D = ni_D</span><br><span class="line">        self.nh_D = nh_D</span><br><span class="line">        self.nh_G = nh_G</span><br><span class="line"></span><br><span class="line">        self.D = self.gen_D()</span><br><span class="line">        self.G = self.gen_G()</span><br><span class="line">        self.GD = self.make_GD()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gen_D</span><span class="params">(self)</span>:</span></span><br><span class="line">        ni_D = self.ni_D</span><br><span class="line">        nh_D = self.nh_D</span><br><span class="line">        D = models.Sequential()</span><br><span class="line">        D.add(Lambda(add_decorate, output_shape=add_decorate_shape, input_shape=(ni_D,)))</span><br><span class="line">        D.add(Dense(nh_D, activation=<span class="string">'relu'</span>))</span><br><span class="line">        D.add(Dense(nh_D, activation=<span class="string">'relu'</span>))</span><br><span class="line">        D.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"></span><br><span class="line">        model_compile(D)</span><br><span class="line">        <span class="keyword">return</span> D</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gen_G</span><span class="params">(self)</span>:</span></span><br><span class="line">        ni_D = self.ni_D</span><br><span class="line">        nh_G = self.nh_D</span><br><span class="line"></span><br><span class="line">        G = models.Sequential()   (Batch, ni_D)</span><br><span class="line">        G.add(Reshape((ni_D, <span class="number">1</span>), input_shape=(ni_D,)))   (Batch, steps=ni_D, input_dim=<span class="number">1</span>)</span><br><span class="line">        G.add(Conv1D(nh_G, <span class="number">1</span>, activation=<span class="string">'relu'</span>))   (Batch, ni_D, nh_G)</span><br><span class="line">        G.add(Conv1D(nh_G, <span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))   (Batch, ni_D, nh_G)</span><br><span class="line">        G.add(Conv1D(<span class="number">1</span>, <span class="number">1</span>))   (Batch, ni_D, <span class="number">1</span>)</span><br><span class="line">        G.add(Flatten())   (Batch, ni_D)</span><br><span class="line"></span><br><span class="line">        model_compile(G)</span><br><span class="line">        <span class="keyword">return</span> G</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_GD</span><span class="params">(self)</span>:</span></span><br><span class="line">        G, D = self.G, self.D</span><br><span class="line">        GD = models.Sequential()</span><br><span class="line">        GD.add(G)</span><br><span class="line">        GD.add(D)</span><br><span class="line">        D.trainable = <span class="keyword">False</span></span><br><span class="line">        model_compile(GD)</span><br><span class="line">        D.trainable = <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">return</span> GD</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">D_train_on_batch</span><span class="params">(self, Real, Gen)</span>:</span></span><br><span class="line">        D = self.D</span><br><span class="line">        X = np.concatenate([Real, Gen], axis=<span class="number">0</span>)</span><br><span class="line">        y = np.array([<span class="number">1</span>] * Real.shape[<span class="number">0</span>] + [<span class="number">0</span>] * Gen.shape[<span class="number">0</span>])</span><br><span class="line">        D.train_on_batch(X, y)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">GD_train_on_batch</span><span class="params">(self, Z)</span>:</span></span><br><span class="line">        GD = self.GD</span><br><span class="line">        y = np.array([<span class="number">1</span>] * Z.shape[<span class="number">0</span>])</span><br><span class="line">        GD.train_on_batch(Z, y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Data</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, mu, sigma, ni_D)</span>:</span></span><br><span class="line">        self.real_sample = <span class="keyword">lambda</span> n_batch: np.random.normal(mu, sigma, (n_batch, ni_D))</span><br><span class="line">        self.in_sample = <span class="keyword">lambda</span> n_batch: np.random.rand(n_batch, ni_D)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Machine</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_batch=<span class="number">10</span>, ni_D=<span class="number">100</span>)</span>:</span></span><br><span class="line">        data_mean = <span class="number">4</span></span><br><span class="line">        data_stddev = <span class="number">1.25</span></span><br><span class="line"></span><br><span class="line">        self.n_iter_D = <span class="number">1</span></span><br><span class="line">        self.n_iter_G = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">        self.data = Data(data_mean, data_stddev, ni_D)</span><br><span class="line">        self.gan = GAN(ni_D=ni_D, nh_D=<span class="number">50</span>, nh_G=<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">        self.n_batch = n_batch</span><br><span class="line">         self.ni_D = ni_D</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_D</span><span class="params">(self)</span>:</span></span><br><span class="line">        gan = self.gan</span><br><span class="line">        n_batch = self.n_batch</span><br><span class="line">        data = self.data</span><br><span class="line"></span><br><span class="line">         Real data</span><br><span class="line">        Real = data.real_sample(n_batch)   (n_batch, ni_D)</span><br><span class="line">         print(Real.shape)</span><br><span class="line">         Generated data</span><br><span class="line">        Z = data.in_sample(n_batch)   (n_batch, ni_D)</span><br><span class="line">        Gen = gan.G.predict(Z)   (n_batch, ni_D)</span><br><span class="line">         print(Gen.shape)</span><br><span class="line"></span><br><span class="line">        gan.D.trainable = <span class="keyword">True</span></span><br><span class="line">        gan.D_train_on_batch(Real, Gen)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_GD</span><span class="params">(self)</span>:</span></span><br><span class="line">        gan = self.gan</span><br><span class="line">        n_batch = self.n_batch</span><br><span class="line">        data = self.data</span><br><span class="line">         Seed data <span class="keyword">for</span> data generation</span><br><span class="line">        Z = data.in_sample(n_batch)</span><br><span class="line"></span><br><span class="line">        gan.D.trainable = <span class="keyword">False</span></span><br><span class="line">        gan.GD_train_on_batch(Z)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_each</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> it <span class="keyword">in</span> range(self.n_iter_D):</span><br><span class="line">            self.train_D()</span><br><span class="line">        <span class="keyword">for</span> it <span class="keyword">in</span> range(self.n_iter_G):</span><br><span class="line">            self.train_GD()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, epochs)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">            self.train_each()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(self, n_test)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        generate a new image</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        gan = self.gan</span><br><span class="line">        data = self.data</span><br><span class="line">        Z = data.in_sample(n_test)</span><br><span class="line">        Gen = gan.G.predict(Z)</span><br><span class="line">        <span class="keyword">return</span> Gen, Z</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show_hist</span><span class="params">(self, Real, Gen, Z)</span>:</span></span><br><span class="line">        plt.hist(Real.reshape(<span class="number">-1</span>), histtype=<span class="string">'step'</span>, label=<span class="string">'Real'</span>)</span><br><span class="line">        plt.hist(Gen.reshape(<span class="number">-1</span>), histtype=<span class="string">'step'</span>, label=<span class="string">'Generated'</span>)</span><br><span class="line">        plt.hist(Z.reshape(<span class="number">-1</span>), histtype=<span class="string">'step'</span>, label=<span class="string">'Input'</span>)</span><br><span class="line">        plt.legend(loc=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_and_show</span><span class="params">(self, n_test)</span>:</span></span><br><span class="line">        data = self.data</span><br><span class="line">        Gen, Z = self.test(n_test)</span><br><span class="line">        Real = data.real_sample(n_test)</span><br><span class="line">        self.show_hist(Real, Gen, Z)</span><br><span class="line">        Machine.print_stat(Real, Gen)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run_epochs</span><span class="params">(self, epochs, n_test)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        train GAN and show the results</span></span><br><span class="line"><span class="string">        for showing, the original and the artificial results will be compared</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.train(epochs)</span><br><span class="line">        self.test_and_show(n_test)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self, n_repeat=<span class="number">200</span>, n_show=<span class="number">200</span>, n_test=<span class="number">100</span>)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> ii <span class="keyword">in</span> range(n_repeat):</span><br><span class="line">            print(<span class="string">'Stage'</span>, ii, <span class="string">'(Epoch: &#123;&#125;)'</span>.format(ii * n_show))</span><br><span class="line">            self.run_epochs(n_show, n_test)</span><br><span class="line">            plt.show()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_stat</span><span class="params">(Real, Gen)</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">stat</span><span class="params">(d)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> (np.mean(d), np.std(d))</span><br><span class="line">        print(<span class="string">'Mean and Std of Real:'</span>, stat(Real))</span><br><span class="line">        print(<span class="string">'Mean and Std of Gen:'</span>, stat(Gen))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GAN_Pure</span><span class="params">(GAN)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, ni_D, nh_D, nh_G)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        Discriminator input is not added</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        super().__init__(ni_D, nh_D, nh_G)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gen_D</span><span class="params">(self)</span>:</span></span><br><span class="line">        ni_D = self.ni_D</span><br><span class="line">        nh_D = self.nh_D</span><br><span class="line">        D = models.Sequential()</span><br><span class="line">         D.add(Lambda(add_decorate, output_shape=add_decorate_shape, input_shape=(ni_D,)))</span><br><span class="line">        D.add(Dense(nh_D, activation=<span class="string">'relu'</span>, input_shape=(ni_D,)))</span><br><span class="line">        D.add(Dense(nh_D, activation=<span class="string">'relu'</span>))</span><br><span class="line">        D.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"></span><br><span class="line">        model_compile(D)</span><br><span class="line">        <span class="keyword">return</span> D</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Machine_Pure</span><span class="params">(Machine)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_batch=<span class="number">10</span>, ni_D=<span class="number">100</span>)</span>:</span></span><br><span class="line">        data_mean = <span class="number">4</span></span><br><span class="line">        data_stddev = <span class="number">1.25</span></span><br><span class="line"></span><br><span class="line">        self.data = Data(data_mean, data_stddev, ni_D)</span><br><span class="line">        self.gan = GAN_Pure(ni_D=ni_D, nh_D=<span class="number">50</span>, nh_G=<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">        self.n_batch = n_batch</span><br><span class="line">         self.ni_D = ni_D</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    machine = Machine(n_batch=<span class="number">1</span>, ni_D=<span class="number">100</span>)</span><br><span class="line">    machine.run(n_repeat=<span class="number">200</span>, n_show=<span class="number">200</span>, n_test=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><pre><code class="python"></code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;경쟁하여 최적화를 수행하는 생성형 신경망.&lt;/li&gt;
&lt;li&gt;내부의 두 신경망이 상호 경쟁하면서 학습.&lt;ul&gt;
&lt;li&gt;하나는 생성망, 하나는 판별망&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;7-1-GAN의-원리&quot;&gt;&lt;a hr
      
    
    </summary>
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/categories/DeepLearning/"/>
    
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/tags/DeepLearning/"/>
    
      <category term="코딩셰프의 3분 딥러닝, 케라스맛" scheme="https://ddulhddul.github.io/tags/%EC%BD%94%EB%94%A9%EC%85%B0%ED%94%84%EC%9D%98-3%EB%B6%84-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%BC%80%EB%9D%BC%EC%8A%A4%EB%A7%9B/"/>
    
  </entry>
  
  <entry>
    <title>케라스맛 Chapter4] 케라스로 구현하는 CNN (합성곱신경망)</title>
    <link href="https://ddulhddul.github.io/2018/04/15/DeepLearning/ml012/"/>
    <id>https://ddulhddul.github.io/2018/04/15/DeepLearning/ml012/</id>
    <published>2018-04-15T11:00:52.000Z</published>
    <updated>2019-06-06T10:04:52.486Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>영상처리에 많이 활용되는 합성곱을 이용하는 인공신경망 기술.</p></blockquote><h1 id="4-1-CNN-원리"><a href="#4-1-CNN-원리" class="headerlink" title="4.1 CNN 원리"></a>4.1 CNN 원리</h1><ul><li><p>합성곱 필터를 이용해 신경망 동작을 수행.</p><ul><li>합성곱계층 : 특징점을 효과적으로 찾는데 활용.</li><li>완전연결계층 : 찾으나 특징점을 기반으로 이미지를 분류하는데 주로 활용.<blockquote><p>주 목적은 그렇지만… 스스로 학습해 신경망이 최적화되기 때문에 그역할이 적정하게 둘에 분배된다. 한쪽이 절대적으로 특정 역할을 하는게 아니다.</p></blockquote></li></ul></li><li><p>CNN과 DNN 비교</p><ul><li>DNN은 이미지를 1차원 벡터로 변환하여 처리하기 때문에 2차원 특성을 처리하기엔 한계가 있다.</li><li>반면 CNN은 2차원 이상의 데이터 처리에 적합하다. </li><li>CNN 은 이미지의 높이와 넓이를 생각하며 2차원 처리를 수행.</li></ul></li><li><p>CNN 은 합성곱 계층이 끝나면 맥스풀링 계층을 이용해 각 지역별로 최댓값을 찾아줘서 특징점 위치가 약간씩 달라져도 딥러닝을 제대로 수행한다.</p></li></ul><h1 id="4-2-필기체를-분류하는-CNN-구현"><a href="#4-2-필기체를-분류하는-CNN-구현" class="headerlink" title="4.2 필기체를 분류하는 CNN 구현"></a>4.2 필기체를 분류하는 CNN 구현</h1><ul><li>4.2.1 분류 CNN 모델링</li><li>4.2.2 분류 CNN을 위한 데이터 준비  </li><li>4.2.3 학습 효과 분석</li><li>4.2.3 분류 CNN 학습 및 테스트</li></ul><h2 id="4-2-1-분류-CNN-모델링"><a href="#4-2-1-분류-CNN-모델링" class="headerlink" title="4.2.1 분류 CNN 모델링"></a>4.2.1 분류 CNN 모델링</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###############################</span></span><br><span class="line"><span class="comment"># 분류 CNN 모델링</span></span><br><span class="line"><span class="comment">###############################</span></span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models, layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="comment"># 딥러닝 엔진들 함수를 직접 호출하거나 주요 파라미터 제어</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNN</span><span class="params">(models.Sequential)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_shape, num_classes)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1. 3X3 커널 32개로 구성된 합성곱 계층</span></span><br><span class="line">        self.add(layers.Conv2D(<span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                 activation=<span class="string">'relu'</span>,</span><br><span class="line">                 input_shape=input_shape))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 64커널수, Maxpooling 이 부속계층으로 있음. (가중치가 바뀌진 않지만 특정한 형태로 변화시키는 계층을 부속계층이라고 한다고 합니다)</span></span><br><span class="line">        self.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">        self.add(layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">        self.add(layers.Dropout(<span class="number">0.25</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. 완전연결계층. Flatten : 2차원 이미지를 1차원으로 변화시킴</span></span><br><span class="line">        self.add(layers.Flatten())</span><br><span class="line">        self.add(layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">        self.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">        self.add(layers.Dense(num_classes, activation=<span class="string">'softmax'</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4. 컴파일</span></span><br><span class="line">        self.compile(loss=keras.losses.categorical_crossentropy,</span><br><span class="line">                      optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">                      metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure><h2 id="4-2-2-분류-CNN을-위한-데이터-준비"><a href="#4-2-2-분류-CNN을-위한-데이터-준비" class="headerlink" title="4.2.2 분류 CNN을 위한 데이터 준비"></a>4.2.2 분류 CNN을 위한 데이터 준비</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###############################</span></span><br><span class="line"><span class="comment"># 분류 CNN을 위한 데이터 준비  </span></span><br><span class="line"><span class="comment">###############################</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> datasets </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DATA</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        num_classes = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">        (x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()</span><br><span class="line">        img_rows, img_cols = x_train.shape[<span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 흑백 이미지는 채널 정보가 존재하지 않아서, 추가적인 차원을 이미지 데이터에 포함하는 작업.</span></span><br><span class="line">        <span class="keyword">if</span> backend.image_data_format() == <span class="string">'channels_first'</span>:</span><br><span class="line">            <span class="comment"># 샘플수, 채널수, 이미지 가로길이, 이미지세로길이</span></span><br><span class="line">            x_train = x_train.reshape(x_train.shape[<span class="number">0</span>], <span class="number">1</span>, img_rows, img_cols)</span><br><span class="line">            x_test = x_test.reshape(x_test.shape[<span class="number">0</span>], <span class="number">1</span>, img_rows, img_cols)</span><br><span class="line">            input_shape = (<span class="number">1</span>, img_rows, img_cols)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 샘플수, 이미지 가로길이, 이미지세로길이, 채널수</span></span><br><span class="line">            x_train = x_train.reshape(x_train.shape[<span class="number">0</span>], img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line">            x_test = x_test.reshape(x_test.shape[<span class="number">0</span>], img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line">            input_shape = (img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        x_train = x_train.astype(<span class="string">'float32'</span>)</span><br><span class="line">        x_test = x_test.astype(<span class="string">'float32'</span>)</span><br><span class="line">        x_train /= <span class="number">255</span></span><br><span class="line">        x_test /= <span class="number">255</span></span><br><span class="line"></span><br><span class="line">        y_train = keras.utils.to_categorical(y_train, num_classes)</span><br><span class="line">        y_test = keras.utils.to_categorical(y_test, num_classes)</span><br><span class="line">        </span><br><span class="line">        self.input_shape = input_shape</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.x_train, self.y_train = x_train, y_train</span><br><span class="line">        self.x_test, self.y_test = x_test, y_test</span><br></pre></td></tr></table></figure><h2 id="4-2-3-학습-효과-분석"><a href="#4-2-3-학습-효과-분석" class="headerlink" title="4.2.3 학습 효과 분석"></a>4.2.3 학습 효과 분석</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###########################</span></span><br><span class="line"><span class="comment"># 학습 효과 분석</span></span><br><span class="line"><span class="comment">###########################</span></span><br><span class="line"><span class="keyword">from</span> keraspp.skeras <span class="keyword">import</span> plot_loss, plot_acc</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><h2 id="4-2-3-분류-CNN-학습-및-테스트"><a href="#4-2-3-분류-CNN-학습-및-테스트" class="headerlink" title="4.2.3 분류 CNN 학습 및 테스트"></a>4.2.3 분류 CNN 학습 및 테스트</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###############################</span></span><br><span class="line"><span class="comment"># 분류 CNN 학습 및 테스트</span></span><br><span class="line"><span class="comment">###############################</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 1회 학습시 입력 데이터를 128개씩 나눠서 입력.</span></span><br><span class="line">    batch_size = <span class="number">128</span></span><br><span class="line">    epochs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    data = DATA()</span><br><span class="line">    model = CNN(data.input_shape, data.num_classes)</span><br><span class="line"></span><br><span class="line">    history = model.fit(data.x_train, data.y_train,</span><br><span class="line">              batch_size=batch_size,</span><br><span class="line">              epochs=epochs,</span><br><span class="line">              <span class="comment"># 검증용 데이터는 학습데이터의 일부를 사용</span></span><br><span class="line">              validation_split=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">    score = model.evaluate(data.x_test, data.y_test)</span><br><span class="line">    print()</span><br><span class="line">    print(<span class="string">'Test loss:'</span>, score[<span class="number">0</span>])</span><br><span class="line">    print(<span class="string">'Test accuracy:'</span>, score[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    plot_loss(history)</span><br><span class="line">    plt.show()</span><br><span class="line">    plot_acc(history)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h2 id="http-localhost-8888-notebooks-nb-ex4-1-cnn-mnist-cl-ipynb"><a href="#http-localhost-8888-notebooks-nb-ex4-1-cnn-mnist-cl-ipynb" class="headerlink" title="http://localhost:8888/notebooks/nb_ex4_1_cnn_mnist_cl.ipynb"></a><a href="http://localhost:8888/notebooks/nb_ex4_1_cnn_mnist_cl.ipynb" target="_blank" rel="noopener">http://localhost:8888/notebooks/nb_ex4_1_cnn_mnist_cl.ipynb</a></h2><h1 id="4-3-컬러-이미지를-분류하는-CNN-구현"><a href="#4-3-컬러-이미지를-분류하는-CNN-구현" class="headerlink" title="4.3 컬러 이미지를 분류하는 CNN 구현"></a>4.3 컬러 이미지를 분류하는 CNN 구현</h1><ul><li>필기체 분류와 크게 다르지 않다.</li><li>CIFAR-10<ul><li>4.3.1 분류 CNN 패키지 임포트</li><li>4.3.2 분류 CNN 모델링</li><li>4.3.3 분류 CNN을 위한 데이터 준비</li><li>4.3.4 분류 CNN의 학습 및 성능 평가를 위한 머신 클래스 구현</li><li>4.3.5 분류 CNN의 학습 및 성능 평가 수행</li></ul></li></ul><h2 id="4-3-1-분류-CNN-패키지-임포트"><a href="#4-3-1-분류-CNN-패키지-임포트" class="headerlink" title="4.3.1 분류 CNN 패키지 임포트"></a>4.3.1 분류 CNN 패키지 임포트</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection, metrics</span><br><span class="line"><span class="comment"># 지정한 최대 최소값을 이용해 입력값 크기 조정</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 케라스 모델링을 위한 서브패키지들</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> . <span class="keyword">import</span> skeras</span><br><span class="line"><span class="keyword">from</span> . <span class="keyword">import</span> sfile</span><br></pre></td></tr></table></figure><h2 id="4-3-2-분류-CNN-모델링"><a href="#4-3-2-분류-CNN-모델링" class="headerlink" title="4.3.2 분류 CNN 모델링"></a>4.3.2 분류 CNN 모델링</h2><ul><li>LeNet 신경망 모델 사용<ul><li>합성곱 계층 2개, 완전연결계층 1개</li><li>Conv2D(), Maxpoling2D() : 채널에 처리가 있는 계층</li><li>Dense() : 채널에 대한 처리가 없는 계층</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNN</span><span class="params">(Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(model, nb_classes, in_shape=None)</span>:</span></span><br><span class="line">        model.nb_classes = nb_classes</span><br><span class="line">        model.in_shape = in_shape</span><br><span class="line">        model.build_model()</span><br><span class="line">        super().__init__(model.x, model.y)</span><br><span class="line">        model.compile()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_model</span><span class="params">(model)</span>:</span></span><br><span class="line">        nb_classes = model.nb_classes</span><br><span class="line">        in_shape = model.in_shape</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 주어진 입력 이미지의 크기를 처리하는 입력 계층을 정의</span></span><br><span class="line">        x = Input(in_shape)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 합성곱 계층 두 개를 정의</span></span><br><span class="line">        h = Conv2D(<span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>,</span><br><span class="line">                   input_shape=in_shape)(x)</span><br><span class="line">        h = Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>)(h)</span><br><span class="line"></span><br><span class="line">        h = MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>))(h) <span class="comment"># 가로세로 두 축으로 반반씩 줄어듬</span></span><br><span class="line">        h = Dropout(<span class="number">0.25</span>)(h)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 합성곱 계층을 완전연결 계층으롤 보내기 위해 플랫턴 작업</span></span><br><span class="line">        <span class="comment"># 3차원 데이터 -&gt; 1차원</span></span><br><span class="line">        h = Flatten()(h)</span><br><span class="line">        z_cl = h</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 완전연결계층의 은닉 계층과 출력 계층</span></span><br><span class="line">        h = Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>)(h)</span><br><span class="line">        h = Dropout(<span class="number">0.5</span>)(h)</span><br><span class="line">        z_fl = h</span><br><span class="line">        y = Dense(nb_classes, activation=<span class="string">'softmax'</span>, name=<span class="string">'preds'</span>)(h)</span><br><span class="line"></span><br><span class="line">        model.cl_part = Model(x, z_cl)</span><br><span class="line">        model.fl_part = Model(x, z_fl)</span><br><span class="line"></span><br><span class="line">        model.x, model.y = x, y</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compile</span><span class="params">(model)</span>:</span></span><br><span class="line">        Model.compile(model, loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">                      optimizer=<span class="string">'adadelta'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure><h2 id="4-3-3-분류-CNN을-위한-데이터-준비"><a href="#4-3-3-분류-CNN을-위한-데이터-준비" class="headerlink" title="4.3.3 분류 CNN을 위한 데이터 준비"></a>4.3.3 분류 CNN을 위한 데이터 준비</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 데이터를 머신러닝에 사용하기 적합하도록 조정하는 역할</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataSet</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, X, y, nb_classes, scaling=True, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        X is originally vector. Hence, it will be transformed</span></span><br><span class="line"><span class="string">        to 2D images with a channel (i.e, 3D).</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.X = X</span><br><span class="line">        self.add_channels()</span><br><span class="line"></span><br><span class="line">        X = self.X</span><br><span class="line">        <span class="comment"># the data, shuffled and split between train and test sets</span></span><br><span class="line">        X_train, X_test, y_train, y_test = model_selection.train_test_split(</span><br><span class="line">            X, y, test_size=<span class="number">0.2</span>, random_state=random_state)</span><br><span class="line"></span><br><span class="line">        print(X_train.shape, y_train.shape)</span><br><span class="line"></span><br><span class="line">        X_train = X_train.astype(<span class="string">'float32'</span>)</span><br><span class="line">        X_test = X_test.astype(<span class="string">'float32'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> scaling:</span><br><span class="line">            <span class="comment"># scaling to have (0, 1) for each feature (each pixel)</span></span><br><span class="line">            scaler = MinMaxScaler()</span><br><span class="line">            n = X_train.shape[<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># 스케일링 기준은 X_train 으로만 해야한다. X_test는 X_train으로부터 정해진 기준을 따르게 한다.</span></span><br><span class="line">            X_train = scaler.fit_transform(</span><br><span class="line">                X_train.reshape(n, <span class="number">-1</span>)).reshape(X_train.shape)</span><br><span class="line">            n = X_test.shape[<span class="number">0</span>]</span><br><span class="line">            X_test = scaler.transform(</span><br><span class="line">                X_test.reshape(n, <span class="number">-1</span>)).reshape(X_test.shape)</span><br><span class="line">            self.scaler = scaler</span><br><span class="line"></span><br><span class="line">        print(<span class="string">'X_train shape:'</span>, X_train.shape)</span><br><span class="line">        print(X_train.shape[<span class="number">0</span>], <span class="string">'train samples'</span>)</span><br><span class="line">        print(X_test.shape[<span class="number">0</span>], <span class="string">'test samples'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># convert class vectors to binary class matrices</span></span><br><span class="line">        Y_train = np_utils.to_categorical(y_train, nb_classes)</span><br><span class="line">        Y_test = np_utils.to_categorical(y_test, nb_classes)</span><br><span class="line"></span><br><span class="line">        self.X_train, self.X_test = X_train, X_test</span><br><span class="line">        self.Y_train, self.Y_test = Y_train, Y_test</span><br><span class="line">        self.y_train, self.y_test = y_train, y_test</span><br><span class="line">        <span class="comment"># self.input_shape = input_shape</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 채널 정보를 데이터에 포함시키는 과정</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_channels</span><span class="params">(self)</span>:</span></span><br><span class="line">        X = self.X</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 흑백 이미지인지 검사</span></span><br><span class="line">        <span class="keyword">if</span> len(X.shape) == <span class="number">3</span>:</span><br><span class="line">            N, img_rows, img_cols = X.shape</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> K.image_dim_ordering() == <span class="string">'th'</span>:</span><br><span class="line">                X = X.reshape(X.shape[<span class="number">0</span>], <span class="number">1</span>, img_rows, img_cols)</span><br><span class="line">                input_shape = (<span class="number">1</span>, img_rows, img_cols)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                X = X.reshape(X.shape[<span class="number">0</span>], img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line">                input_shape = (img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            input_shape = X.shape[<span class="number">1</span>:]  <span class="comment"># channel is already included.</span></span><br><span class="line"></span><br><span class="line">        self.X = X</span><br><span class="line">        self.input_shape = input_shape</span><br></pre></td></tr></table></figure><h2 id="4-3-4-분류-CNN의-학습-및-성능-평가를-위한-머신-클래스-구현"><a href="#4-3-4-분류-CNN의-학습-및-성능-평가를-위한-머신-클래스-구현" class="headerlink" title="4.3.4 분류 CNN의 학습 및 성능 평가를 위한 머신 클래스 구현"></a>4.3.4 분류 CNN의 학습 및 성능 평가를 위한 머신 클래스 구현</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 학습 및 성능 평가 코드가 들어 있는 클래스</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Machine</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, X, y, nb_classes=<span class="number">2</span>, fig=True)</span>:</span></span><br><span class="line">        self.nb_classes = nb_classes</span><br><span class="line">        self.set_data(X, y)</span><br><span class="line">        self.set_model()</span><br><span class="line">        <span class="comment"># 수행결과를 그림으로 보여줄지</span></span><br><span class="line">        self.fig = fig</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_data</span><span class="params">(self, X, y)</span>:</span></span><br><span class="line">        nb_classes = self.nb_classes</span><br><span class="line">        self.data = DataSet(X, y, nb_classes)</span><br><span class="line">        print(<span class="string">'data.input_shape'</span>, self.data.input_shape)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_model</span><span class="params">(self)</span>:</span></span><br><span class="line">        nb_classes = self.nb_classes</span><br><span class="line">        data = self.data</span><br><span class="line">        self.model = CNN(nb_classes=nb_classes, in_shape=data.input_shape)</span><br><span class="line">        <span class="comment"># cnn_lenet(nb_classes=nb_classes, in_shape=data.input_shape)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, </span></span></span><br><span class="line"><span class="function"><span class="params">            epochs=<span class="number">10</span>,      # 에포크</span></span></span><br><span class="line"><span class="function"><span class="params">            batch_size=<span class="number">128</span>, # 학습시 한번에 처리할 블록 길이</span></span></span><br><span class="line"><span class="function"><span class="params">            verbose=<span class="number">1</span>       # 화면에 진행사항 표시방법</span></span></span><br><span class="line"><span class="function"><span class="params">        )</span>:</span></span><br><span class="line">        data = self.data</span><br><span class="line">        model = self.model</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 학습 시작</span></span><br><span class="line">        history = model.fit(data.X_train, data.Y_train, batch_size=batch_size, epochs=epochs,</span><br><span class="line">                            verbose=verbose, validation_data=(data.X_test, data.Y_test))</span><br><span class="line">        <span class="keyword">return</span> history</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 학습과 성능 평가 전체를 진행</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self, epochs=<span class="number">10</span>, batch_size=<span class="number">128</span>, verbose=<span class="number">1</span>)</span>:</span></span><br><span class="line">        data = self.data</span><br><span class="line">        model = self.model</span><br><span class="line">        fig = self.fig</span><br><span class="line"></span><br><span class="line">        history = self.fit(epochs=epochs,</span><br><span class="line">                           batch_size=batch_size, verbose=verbose)</span><br><span class="line"></span><br><span class="line">        score = model.evaluate(data.X_test, data.Y_test, verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        print(<span class="string">'Confusion matrix'</span>)</span><br><span class="line">        Y_test_pred = model.predict(data.X_test, verbose=<span class="number">0</span>)</span><br><span class="line">        y_test_pred = np.argmax(Y_test_pred, axis=<span class="number">1</span>)</span><br><span class="line">        print(metrics.confusion_matrix(data.y_test, y_test_pred))</span><br><span class="line"></span><br><span class="line">        print(<span class="string">'Test score:'</span>, score[<span class="number">0</span>])</span><br><span class="line">        print(<span class="string">'Test accuracy:'</span>, score[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Save results</span></span><br><span class="line">        suffix = sfile.unique_filename(<span class="string">'datatime'</span>)</span><br><span class="line">        foldname = <span class="string">'output_'</span> + suffix</span><br><span class="line">        os.makedirs(foldname)</span><br><span class="line">        skeras.save_history_history(</span><br><span class="line">            <span class="string">'history_history.npy'</span>, history.history, fold=foldname)</span><br><span class="line">        model.save_weights(os.path.join(foldname, <span class="string">'dl_model.h5'</span>))</span><br><span class="line">        print(<span class="string">'Output results are saved in'</span>, foldname)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 학습 곡선 그리기</span></span><br><span class="line">        <span class="keyword">if</span> fig:</span><br><span class="line">            plt.figure(figsize=(<span class="number">12</span>, <span class="number">4</span>))</span><br><span class="line">            plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">            skeras.plot_acc(history)</span><br><span class="line">            plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">            skeras.plot_loss(history)</span><br><span class="line">            plt.show()</span><br><span class="line"></span><br><span class="line">        self.history = history</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> foldname</span><br></pre></td></tr></table></figure><h2 id="4-3-5-분류-CNN의-학습-및-성능-평가-수행"><a href="#4-3-5-분류-CNN의-학습-및-성능-평가-수행" class="headerlink" title="4.3.5 분류 CNN의 학습 및 성능 평가 수행"></a>4.3.5 분류 CNN의 학습 및 성능 평가 수행</h2><h2 id="http-localhost-8888-notebooks-nb-ex4-2-cnn-cifar10-cl-ipynb"><a href="#http-localhost-8888-notebooks-nb-ex4-2-cnn-cifar10-cl-ipynb" class="headerlink" title="http://localhost:8888/notebooks/nb_ex4_2_cnn_cifar10_cl.ipynb"></a><a href="http://localhost:8888/notebooks/nb_ex4_2_cnn_cifar10_cl.ipynb" target="_blank" rel="noopener">http://localhost:8888/notebooks/nb_ex4_2_cnn_cifar10_cl.ipynb</a></h2><h1 id="4-4-마치며"><a href="#4-4-마치며" class="headerlink" title="4.4 마치며"></a>4.4 마치며</h1><ul><li>CNN 은 합성곱 계층을 이용해 적은 가중치 수로도 이미지 분류에서 높은 성능(?)을 낸다.</li><li>가중치 수가 적기 때문에 과적합의 가능성도 낮아진다.</li><li>이미지 특성에 맞게 합성곱 필터링이 이루어지기 때문에 이미지 내에 있는 특징점을 잘 찾아낸다.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;영상처리에 많이 활용되는 합성곱을 이용하는 인공신경망 기술.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;4-1-CNN-원리&quot;&gt;&lt;a href=&quot;#4-1-CNN-원리&quot; class=&quot;headerlink&quot; title=&quot;4.1 
      
    
    </summary>
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/categories/DeepLearning/"/>
    
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/tags/DeepLearning/"/>
    
      <category term="코딩셰프의 3분 딥러닝, 케라스맛" scheme="https://ddulhddul.github.io/tags/%EC%BD%94%EB%94%A9%EC%85%B0%ED%94%84%EC%9D%98-3%EB%B6%84-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%BC%80%EB%9D%BC%EC%8A%A4%EB%A7%9B/"/>
    
  </entry>
  
  <entry>
    <title>코딩셰프의 3분 딥러닝, 케라스맛 Init</title>
    <link href="https://ddulhddul.github.io/2018/04/01/DeepLearning/ml011/"/>
    <id>https://ddulhddul.github.io/2018/04/01/DeepLearning/ml011/</id>
    <published>2018-04-01T10:00:52.000Z</published>
    <updated>2019-06-06T10:04:52.486Z</updated>
    
    <content type="html"><![CDATA[<h2 id="파이썬-Numpy-강좌"><a href="#파이썬-Numpy-강좌" class="headerlink" title="파이썬 Numpy 강좌"></a><a href="http://aikorea.org/cs231n/python-numpy-tutorial/" target="_blank" rel="noopener">파이썬 Numpy 강좌</a></h2><h2 id="코딩셰프의-3분-딥러닝-케라스맛-Github"><a href="#코딩셰프의-3분-딥러닝-케라스맛-Github" class="headerlink" title="코딩셰프의 3분 딥러닝, 케라스맛 Github"></a><a href="https://github.com/jskDr/keraspp" target="_blank" rel="noopener">코딩셰프의 3분 딥러닝, 케라스맛 Github</a></h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;파이썬-Numpy-강좌&quot;&gt;&lt;a href=&quot;#파이썬-Numpy-강좌&quot; class=&quot;headerlink&quot; title=&quot;파이썬 Numpy 강좌&quot;&gt;&lt;/a&gt;&lt;a href=&quot;http://aikorea.org/cs231n/python-numpy-tu
      
    
    </summary>
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/categories/DeepLearning/"/>
    
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/tags/DeepLearning/"/>
    
      <category term="코딩셰프의 3분 딥러닝, 케라스맛" scheme="https://ddulhddul.github.io/tags/%EC%BD%94%EB%94%A9%EC%85%B0%ED%94%84%EC%9D%98-3%EB%B6%84-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%BC%80%EB%9D%BC%EC%8A%A4%EB%A7%9B/"/>
    
  </entry>
  
  <entry>
    <title>생활코딩. 지옥에서 온 Git 정리</title>
    <link href="https://ddulhddul.github.io/2018/03/22/datas/git/git001/"/>
    <id>https://ddulhddul.github.io/2018/03/22/datas/git/git001/</id>
    <published>2018-03-22T13:00:52.000Z</published>
    <updated>2019-06-06T10:04:52.488Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://opentutorials.org/course/2708" target="_blank" rel="noopener">생활코딩 - 지옥에서 온 Git</a></p><h1 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h1><h2 id="Git-init-Setting"><a href="#Git-init-Setting" class="headerlink" title="Git init Setting"></a>Git init Setting</h2><ol start="0"><li>git bash 구동</li><li><p>SSL 인증서 검증을 끕니다.</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --global http.sslVerify <span class="literal">false</span></span><br></pre></td></tr></table></figure></li><li><p>HTTP POST 최대 사이즈를 수정합니다.</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --global http.postBuffer 524288000</span><br></pre></td></tr></table></figure></li><li><p>git bash 구동시, 초기 path 설정</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> <span class="variable">$home</span></span><br><span class="line">$ vi .bashrc</span><br></pre></td></tr></table></figure><ul><li>Edit 창에 cd %프로젝트 경로% 입력 후 :wq<ul><li>(본인의 프로젝트 경로를 입력한다.)</li></ul></li></ul></li><li><p>Git bash User name &amp; Email Setting</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git config --global user.name <span class="string">"name"</span></span><br><span class="line">$ git config --global user.email <span class="string">"mailmail@mail.com"</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="GIt-에서-특정-파일을-제외하는-방법"><a href="#GIt-에서-특정-파일을-제외하는-방법" class="headerlink" title="GIt 에서 특정 파일을 제외하는 방법"></a>GIt 에서 특정 파일을 제외하는 방법</h2><ul><li>저장소에서 파일 삭제하지만 내 작업공간에 필요한 경우  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git rm --cached filename</span><br></pre></td></tr></table></figure></li></ul><ul><li>저장소에도 필요하고 내 작업공간도 필요한 경우  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git update-index --assume-unchanged [path]</span><br></pre></td></tr></table></figure></li></ul><hr><hr><h1 id="버전-관리의-본질"><a href="#버전-관리의-본질" class="headerlink" title="버전 관리의 본질"></a>버전 관리의 본질</h1><h2 id="1-설치-및-실습-방법"><a href="#1-설치-및-실습-방법" class="headerlink" title="1. 설치 및 실습 방법"></a>1. 설치 및 실습 방법</h2><ul><li><a href="http://git-scm.com" target="_blank" rel="noopener">Git</a></li><li><a href="https://codeonweb.com/dashboard" target="_blank" rel="noopener">code on web</a></li></ul><h2 id="2-저장소-만들기"><a href="#2-저장소-만들기" class="headerlink" title="2. 저장소 만들기"></a>2. 저장소 만들기</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git init</span><br></pre></td></tr></table></figure><h2 id="3-git이-관리할-대상으로-파일-등록"><a href="#3-git이-관리할-대상으로-파일-등록" class="headerlink" title="3. git이 관리할 대상으로 파일 등록"></a>3. git이 관리할 대상으로 파일 등록</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ vim f1.txt</span><br><span class="line"><span class="comment"># typing 'source : 1'</span></span><br><span class="line">$ git add f1.txt</span><br><span class="line">$ git status</span><br></pre></td></tr></table></figure><h2 id="4-버전-만들기-commit"><a href="#4-버전-만들기-commit" class="headerlink" title="4. 버전 만들기 (commit)"></a>4. 버전 만들기 (commit)</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Commiter Info Setting</span></span><br><span class="line">$ git config --global user.name <span class="string">"name"</span></span><br><span class="line">$ git config --global user.email <span class="string">"mailmail@mail.com"</span></span><br><span class="line"><span class="comment"># Commit</span></span><br><span class="line">$ git commit</span><br><span class="line"><span class="comment"># typing commit message 'version 1'</span></span><br><span class="line">$ git <span class="built_in">log</span></span><br></pre></td></tr></table></figure><h2 id="5-Stage-area"><a href="#5-Stage-area" class="headerlink" title="5. Stage area"></a>5. Stage area</h2><p>Commit 전에 Add를 하는 이유는, 선택적으로 파일을 버전에 포함시키기 위함.<br>Add 를 하면 Stage Area 에 등록된다.</p><h2 id="6-변경사항-확인하기"><a href="#6-변경사항-확인하기" class="headerlink" title="6. 변경사항 확인하기"></a>6. 변경사항 확인하기</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 각각의 커밋과 커밋 사이 소스 차이 확인 가능</span></span><br><span class="line">$ git <span class="built_in">log</span> -p</span><br><span class="line"><span class="comment"># 해당 커밋 이전의 내용만 확인 가능</span></span><br><span class="line">$ git <span class="built_in">log</span> 48d495b0580194d38bd49bc4993f4bedf26a28aa</span><br><span class="line"><span class="comment"># 해당 커밋 사이의 변경 내용 확인</span></span><br><span class="line">$ git diff ee40b63a6e923cee04ba9dc3ae9306e50a9e53f9..08eaffc820df097f0746359d5d70cb15ba8b03b5</span><br><span class="line"><span class="comment"># 현재 어떤 작업 했는지 확인 가능</span></span><br><span class="line">$ git diff</span><br></pre></td></tr></table></figure><h2 id="7-과거의-버전으로-돌아가기"><a href="#7-과거의-버전으로-돌아가기" class="headerlink" title="7. 과거의 버전으로 돌아가기"></a>7. 과거의 버전으로 돌아가기</h2><p>현재의 로그를 취소해서 과거로 돌아가고 싶다 ??</p><ol><li><p>Reset</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 08eaffc820df097f0746359d5d70cb15ba8b03b5 이후의 버전을 삭제</span></span><br><span class="line">$ git reset 08eaffc820df097f0746359d5d70cb15ba8b03b5 --hard</span><br></pre></td></tr></table></figure><p> 실제로는 버린게 아니라, 남아있다. 보이지 않을뿐.</p></li><li><p>Revert<br> 커밋을 날리는 것이 아니라 해당 커밋을 취소하면서 새로운 버전을 생성한다.</p></li></ol><h2 id="8-명령의-빈도와-메뉴얼-보는-방법"><a href="#8-명령의-빈도와-메뉴얼-보는-방법" class="headerlink" title="8. 명령의 빈도와 메뉴얼 보는 방법"></a>8. 명령의 빈도와 메뉴얼 보는 방법</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git commit --<span class="built_in">help</span></span><br></pre></td></tr></table></figure><hr><h1 id="Git의-원리"><a href="#Git의-원리" class="headerlink" title="Git의 원리"></a>Git의 원리</h1><h2 id="1-gistory-설치"><a href="#1-gistory-설치" class="headerlink" title="1. gistory 설치"></a>1. gistory 설치</h2><blockquote><p>.git 내부 변화를 살펴보며, git 이 어떻게 작동하는지 알아보자.</p></blockquote><ol><li>python을 설치합니다. (python2, 3 모두 호환됩니다)<br> <a href="http://python.org/" target="_blank" rel="noopener">http://python.org/</a></li><li>pip로 설치합니다. <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install gistory</span><br></pre></td></tr></table></figure></li></ol><h2 id="2-git-add의-원리"><a href="#2-git-add의-원리" class="headerlink" title="2. git add의 원리"></a>2. git add의 원리</h2><p>내용이 같으면 같은 파일명에 담긴다. // 어떻게 ? // sha1</p><h2 id="3-objects-파일명의-원리"><a href="#3-objects-파일명의-원리" class="headerlink" title="3. objects 파일명의 원리"></a>3. objects 파일명의 원리</h2><p>각각의 버전은 tree, blob, commit 으로 구성된다.</p><h2 id="4-status의-원리"><a href="#4-status의-원리" class="headerlink" title="4. status의 원리"></a>4. status의 원리</h2><p>working directory - index, staging area, cache - repository<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git status</span><br></pre></td></tr></table></figure></p><ul><li>최신 commit 과 index 의 내용을 비교해서 알려준다.<br><img src="https://i.stack.imgur.com/caci5.png" alt="https://i.stack.imgur.com/caci5.png"><ul><li>Add 하면 Staging Area(index 파일)에 등록 // Commit 대기상태</li><li>Commit 하면 Local Repository에 등록</li></ul></li></ul><hr><h1 id="git의-혁신-branch"><a href="#git의-혁신-branch" class="headerlink" title="git의 혁신 - branch"></a>git의 혁신 - branch</h1><h2 id="1-branch-만들기"><a href="#1-branch-만들기" class="headerlink" title="1. branch 만들기"></a>1. branch 만들기</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git branch</span><br><span class="line">$ git branch exp <span class="comment"># exp 이름의 branch 생성</span></span><br><span class="line">$ git checkout exp <span class="comment"># exp branch 로 이동</span></span><br></pre></td></tr></table></figure><h2 id="2-branch-정보확인"><a href="#2-branch-정보확인" class="headerlink" title="2. branch 정보확인"></a>2. branch 정보확인</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ git branch</span><br><span class="line">$ git <span class="built_in">log</span> --branches --graph <span class="comment"># 현재 체크아웃되어있는 브랜치 말고 저장소의 모든 브랜치를 보여줌</span></span><br><span class="line">$ git <span class="built_in">log</span> --branches --graph --oneline <span class="comment"># 한줄로 표현</span></span><br><span class="line">$ git <span class="built_in">log</span> master..exp <span class="comment"># master엔 없고 exp에 있는 커밋을 보여줌</span></span><br><span class="line">$ git diff master..exp <span class="comment"># master엔 없고 exp에 있는 내용을 보여줌</span></span><br></pre></td></tr></table></figure><ul><li>stree // GUI 버전관리툴</li></ul><h2 id="3-branch-병합"><a href="#3-branch-병합" class="headerlink" title="3. branch 병합"></a>3. branch 병합</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># exp 의 내용을 master로 옮기는 방법</span></span><br><span class="line">$ git checkout master</span><br><span class="line">$ git merge exp</span><br><span class="line"></span><br><span class="line"><span class="comment"># master 의 내용을 exp로 옮기는 방법</span></span><br><span class="line">$ git checkout exp</span><br><span class="line">$ git merge master</span><br><span class="line"></span><br><span class="line"><span class="comment"># exp branch 삭제</span></span><br><span class="line">$ git checkout master</span><br><span class="line">$ git branch -d exp</span><br></pre></td></tr></table></figure><ul><li>두개의 부모를 갖는 하나의 commit 이 만들어진다.</li></ul><h2 id="4-branch-수련"><a href="#4-branch-수련" class="headerlink" title="4. branch 수련"></a>4. branch 수련</h2><p><a href="https://www.git-scm.com" target="_blank" rel="noopener">https://www.git-scm.com</a><br><a href="https://www.git-scm.com/book/en/v2/Git-Branching-Basic-Branching-and-Merging" target="_blank" rel="noopener">3.2 Git Branching - Basic Branching and Merging</a></p><ul><li><p>Fast-Forward</p><ul><li>(master) git merge hotfix</li><li>master는 hotfix 를 가리키게 된다. (별도의 커밋을 생성하지 않는다.)<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout -b <span class="string">'iss53'</span></span><br><span class="line">$ git checkout master</span><br><span class="line">$ git merge hotfix</span><br></pre></td></tr></table></figure></li></ul></li><li><p>Recursive Stragety</p><ul><li>master 와 iss53 의 공통의 조상을 찾는다.</li><li><p>두가지의 브랜치를 합친 별도의 머지 커밋을 만든다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout master</span><br><span class="line">$ git merge iss53</span><br><span class="line">```    </span><br><span class="line"></span><br><span class="line"><span class="comment">## 5. branch 병합 시 충돌해결</span></span><br><span class="line">- 같은 파일임에도 수정한 위치가 다르면 자동 merge.</span><br><span class="line">- 같은 위치를 수정했을때 merge -&gt; conflict</span><br><span class="line">    ```bash</span><br><span class="line">     (master|MERGING)</span><br><span class="line">    &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</span><br><span class="line">    <span class="keyword">function</span> b()</span><br><span class="line">    =======</span><br><span class="line">    <span class="keyword">function</span> c()</span><br><span class="line">    &gt;&gt;&gt;&gt;&gt;&gt;&gt; exp</span><br><span class="line">    <span class="keyword">function</span> <span class="function"><span class="title">a</span></span>()&#123;&#125;</span><br></pre></td></tr></table></figure></li><li><p>자동병합에 실패했기 때문에, 충돌 해결을 위임한 것.</p></li></ul></li><li><p>해결 방법</p><ol><li>충돌난 부분 수정</li><li>git add 해당파일</li><li>git commit -m ‘’</li></ol></li></ul><h2 id="6-stash"><a href="#6-stash" class="headerlink" title="6. stash"></a>6. stash</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">$ git init</span><br><span class="line">$ git checkout master </span><br><span class="line"><span class="comment"># 작업이 끝나지 않았으면 작업 그대로 master 로 가기때문에 곤란하다.</span></span><br><span class="line"></span><br><span class="line">$ git stash</span><br><span class="line"><span class="comment"># Saved working directory and index state WIP on exp: b920916 10</span></span><br><span class="line"><span class="comment"># 작업중인 변경사항들이 save되었다.</span></span><br><span class="line">$ git status</span><br><span class="line"></span><br><span class="line">$ git stash apply</span><br><span class="line"><span class="comment"># 작업중인 변경사항들이 load되었다.</span></span><br><span class="line"></span><br><span class="line">$ git stash list</span><br><span class="line"><span class="comment"># stash@&#123;0&#125;: WIP on exp: b920916 10</span></span><br><span class="line"></span><br><span class="line">$ git reset --hard HEAD</span><br><span class="line">$ git stash apply</span><br><span class="line"><span class="comment"># 명시적으로 삭제하지 않는이상 stash 는 살아있다.</span></span><br><span class="line"></span><br><span class="line">$ vim f2.txt <span class="comment"># 신규파일</span></span><br><span class="line">$ git stash</span><br><span class="line">$ git stash list</span><br><span class="line"><span class="comment"># stash@&#123;0&#125;: WIP on exp: b920916 10  // 방금것</span></span><br><span class="line"><span class="comment"># stash@&#123;1&#125;: WIP on exp: b920916 10  // 그 이전것</span></span><br><span class="line"></span><br><span class="line">$ git stash apply <span class="comment"># 가장 최근 stash 가 적용된다.</span></span><br><span class="line">$ git stash drop <span class="comment"># 최근 stash 제거</span></span><br><span class="line"></span><br><span class="line">$ git stash apply; git stash drop;</span><br><span class="line">$ git stash pop</span><br><span class="line"><span class="comment"># 적용하고 삭제하고</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Untracked files 는 stash 에 저장되지 않는다. </span></span><br><span class="line"><span class="comment"># 버전관리가 되고있는 파일들만 stash 할 수 있다.</span></span><br></pre></td></tr></table></figure><hr><h1 id="끝이-열려-있는-수업과-학습"><a href="#끝이-열려-있는-수업과-학습" class="headerlink" title="끝이 열려 있는 수업과 학습"></a>끝이 열려 있는 수업과 학습</h1><h2 id="3-way-merge"><a href="#3-way-merge" class="headerlink" title="3 way merge"></a>3 way merge</h2><table><thead><tr><th>Me</th><th>Base</th><th>Other</th><th>2way merge</th><th>3way merge</th></tr></thead><tbody><tr><td> A</td><td>A</td><td>-</td><td><font color="red">?</font></td><td>-</td></tr><tr><td> B</td><td>B</td><td>B</td><td>B</td><td>B</td></tr><tr><td> 1</td><td>C</td><td>2</td><td><font color="red">?</font></td><td><font color="red">?</font></td></tr><tr><td> -</td><td>D</td><td>D</td><td><font color="red">?</font></td><td>-</td></tr></tbody></table><ul><li>2way merge : base 를 보지않고 2개를 병합</li><li>3way merge : base를 참고로 해서 2개를 병합</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://opentutorials.org/course/2708&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;생활코딩 - 지옥에서 온 Git&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;Tips&quot;&gt;&lt;a href=&quot;#Tips&quot; cl
      
    
    </summary>
    
      <category term="Git" scheme="https://ddulhddul.github.io/categories/Git/"/>
    
    
      <category term="Git" scheme="https://ddulhddul.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>리액트 참조 사이트</title>
    <link href="https://ddulhddul.github.io/2018/03/17/datas/react/react_d2/"/>
    <id>https://ddulhddul.github.io/2018/03/17/datas/react/react_d2/</id>
    <published>2018-03-17T13:00:52.000Z</published>
    <updated>2019-06-06T10:04:52.489Z</updated>
    
    <content type="html"><![CDATA[<h2 id="React-적용-가이드-React와-Redux"><a href="#React-적용-가이드-React와-Redux" class="headerlink" title="React 적용 가이드 - React와 Redux"></a>React 적용 가이드 - React와 Redux</h2><p><a href="http://d2.naver.com/helloworld/1848131" target="_blank" rel="noopener">http://d2.naver.com/helloworld/1848131</a></p><ul><li>Sample Code<br><a href="https://github.com/naver/react-sample-code" target="_blank" rel="noopener">https://github.com/naver/react-sample-code</a></li></ul><h3 id="Redux"><a href="#Redux" class="headerlink" title="Redux"></a>Redux</h3><p><a href="https://deminoth.github.io/redux/" target="_blank" rel="noopener">https://deminoth.github.io/redux/</a></p><h2 id="React-적용-가이드-React-작동-방법"><a href="#React-적용-가이드-React-작동-방법" class="headerlink" title="React 적용 가이드 - React 작동 방법"></a>React 적용 가이드 - React 작동 방법</h2><p><a href="http://d2.naver.com/helloworld/9297403" target="_blank" rel="noopener">http://d2.naver.com/helloworld/9297403</a></p><h2 id="React-적용-가이드-네이버-메일-모바일-웹-적용기"><a href="#React-적용-가이드-네이버-메일-모바일-웹-적용기" class="headerlink" title="React 적용 가이드 - 네이버 메일 모바일 웹 적용기"></a>React 적용 가이드 - 네이버 메일 모바일 웹 적용기</h2><p><a href="http://d2.naver.com/helloworld/4966453" target="_blank" rel="noopener">http://d2.naver.com/helloworld/4966453</a></p><h2 id="React-Flux-Redux-관련-자료"><a href="#React-Flux-Redux-관련-자료" class="headerlink" title="React, Flux, Redux 관련 자료"></a>React, Flux, Redux 관련 자료</h2><p><a href="http://d2.naver.com/news/7030975" target="_blank" rel="noopener">http://d2.naver.com/news/7030975</a></p><h2 id="Velopert-React-JS-강좌-목록"><a href="#Velopert-React-JS-강좌-목록" class="headerlink" title="Velopert - [React.JS] 강좌 목록"></a>Velopert - [React.JS] 강좌 목록</h2><p><a href="https://velopert.com/reactjs-tutorials" target="_blank" rel="noopener">https://velopert.com/reactjs-tutorials</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;React-적용-가이드-React와-Redux&quot;&gt;&lt;a href=&quot;#React-적용-가이드-React와-Redux&quot; class=&quot;headerlink&quot; title=&quot;React 적용 가이드 - React와 Redux&quot;&gt;&lt;/a&gt;React 적용 
      
    
    </summary>
    
      <category term="자료정리" scheme="https://ddulhddul.github.io/categories/%EC%9E%90%EB%A3%8C%EC%A0%95%EB%A6%AC/"/>
    
      <category term="react" scheme="https://ddulhddul.github.io/categories/%EC%9E%90%EB%A3%8C%EC%A0%95%EB%A6%AC/react/"/>
    
    
      <category term="javascript" scheme="https://ddulhddul.github.io/tags/javascript/"/>
    
      <category term="react" scheme="https://ddulhddul.github.io/tags/react/"/>
    
  </entry>
  
  <entry>
    <title>Chapter8. 딥러닝</title>
    <link href="https://ddulhddul.github.io/2018/03/02/DeepLearning/ml009/"/>
    <id>https://ddulhddul.github.io/2018/03/02/DeepLearning/ml009/</id>
    <published>2018-03-02T06:23:52.000Z</published>
    <updated>2019-06-06T10:04:52.485Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/deeplearning/cover.jpg" alt="밑바닥부터 시작하는 딥러닝"></p><p><a href="https://www.slideshare.net/sunggonSong/8-75266382" target="_blank" rel="noopener">https://www.slideshare.net/sunggonSong/8-75266382</a></p><p><a href="https://books.google.co.kr/books?id=SM9KDwAAQBAJ&amp;pg=PA269&amp;dq=ILSVRC+%EC%B5%9C%EC%9A%B0%EC%88%98+%ED%8C%80+%EC%84%B1%EC%A0%81+%EC%B6%94%EC%9D%B4&amp;hl=ko&amp;sa=X&amp;ved=0ahUKEwigpu6Qn9LZAhWIu7wKHZDOCygQ6AEIJjAA#v=onepage&amp;q=ILSVRC%20%EC%B5%9C%EC%9A%B0%EC%88%98%20%ED%8C%80%20%EC%84%B1%EC%A0%81%20%EC%B6%94%EC%9D%B4&amp;f=false" target="_blank" rel="noopener">https://books.google.co.kr/books?id=SM9KDwAAQBAJ&amp;pg=PA269&amp;dq=ILSVRC+%EC%B5%9C%EC%9A%B0%EC%88%98+%ED%8C%80+%EC%84%B1%EC%A0%81+%EC%B6%94%EC%9D%B4&amp;hl=ko&amp;sa=X&amp;ved=0ahUKEwigpu6Qn9LZAhWIu7wKHZDOCygQ6AEIJjAA#v=onepage&amp;q=ILSVRC%20%EC%B5%9C%EC%9A%B0%EC%88%98%20%ED%8C%80%20%EC%84%B1%EC%A0%81%20%EC%B6%94%EC%9D%B4&amp;f=false</a></p><h4 id="딥러닝-용어사전"><a href="#딥러닝-용어사전" class="headerlink" title="딥러닝 용어사전"></a><a href="https://github.com/tgjeon/Keras-Tutorials/blob/master/DeepLearningGlossary.md" target="_blank" rel="noopener">딥러닝 용어사전</a></h4><p>딥러닝의 특징과 사례, 그리고 가능성</p><h1 id="8-1-더-깊게"><a href="#8-1-더-깊게" class="headerlink" title="8.1 더 깊게"></a>8.1 더 깊게</h1><p>그동안 배운 기술을 집약하고 (CNN과 매개변수 최적화) 신경망을 만들어 MNIST 데이터셋 손글씨 숫자 인식에 도전하자</p><h2 id="8-1-1-더-깊은-신경망으로"><a href="#8-1-1-더-깊은-신경망으로" class="headerlink" title="8.1.1 더 깊은 신경망으로"></a>8.1.1 더 깊은 신경망으로</h2><p><img src="/images/deeplearning/ml009/ml009_01.png" alt="손글씨 숫자를 인식하는 심층 CNN"></p><ul><li>이 신경망의 특징<ul><li>3X3 의 작은 필터를 사용한 합성곱 계층</li><li>활성화 함수는 ReLU</li><li>완전연결 계층 뒤에 드롭아웃 계층 사용</li><li>Adam을 사용해 최적화</li><li>가중치 초깃값은 ‘He의 초깃값’</li></ul></li></ul><p>=&gt; 잘못 인식할 확률이 겨우 0.62% 인 신경망이 탄생</p><p><img src="/images/deeplearning/ml009/ml009_04.png" alt="인식하지 못한 이미지들"><br>=&gt; 사람도 헷갈릴만한 이미지들이다.</p><h2 id="8-1-2-정확도를-더-높이려면"><a href="#8-1-2-정확도를-더-높이려면" class="headerlink" title="8.1.2 정확도를 더 높이려면"></a>8.1.2 정확도를 더 높이려면</h2><ul><li><p>What is the class of this image ?<br><a href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html" target="_blank" rel="noopener">http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html</a></p><iframe src="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html" width="100%" height="300" frameborder="0" allowfullscreen></iframe><ul><li>책에 나온 기법의 정확도 순위(2016년 12월 기점)와 달라진게 없다.</li><li>상위권은 대부분 CNN을 기초로한 기법들</li><li>이 목록의 기법들의 CNN은 그다지 깊지 않다. (합성곱 계층 2개, 완전연결 계층 2개 정도인 신경망)<ul><li>손글씨 숫자라는 문제가 비교적 단순해서 라고 추측</li></ul></li></ul></li></ul><h3 id="데이터-확장"><a href="#데이터-확장" class="headerlink" title="데이터 확장"></a>데이터 확장</h3><p>입력 이미지(훈련 이미지)를 알고리즘으로 인위적으로 확장.<br><img src="/images/deeplearning/ml009/ml009_05.png" alt="데이터 확장의 예"></p><ul><li>이미지 일부를 잘라내는 <strong>crop</strong></li><li>좌우를 뒤집는 <strong>flip</strong> 등이 있다.</li><li>쉬운 트릭이라 생각하지만, 멋진 결과를 가져오는 경우가 많다.</li><li>한번 도전해봐도 좋을듯… ? (찾아보자)<ul><li><a href="https://github.com/keras-team/keras/issues/3338" target="_blank" rel="noopener">https://github.com/keras-team/keras/issues/3338</a></li></ul></li></ul><h2 id="8-1-3-깊게-하는-이유"><a href="#8-1-3-깊게-하는-이유" class="headerlink" title="8.1.3 깊게 하는 이유"></a>8.1.3 깊게 하는 이유</h2><ol><li><p>ILSVRC 로 대표되는 이미지 인식 대회의 결과에서 파악할 수 있다.<br>(찾아보자)</p><ul><li>딥러닝 기반이며, 층의 깊이에 비례해 정확도가 좋아지는 추세</li></ul></li><li><p>신경망의 매개변수 수가 줄어든다.</p><ul><li>깊게한 매개변수가 깊지 않은 경우보다 적은 매개변수로 같은 수준의 표현력을 달성할 수 있다.<br><img src="/images/deeplearning/ml009/ml009_06.png" alt="3X3의 합성곱 계층을 2회 반복한 예"></li><li>작은 필터를 겹쳐 신경망을 깊게 할 때의 장점은, 매개변수 수를 줄여 넓은 <strong>수용 영역</strong>을 소화할 수 있다는 데에 있다.</li><li>게다가 층을 거듭하면서, ReLU등의 활성화 함수를 합성곱 계층 사이에 끼움으로써, 신경망의 표현력이 개선된다.<ul><li>활성화 함수가 신경망에 <strong>비선형</strong> 힘을 가하고, 비선형 함수가 겹치면서 더 복잡한 것도 표현할 수 있게 되기 때문.</li></ul></li></ul></li><li><p>학습의 효율성</p><ul><li>층을 깊게 함으로써, 학습 데이터의 양을 줄여 학습을 고속으로 수행할 수 있다.</li><li>7.6 CNN의 합성곱 계층이 정보를 계층적으로 추출하고 있음을 빌어 보면<br><img src="/images/deeplearning/ml009/ml009_02.png" alt="층 깊이에 따른 정보"><ul><li>에지 등의 단순한 패턴에서 층이 깊어질수록 사물의 일부와 같은 점차 복잡한 것에 반응한다.</li></ul></li><li>ex) 얕은 신경망에서 개를 인식하려면, 합성곱 계층을 개의 특징 대부분을 한번에 이해하여야한다. 하지만 신경망을 깊게하면 학습해야 할 문제를 계층적으로 분해할 수 있다.</li><li>층을 깊게하면 정보를 계층적으로 전달 할 수 있다.<ul><li>에지를 추출한 정보를 다음 층에서 쓰고, 더 고도의 패턴을 효과적으로 학습하는것을 기대할 수 있다.</li></ul></li></ul></li></ol><h1 id="8-2-딥러닝의-초기-역사"><a href="#8-2-딥러닝의-초기-역사" class="headerlink" title="8.2 딥러닝의 초기 역사"></a>8.2 딥러닝의 초기 역사</h1><p>딥러닝이 큰 주목을 받게 된 계기 - ImageNet Large Scale Visual Recognition Competition (ILSVRC)</p><h2 id="8-2-1-이미지넷"><a href="#8-2-1-이미지넷" class="headerlink" title="8.2.1 이미지넷"></a>8.2.1 이미지넷</h2><ul><li>100만장이 넘는 이미지를 담고 있는 데이터셋.</li><li>매년 열리는 ILSVRC는 이 거대 데이터셋을 사용해 자웅을 겨룬다.<br><img src="https://addingtonword.files.wordpress.com/2015/12/20151216-ilsvrc-image.jpg" alt="https://addingtonword.files.wordpress.com/2015/12/20151216-ilsvrc-image.jpg"></li><li>몇가지 종목중 하나가 분류. 1000개의 클래스를 제대로 분류하는지 겨룸.<br><img src="/images/deeplearning/ml009/ml009_03.png" alt="ILSVRC 최우수 팀의 성적 추이"><ul><li>2012년 이후 선두는 항상 딥러닝 방식이었다.</li><li>2012 년 AlexNet이 오류율을 크게 낮췄고…</li><li>2015년에는 150층이 넘는 심층 신경망인 ResNet이 오류율을 3.5% 까지 낮춤 (인간의 인식 능력을 넘어섰다 ?)</li></ul></li><li>유명한 세 신경망에 대한 소개 (VGG, GoogLeNet, ResNet)<br><img src="/images/deeplearning/ml009/ml009_07.png" alt="CNN Architectures"><br>출처 : <a href="https://www.slideshare.net/samchoi7/cnn-tutorial-66719728" target="_blank" rel="noopener">https://www.slideshare.net/samchoi7/cnn-tutorial-66719728</a></li></ul><h2 id="8-2-2-VGG"><a href="#8-2-2-VGG" class="headerlink" title="8.2.2 VGG"></a>8.2.2 VGG</h2><ul><li>A visualization of the VGG architecture<br><img src="https://static.wixstatic.com/media/3c6d20_d485f152a74b4df8b3d4b0bf4484196e~mv2.png/v1/fill/w_658,h_386,al_c,lg_1/3c6d20_d485f152a74b4df8b3d4b0bf4484196e~mv2.png" alt="A visualization of the VGG architecture"><ul><li>비중있는 층(합성곱, 완전연결계층) 을 모두 16 or 19 층으로 심화한게 특징.</li><li>주목할 점은 3X3 의 작은 필터를 사용한 합성곱 계층을 연속으로 거친다는 것.</li><li>합성곱 계층을 2~4회 연속으로 풀링 계층을 두어 크기를 절반으로 줄이는 처리를 반복.</li><li>마지막엔 완전연결 계층을 통과시켜 결과를 출력</li><li>성능면에서 GoogLeNet 에 뒤지지만 구성이 간단하여 응용하기 좋다.</li></ul></li></ul><h2 id="8-2-3-GoogLeNet"><a href="#8-2-3-GoogLeNet" class="headerlink" title="8.2.3 GoogLeNet"></a>8.2.3 GoogLeNet</h2><p><img src="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_5/GoogleNet.png" alt="GoogleNet"><br>  출처 : <a href="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/googlenet.html" target="_blank" rel="noopener">https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/googlenet.html</a></p><ul><li>GoogLeNet에는 가로방향의 폭이 있다. 인셉션 구조. 그 기반구조는 다음과 같다.<br><img src="https://norman3.github.io/papers/images/google_inception/f01.png" alt="GoogLeNet 인셉션 구조"><br>  출처 : <a href="https://norman3.github.io/papers/docs/google_inception.html" target="_blank" rel="noopener">https://norman3.github.io/papers/docs/google_inception.html</a><ul><li>크기가 다른 필터(와 풀링)를 여러개 적용하여 그 결과를 결합.</li><li>인셉션 구조를 하나의 빌딩 블록(구성요소로 사용하는 것이 GoogLeNet의 특징)</li><li>GoogLeNet에서는 1X1 크기의 필터를 사용한 합성곱 계층을 많은 곳에서 사용.<ul><li>채널 쪽으로 크기를 줄이는 것으로, 매개변수 제거와 고속 처리에 기여</li></ul></li></ul></li></ul><h2 id="8-2-4-ResNet"><a href="#8-2-4-ResNet" class="headerlink" title="8.2.4 ResNet"></a>8.2.4 ResNet</h2><ul><li>마이크로소프트의 팀이 개발한 네트워크.</li><li>지금까지보다 층을 더 깊게 할 수 있는 특별한 장치가 있다.</li><li><p>딥러닝은 층을 깊게 하는 것이 성능 향상에 중요하다. 하지만 층이 지나치게 깊으면 학습이 잘 되지 않고, 성능이 오히려 떨어지는데, 이를 해결하기 위해 <strong>스킵 연결</strong>을 도입</p><ul><li>층의 깊이에 비례해 성능을 향상 시킬 수 있는 핵심 요소.<br><img src="/images/deeplearning/ml009/ml009_08.png" alt="스킵 연결"><ul><li>weight layer 는 합성곱 계층을 말함.</li><li>두 합성곱 계층을 뛰어넘어 스킵 연결로 인해 <strong>F(x)+x</strong> 가 되는게 핵심.</li><li>이는 역전파 때 스킵 연결이 신호 감쇠를 막아주기 때문에 학습이 효율적으로 가능하다.</li><li>스킵 연결로 기울기가 작아지거나 지나치게 커질 걱정 없이 <strong>앞 층의 의미 있는 기울기</strong>가 전해지리라 기대할 수 있다.</li></ul></li></ul></li><li><p>ResNet<br><img src="https://2.bp.blogspot.com/-J7j0eUkNJ-w/WPU7iXKs6II/AAAAAAAAJt0/FMY6pOVMu34y2TziHnVPbadohKim1XpKACLcB/s640/resnet_vs_plainnet.png" alt="ResNet"><br> 출처 : <a href="http://alimurreza.blogspot.kr/2017/04/deep-residual-network-resnet.html" target="_blank" rel="noopener">http://alimurreza.blogspot.kr/2017/04/deep-residual-network-resnet.html</a></p><ul><li>합성곱 계층을 2개 층마다 건너뛰면서 층을 깊게 학습한다.</li></ul></li><li>전이 학습?<ul><li>이미지넷이 제공하는 거대한 데이터셋으로 학습한 가중치 결과를 실제 제품에 활용하기도 함.</li><li>미리 학습된 가중치를 초기 값으로 설정하고 새로운 데이터셋을 대상으로 재학습을 수행.</li></ul></li></ul><h1 id="8-3-더-빠르게-딥러닝-고속화"><a href="#8-3-더-빠르게-딥러닝-고속화" class="headerlink" title="8.3 더 빠르게(딥러닝 고속화)"></a>8.3 더 빠르게(딥러닝 고속화)</h1><ul><li>CPU만으로는 처리하기 부족한 계산을 GPU를 활용해 고속으로 처리할 수 있다.</li><li>최근 프레임워크에선 학습을 복수의 GPU와 여러 기기로 분산 수행.</li></ul><h2 id="8-3-1-풀어야-할-숙제"><a href="#8-3-1-풀어야-할-숙제" class="headerlink" title="8.3.1 풀어야 할 숙제"></a>8.3.1 풀어야 할 숙제</h2><ul><li>AlexNet 각 층의 시간 비율<br><img src="/images/deeplearning/ml009/ml009_09.png" alt="AlexNet 각 층의 시간 비율"><ul><li>오랜 시간을 합성곱 계층에서 소요한다. (GPU 전체의 95%, CPU 전체의 89%)</li><li>합성곱 계층을 결국 단일 곱셈 누산이다. 즉, 딥러닝 고속화는 단일 곱셈 누산을 어떻게 효율적으로 개선하느냐가 관건이다.</li></ul></li></ul><h2 id="8-3-2-GPU를-활용한-고속화"><a href="#8-3-2-GPU를-활용한-고속화" class="headerlink" title="8.3.2 GPU를 활용한 고속화"></a>8.3.2 GPU를 활용한 고속화</h2><ul><li><p>GPU는 병렬 수치 연산을 고속으로 처리할 수 있다.</p><ul><li>ex) 합성곱 계층에서 행하는 im2col<br><img src="https://static.wixstatic.com/media/5dad68_a7c45717c03c45638b91608b90db7e1f~mv2.png/v1/fill/w_945,h_588,al_c,usm_0.66_1.00_0.01/5dad68_a7c45717c03c45638b91608b90db7e1f~mv2.png" alt="AlexNet 학습 시간 비교"></li><li>CPU에서는 40여일이 걸리지만, GPU로는 6일까지 단축.</li><li>cuDNN 딥ㅁ러닝 최적화 라이브러리를 사용하면 더욱 빨라짐.</li></ul></li><li><p>GPU는 엔비디아와 AMD 두 회사가 제공. 대부분 딥러닝 프레임워큰느 엔비디아 GPU에서 혜택을 받을 수 있다. </p><ul><li>CUDA 라는 엔비디아의 GPU컴퓨팅용 통합 개발 환경을 사용.</li><li>cuDNN 은 CUDA 위에서 동작하는 라이브러리.</li></ul></li></ul><h2 id="8-3-3-분산-학습"><a href="#8-3-3-분산-학습" class="headerlink" title="8.3.3 분산 학습"></a>8.3.3 분산 학습</h2><ul><li>뛰어난 신경망을 위해 시험을 수없이 반복해야하고, 1회 학습에 걸리는 시간을 단축해야한다. // 딥러닝 학습의 수평확장이 필요</li><li><p>다수의 GPU와 컴퓨터를 이용한 분산 학습을 지원한 딥러닝 프레임워크들이 나타나고 있다.</p><ul><li>상위 10가지 딥러닝 프레임워크 (<a href="https://www.nextobe.com/single-post/2017/08/01/%EC%83%81%EC%9C%84-10%EA%B0%80%EC%A7%80-%EB%94%A5%EB%9F%AC%EB%8B%9D-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC" target="_blank" rel="noopener">https://www.nextobe.com/single-post/2017/08/01/%EC%83%81%EC%9C%84-10%EA%B0%80%EC%A7%80-%EB%94%A5%EB%9F%AC%EB%8B%9D-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC</a>)</li><li><p><a href="https://www.slideshare.net/JunyiSong1/ss-75552936" target="_blank" rel="noopener">딥러닝 프레임워크 비교</a></p><iframe src="https://www.nextobe.com/single-post/2017/08/01/%EC%83%81%EC%9C%84-10%EA%B0%80%EC%A7%80-%EB%94%A5%EB%9F%AC%EB%8B%9D-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC" width="100%" height="300" frameborder="0" allowfullscreen></iframe></li></ul></li><li><p>텐서플로우 분산 학습 성능<br><img src="https://tensorflowkorea.files.wordpress.com/2016/04/image00.png?w=625" alt="텐서플로우 분산 학습 성능"></p><ul><li>100개를 사용하니 하나일때보다 56배 빨라짐.</li><li>하지만 어떻게 분산시키느냐도 어려운 문제.<ul><li>컴퓨터사이 통신과 동기화 등</li></ul></li></ul></li></ul><h2 id="8-3-4-연산-정밀도와-비트-줄이기"><a href="#8-3-4-연산-정밀도와-비트-줄이기" class="headerlink" title="8.3.4 연산 정밀도와 비트 줄이기"></a>8.3.4 연산 정밀도와 비트 줄이기</h2><ul><li>메모리 용량과 버스 대역폭 등이 병목이 될 수 있다.</li><li>따라서 네트워크로 주고 받는 데이터의 비트 수는 최소로 만드는것이 바람직.</li><li>딥러닝은 높은수치의 정확도를 요구하지 않으므로. 데이터를 퇴화시켜도 출력에 주는 영향이 적다.</li><li>컴퓨터는 32비트 단정밀도, 64비트 배정밀도 등의 포맷이 있지만, 딥러닝은 <strong>16비트 반정밀도</strong>만 사용해도 학습에 문제가 없다고 알려져 있다.<ul><li>엔비디아의 최신 GPU인 <strong>파스칼 아키텍처</strong>는 이 포맷을 지원.</li></ul></li><li>딥러닝 고속화 하기 위해 비트 수를 줄이는 연구는 계속 주시해야 한다.<ul><li>참고<ul><li>2016-04-08 <a href="http://www.techholic.co.kr/news/articleView.html?idxno=51874" target="_blank" rel="noopener">엔비디아 파스칼 아키텍처…달라진 5가지 포인트</a></li><li>2017-05-11 <a href="http://www.bodnara.co.kr/bbs/article.html?num=140148" target="_blank" rel="noopener">파스칼보다 5배 빠르다? NVIDIA 볼타(Volta) 아키텍처 발표</a></li></ul></li></ul></li></ul><h1 id="8-4-딥러닝의-활용"><a href="#8-4-딥러닝의-활용" class="headerlink" title="8.4 딥러닝의 활용"></a>8.4 딥러닝의 활용</h1><p>우리가 지금까지 본 손글씨 숫자 인식 외에도 온갖 문제에 적용할 수 있다.</p><h2 id="8-4-1-사물-검출"><a href="#8-4-1-사물-검출" class="headerlink" title="8.4.1 사물 검출"></a>8.4.1 사물 검출</h2><ul><li>이미지 속에 담긴 사물의 위치와 종류를 알아내는 기술.</li><li>사물 인식보다 어려운 문제다. 어딘가에 있을 사물의 위치를 잡아내야 하고 여러 사물이 존재할 수 있음.</li><li>CNN 을 이용한 <strong>R-CNN</strong> 이 유명하다.</li></ul><h3 id="참고-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks"><a href="#참고-Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks" class="headerlink" title="참고 Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"></a>참고 <a href="https://jamiekang.github.io/2017/05/28/faster-r-cnn/" target="_blank" rel="noopener">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a></h3><ul><li>R-CNN<br><img src="https://tensorflowkorea.files.wordpress.com/2017/06/0sdj6skdrqyzpo6oh.png?w=6254" alt="R-CNN의 처리 흐름"><ul><li>Regional Proposal + CNN</li><li>Regional proposal을 얻기 위해 selective search 사용</li><li>CNN을 사용한 첫 번째 object detection method</li><li>각 proposal을 독립적으로 계산 (= 많은 계산 필요)</li><li>Bounding box regression으로 detection 정확도 향상</li></ul></li><li>Fater R-CNN<br><img src="https://jamiekang.github.io/media/2017-05-27-faster-r-cnn-fast-r-cnn-concept.jpg" alt="Fater R-CNN의 처리 흐름"><ul><li>같은 image의 proposal들이 convolution layer를 공유</li><li>ROI Pooling 도입</li><li>전체 network이 End-to-end로 한 번에 학습</li><li>R-CNN보다 빠르고 더 정확한 결과</li></ul></li></ul><h2 id="8-4-2-분할"><a href="#8-4-2-분할" class="headerlink" title="8.4.2 분할"></a>8.4.2 분할</h2><ul><li>이미지를 픽셀 수준에서 분류하는 문제.</li><li>단위로 객체마다 채색된 지도 데이터를 사용해 학습.</li><li>분할의 가장 단순한 방법은 모든 픽셀 각각을 추론하는 방법이지만, 긴 시간이 걸리므로,(합성곱 연산에서 많은 영역을 쓸데없이 다시 계산) 낭비를 줄여주는 <strong>FCN</strong> 이 고안됨.<br><img src="https://cdn-images-1.medium.com/max/632/1*wRkj6lsQ5ckExB5BoYkrZg.png" alt="이미지 분할 딥러닝"><ul><li>합성곱 계층으로만 구성된 네트워크</li><li>사물 인식에서 사용한 신경망의 완전연결 계층에서는 중간 데이터의 공간 볼륨을 1차원으로 변환하여 한줄로 늘어선 노드들이 처리했으나, FCN에서는 공간 볼륨을 유지한 채 마지막 출력까지 처리할 수 있다.</li><li>마지막에 공간 크기를 확대하는 처리를 도입했따는 것도 특징임.</li><li>완전 연결계층을 같은 기능을 하는 합성곱 계층으로 바꾼다 ??? (찾아보자)</li></ul></li></ul><h2 id="8-4-3-사진-캡션-생성"><a href="#8-4-3-사진-캡션-생성" class="headerlink" title="8.4.3 사진 캡션 생성"></a>8.4.3 사진 캡션 생성</h2><ul><li>NIC 모델이 대표적이다.<br><img src="http://cfile28.uf.tistory.com/image/2263994E5486AC6D0D8726" alt="NIC 모델"><ul><li>심층 CNN과 자연어를 다루는 순환 신경망으로 구성된다.</li><li>CNN으로 사진 특징을 추출하고, 특징을 RNN으로 넘긴다.</li><li>RNN은 특징을 바탕으로 순환적으로 텍스트를 생성.<ul><li>RNN은 이전에 생성한 정보에 영향을 받는다.</li><li>RNN 은 과거의 정보를 기억하면서 동작한다.</li></ul></li></ul></li><li><p>이미지 캡션 생성 사례<br><img src="https://image.slidesharecdn.com/20170629osiafinal-170712023316/95/deep-learning-47-638.jpg?cb=1499826964" alt="이미지 캡션 생성 사례"></p></li><li><p>자연어와 같은 여러 종류의 정보를 조합하고 처리하는 것을 <strong>멀티모달 처리</strong>라고 하여 최근 주목받는 다는데 … ? (찾아보자)</p></li></ul><h1 id="8-5-딥러닝의-미래"><a href="#8-5-딥러닝의-미래" class="headerlink" title="8.5 딥러닝의 미래"></a>8.5 딥러닝의 미래</h1><h2 id="8-5-1-이미지-스타일-화풍-변환"><a href="#8-5-1-이미지-스타일-화풍-변환" class="headerlink" title="8.5.1 이미지 스타일(화풍) 변환"></a>8.5.1 이미지 스타일(화풍) 변환</h2><p>두 이미지를입력해서 새로운 그림을 생성하는 연구. 하나는 콘텐츠 이미지, 하나는 스타일 이미지<br><img src="http://sanghyukchun.github.io/images/post/92-1.jpg" alt="이미지 스타일(화풍) 변환"></p><ul><li>네트워크의 중간 데이터가 콘텐츠 이미지의 중간 데이터와 비슷해지도록 학습한다. 이를 통해, 입력 이미지로 콘텐츠 이미지의 형태를 흉내낼 수 있다.</li></ul><h2 id="8-5-2-이미지-생성"><a href="#8-5-2-이미지-생성" class="headerlink" title="8.5.2 이미지 생성"></a>8.5.2 이미지 생성</h2><p>앞의 예와 달리, 아무런 입력 이미지 없이 새로운 이미지를 그려내는 연구, 대량의 이미지를 사용하여 먼저 학습이 필요</p><ul><li><strong>DCGAN</strong> (Deep Convolutional Generative Adversarial Network) 기법<ul><li>Alec Radford의 DCGAN 논문 에서 가져온 사진<br><img src="https://cdn-images-1.medium.com/max/640/1*n63ADMch0NU4RxLDt04rHA.png" alt="https://cdn-images-1.medium.com/max/640/1*n63ADMch0NU4RxLDt04rHA.png"></li><li>기술의 핵심은, 생성자와 식별자로 불리는 2개의 신경망을 이용하는 것.<ul><li>생성자는 진짜와 똑같은 이미지를 생성하고 식별자는 그것이 진짜인지(생성한것인지 찍은것인지) 판별한다.</li><li>둘의 능력을 부지런히 갈고닦게 하는것이 <strong>GAN</strong> (Generative Adversarial Network) 기술</li><li>지금까지의 input 데이터돠 정답 레이블을 짝지은 <strong>지도학습</strong> 과는 달리, 스스로 학습하는 <strong>자율학습</strong> 문제이다.<ul><li>Deep Belief Network</li><li>Deep Boltzmann Machine</li></ul></li></ul></li></ul></li></ul><h2 id="8-5-3-자율-주행"><a href="#8-5-3-자율-주행" class="headerlink" title="8.5.3 자율 주행"></a>8.5.3 자율 주행</h2><ul><li>SegNet :  주변 환경을 인식하는 CNN 기반 신경망<br><img src="http://mi.eng.cam.ac.uk/projects/segnet/images/CamVidTeaserwithIndoorScenes.jpg" alt="http://mi.eng.cam.ac.uk/projects/segnet/images/CamVidTeaserwithIndoorScenes.jpg"></li></ul><h2 id="8-5-4-Deep-Q-Network-강화학습"><a href="#8-5-4-Deep-Q-Network-강화학습" class="headerlink" title="8.5.4 Deep Q-Network(강화학습)"></a>8.5.4 Deep Q-Network(강화학습)</h2><ul><li>에이전트라는 것이 환경에 맞게 행동을 선택하고, 행동에 의해서 환경이 변한다는게 기본적인 틀.</li><li>강화 학습의 목적은 에이전트의 행동 지침을 더 나은 보상을 받는 쪽으로 바로잡는 것.</li><li>강화 학습의 기본 틀<br><img src="https://raw.githubusercontent.com/torch/torch.github.io/master/blog/_posts/images/action-perception.png" alt="강화 학습의 기본 틀"><ul><li>정해진 보상이 아니라, 예상 보상이다.</li><li>명확한 지표로부터 역산해서 예상 보상을 정해야 한다.</li></ul></li><li>Deep Q-Network<ul><li>Q 학습이라는 강화학습 알고리즘을 기초로 함.</li><li>[Q Learning][<a href="https://ko.wikipedia.org/wiki/Q_%EB%9F%AC%EB%8B%9D]" target="_blank" rel="noopener">https://ko.wikipedia.org/wiki/Q_%EB%9F%AC%EB%8B%9D]</a><iframe src="https://ko.wikipedia.org/wiki/Q_%EB%9F%AC%EB%8B%9D" width="100%" height="300" frameborder="0" allowfullscreen></iframe></li><li>최적 행동 가치 함수로 최적인 행동을 정한다.</li><li>이 함수를 딥러닝(CNN)으로 비슷하게 흉내 내어 사용하는 것이 DQN<br><img src="http://cfile23.uf.tistory.com/image/275B523D589EE0131CA4B5" alt="Deep Q-Network"></li><li>그동안의 비디오 게임 학습과 다르게, 게임의 상태를 추출하는 것이 아닌 비디오 게임의 영상만을 입력 데이터로하여 학습한다. 수많은 게임에서 사람보다 뛰어난 성적을 거두고 있다고 하는데 … ?? (찾아보자)</li></ul></li><li>알파고에도 딥러닝과 강화학습이 이용되었다. 이들 모두 구글이 인수한 딥마인드가 진행한 연구라고 한다.<ul><li><a href="https://namu.wiki/w/%EA%B5%AC%EA%B8%80%20%EB%94%A5%EB%A7%88%EC%9D%B8%EB%93%9C" target="_blank" rel="noopener">구글 딥마인드 - 나무위키</a><iframe src="https://namu.wiki/w/%EA%B5%AC%EA%B8%80%20%EB%94%A5%EB%A7%88%EC%9D%B8%EB%93%9C" width="100%" height="300" frameborder="0" allowfullscreen></iframe></li></ul></li></ul><h1 id="이번-장에서-배운-것"><a href="#이번-장에서-배운-것" class="headerlink" title="이번 장에서 배운 것"></a>이번 장에서 배운 것</h1><ul><li>수많은 문제에서 신경망을 더 깊게 하여 성능을 개선할 수 있다.</li><li>이미지 인식 기술 대회인 ILSVRC에서는 최근 딥러닝 기반 기법이 상위권을 독점하고 있으며, 그 깊이도 더 깊어지는 추세다.</li><li>유명한 신경망으로는 VGG, GoogLeNet, ResNet이 있다.</li><li>GPU와 분산 학습, 비트 정밀도 감소 등으로 딥러닝을 고속화할 수 있다.</li><li>딥러닝(신경망)은 사물 인식뿐 아니라 삼루검출과 분할에도 이용할 수 있다.</li><li>딥러닝의 응용 분야로는 사진의 갭션 생성, 이미지 생성, 강화학습 등이 있다. 쵝느에는 자율 주행에도 딥러닝을 접목하고 있어 기대된다.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/deeplearning/cover.jpg&quot; alt=&quot;밑바닥부터 시작하는 딥러닝&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.slideshare.net/sunggonSong/8-75266382&quot; target
      
    
    </summary>
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/categories/DeepLearning/"/>
    
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/tags/DeepLearning/"/>
    
      <category term="밑바닥부터 시작하는 딥러닝" scheme="https://ddulhddul.github.io/tags/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D/"/>
    
  </entry>
  
  <entry>
    <title>Chapter4. 신경망 학습</title>
    <link href="https://ddulhddul.github.io/2018/01/28/DeepLearning/ml003/"/>
    <id>https://ddulhddul.github.io/2018/01/28/DeepLearning/ml003/</id>
    <published>2018-01-28T10:23:52.000Z</published>
    <updated>2018-02-12T13:10:28.470Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/deeplearning/cover.jpg" alt="밑바닥부터 시작하는 딥러닝"></p><h1 id="4-1-데이터에서-학습한다"><a href="#4-1-데이터에서-학습한다" class="headerlink" title="4.1 데이터에서 학습한다!"></a>4.1 데이터에서 학습한다!</h1><ul><li>가중치 매개변수의 값을 데이터를 보고 자동으로 결정</li></ul><h2 id="4-1-1-데이터-주도-학습"><a href="#4-1-1-데이터-주도-학습" class="headerlink" title="4.1.1 데이터 주도 학습"></a>4.1.1 데이터 주도 학습</h2><ul><li>신경망돠 딥러닝은 기존 기계학습에서 사용하던 방법보다 사람의 개입을 더욱 배제할 수 있게 해주는 중요한 특성을 지님.</li><li>이미지에서 특징을 추출하고 특징의 패턴을 기계학습 기술로 학습</li><li>이미지의 특징은 보통 벡터로 기술</li><li>다만, 이미지를 벡터로 변환할 때 사용하는 특징은 여전히 사람이 설계</li></ul><p><img src="/images/deeplearning/chapter4.01paradigm.PNG" alt="Paradigm"></p><blockquote><p>회색은 사람이 개입하지 않음.<br>딥러닝을 종단간 기계학습 이라고도 한다. (처음부터 끝까지)</p></blockquote><h2 id="4-1-2-훈련-데이터와-시험-데이터"><a href="#4-1-2-훈련-데이터와-시험-데이터" class="headerlink" title="4.1.2 훈련 데이터와 시험 데이터"></a>4.1.2 훈련 데이터와 시험 데이터</h2><ul><li>기계학습의 문제는 훈련 데이터와 시험 데이터를 나눠 실험을 수행하는 것.<ul><li>범용적으로 사용할 수 있는 모델을 원하기 때문.</li><li>범용 능력을 제대로 평가하기 위해 훈련 데이터와 시험 데이터를 분리.</li></ul></li><li>데이터셋 하나에만 지나치게 최적화되어 오버피팅 된 상태가 벌어지기도 한다.</li></ul><h1 id="4-2-손실-함수"><a href="#4-2-손실-함수" class="headerlink" title="4.2 손실 함수"></a>4.2 손실 함수</h1><ul><li>신경망 학습에서 현재의 상태를 하나의 지표로 표현한다.</li><li>신경망 학습에서 사용하는 지표는 <strong>손실 함수</strong> (loss function) 라고 한다.<ul><li>일반적으로 평균 제곱 오차와 교차 엔트로피 오차를 사용.</li></ul></li></ul><blockquote><p>손실함수는 신경망의 성능의 나쁨을 나타내는 지표이다. 손실 함수에 마이너스를 곱하면 얼마나 좋으냐 라는 지표로 변한다. 성능의 나쁨과 좋음중 어느쪽을 지표로 삼아도 본질적으로 같다.</p></blockquote><h2 id="4-2-1-평균-제곱-오차"><a href="#4-2-1-평균-제곱-오차" class="headerlink" title="4.2.1 평균 제곱 오차"></a>4.2.1 평균 제곱 오차</h2><p>mean squared error, MSE</p><p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e258221518869aa1c6561bb75b99476c4734108e" alt="MSE 함수"></p><blockquote><p>Yi : 신경망의 출력(신경망이 추정한 값)<br>Y^i : 정답 레이블<br>i : 데이터의 차원 수</p></blockquote><p>출처 : <a href="https://en.wikipedia.org/wiki/Mean_squared_error" target="_blank" rel="noopener">위키백과</a></p><p>책에 나온 MSE 함수와 위키에 나온 함수가 다르다 ?</p><ul><li>평균 제곱 오차를 기준으로 오차가 더 작은 값이 정답에 더 가까운 것.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mean_squared_error</span><span class="params">(y,t)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0.5</span> * np.sum((y-t)**<span class="number">2</span>)</span><br></pre></td></tr></table></figure><h2 id="4-2-2-교차-엔트로피-오차"><a href="#4-2-2-교차-엔트로피-오차" class="headerlink" title="4.2.2 교차 엔트로피 오차"></a>4.2.2 교차 엔트로피 오차</h2><p>cross entropy error, CEE</p><p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0cb6da032ab424eefdca0884cd4113fe578f4293" alt="CEE 함수"></p><blockquote><p>q(x) : 신경망의 출력<br>p(x) : 정답 레이블</p></blockquote><p>출처 : <a href="https://en.wikipedia.org/wiki/Cross_entropy" target="_blank" rel="noopener">위키백과</a></p><ul><li>실질적으로 정답일때의 추정의 자연로그를 계산하는 식이 된다.</li><li>교차엔트로피 오차는 정답일 때의 출력이 전체 값을 정한다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_entropy_error</span><span class="params">(y,t)</span>:</span></span><br><span class="line">    delta = <span class="number">1e-7</span></span><br><span class="line">    <span class="keyword">return</span> -np.sum(t * np.log(y+delta))</span><br></pre></td></tr></table></figure><blockquote><p>아주작은 값인 delta 를 더하는 이유는 np.log 에 0을 입력하면 마이너스 무한대로 가기때문.</p></blockquote><h2 id="4-2-3-미니배치-학습"><a href="#4-2-3-미니배치-학습" class="headerlink" title="4.2.3 미니배치 학습"></a>4.2.3 미니배치 학습</h2><p>기계학습은 훈련데이터를 사용해 학습을 해야하는것. 훈련데이터 모두에 대한 손실 함수의 합을 구하자</p><p>빅 데이터 수준이 되면, 손실 함수의 합을 구하는데 시간이 걸린다. 따라서 근사치를 이용. (미니배치)</p><ul><li>미니배치 예 (MNIST)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys, os</span><br><span class="line">sys.path.append(os.pardir)</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> dataset.mnist <span class="keyword">import</span> load_mnist</span><br><span class="line"></span><br><span class="line"><span class="comment"># batch size 만큼 랜덤 추출</span></span><br><span class="line">train_size = x_train.shape[<span class="number">0</span>]</span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line">batch_mask = np.random.choice(train_size, batch_size)</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; np.random.choice(60000, 8)</span></span><br><span class="line"><span class="comment"># array([8013, 14666, 5777, 12351, 12352, 1235, 3463 ,347])</span></span><br><span class="line"></span><br><span class="line">x_batch = x_train[batch_mask]</span><br><span class="line">t_batch = t_train[batch_mask]</span><br><span class="line"></span><br><span class="line">(x_batch, t_batch), (x_test, t_text) = load_mnist(normalize=<span class="keyword">True</span>, one_hot_label=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">print(x_train.shape) <span class="comment"># (60000, 784)</span></span><br><span class="line">print(t_train.shape) <span class="comment"># (60000, 10)</span></span><br></pre></td></tr></table></figure><h2 id="4-2-4-배치용-교차-엔트로피-오차-구현하기"><a href="#4-2-4-배치용-교차-엔트로피-오차-구현하기" class="headerlink" title="4.2.4 (배치용) 교차 엔트로피 오차 구현하기"></a>4.2.4 (배치용) 교차 엔트로피 오차 구현하기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_entropy_error</span><span class="params">(y,t)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> y.dim == <span class="number">1</span>:</span><br><span class="line">        t = t.reshape(<span class="number">1</span>, t.size)</span><br><span class="line">        y = y.reshape(<span class="number">1</span>, y.size)</span><br><span class="line"></span><br><span class="line">    batch_size = y.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># one_hot_label</span></span><br><span class="line">    <span class="keyword">return</span> -np.sum(t * np.log(y)) / batch_size</span><br><span class="line">    <span class="comment"># else</span></span><br><span class="line">    <span class="keyword">return</span> -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size</span><br></pre></td></tr></table></figure><h2 id="4-2-5-왜-손실-함수를-설정하는가"><a href="#4-2-5-왜-손실-함수를-설정하는가" class="headerlink" title="4.2.5 왜 손실 함수를 설정하는가 ?"></a>4.2.5 왜 손실 함수를 설정하는가 ?</h2><p>신경망 학습에서는 최적의 매개변수(가중치, 편향)를 탐색할 때 손실 함수의 값을 가능한 한 작게 하는 매개변수 값을 찾는다. 이때 매개변수의 미분을 계산하고, 그 미분 값을 단서로 매개변수의 값을 서서히 갱신하는 과정을 반복한다.</p><p>가중치 매개변수의 손실 함수의 미분이란, ‘가중치 매개변수의 값을 아주 조금 변화시켰을 때, 손실 함수가 어떻게 변하냐’</p><blockquote><p>신경망을 학습할 때 정확도를 지표로 삼아서는 안된다. 정확도를 지표로 하면 매개변수의 미분이 대부분의 장소에서 0이 되기 때문이다.</p></blockquote><p>신경망 학습에서 중요한 성질로, 기울기가 0이 되지 않는것. (시그모이드 함수)</p><h1 id="4-3-수치-미분"><a href="#4-3-수치-미분" class="headerlink" title="4.3 수치 미분"></a>4.3 수치 미분</h1><h2 id="4-3-1-미분"><a href="#4-3-1-미분" class="headerlink" title="4.3.1 미분"></a>4.3.1 미분</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 나쁜 구현의 예</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">numerical_diff</span><span class="params">(f,x)</span>:</span></span><br><span class="line">    h = <span class="number">10e-50</span></span><br><span class="line">    <span class="keyword">return</span> (f(x+h) -f(x)) /h</span><br></pre></td></tr></table></figure><ul><li>h에 가능한 작은 값을 사용했으므로, 반올림 오차 문제를 야기한다.</li><li>함수의 차분에 대한 문제. 무한히 0으로 좁히는데는 한계가 있다.</li><li>전후의 차분을 계산하는 중심차분으로의 구현</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">numerical_diff</span><span class="params">(f,x)</span>:</span></span><br><span class="line">    h = <span class="number">1e-4</span> <span class="comment"># 0.0001</span></span><br><span class="line">    <span class="keyword">return</span> (f(x+h) -f(x-h)) / (<span class="number">2</span>*h)</span><br></pre></td></tr></table></figure><h2 id="4-3-2-수치-미분의-예"><a href="#4-3-2-수치-미분의-예" class="headerlink" title="4.3.2 수치 미분의 예"></a>4.3.2 수치 미분의 예</h2><h2 id="4-3-3-편미분"><a href="#4-3-3-편미분" class="headerlink" title="4.3.3 편미분"></a>4.3.3 편미분</h2><p>변수가 여럿인 함수에 대한 미분</p><p>변수중 하나의 변수에 초점을 맞추고 다른 변수의 값은 고정하여 편미분의 값을 구할 수 있다.</p><h1 id="4-4-기울기"><a href="#4-4-기울기" class="headerlink" title="4.4 기울기"></a>4.4 기울기</h1><p>모든 변수의 편미분을 벡터로 정리한 것을 <strong>기울기</strong> 라고 한다.</p><h1 id="작성중"><a href="#작성중" class="headerlink" title="작성중"></a>작성중</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/deeplearning/cover.jpg&quot; alt=&quot;밑바닥부터 시작하는 딥러닝&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;4-1-데이터에서-학습한다&quot;&gt;&lt;a href=&quot;#4-1-데이터에서-학습한다&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/categories/DeepLearning/"/>
    
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/tags/DeepLearning/"/>
    
      <category term="밑바닥부터 시작하는 딥러닝" scheme="https://ddulhddul.github.io/tags/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D/"/>
    
  </entry>
  
  <entry>
    <title>Jupyter Test</title>
    <link href="https://ddulhddul.github.io/2018/01/28/DeepLearning/ml005/"/>
    <id>https://ddulhddul.github.io/2018/01/28/DeepLearning/ml005/</id>
    <published>2018-01-28T10:23:52.000Z</published>
    <updated>2019-06-06T10:04:52.485Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential, Model</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Dense, Activation, BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD, Adagrad, RMSprop, Adam</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l2</span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련셋과 시험셋 로딩</span></span><br><span class="line">(X_train, Y_train), (X_test, Y_test) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련셋과 검증셋 분리</span></span><br><span class="line">X_val = X_train[<span class="number">50000</span>:]</span><br><span class="line">Y_val = Y_train[<span class="number">50000</span>:]</span><br><span class="line">X_train = X_train[:<span class="number">50000</span>]</span><br><span class="line">Y_train = Y_train[:<span class="number">50000</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">## 나누기 연산이 들어가므로 uint8 -&gt; float32로 변경</span></span><br><span class="line"><span class="comment">## preprocessing (feature scaling)</span></span><br><span class="line">X_train = X_train.reshape(<span class="number">50000</span>, <span class="number">784</span>).astype(<span class="string">'float32'</span>) / <span class="number">255.0</span></span><br><span class="line">X_val = X_val.reshape(<span class="number">10000</span>, <span class="number">784</span>).astype(<span class="string">'float32'</span>) / <span class="number">255.0</span></span><br><span class="line">X_test = X_test.reshape(<span class="number">10000</span>, <span class="number">784</span>).astype(<span class="string">'float32'</span>) / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>).astype(<span class="string">'float32'</span>) </span><br><span class="line">X_val = X_val.reshape(X_val.shape[<span class="number">0</span>], <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>).astype(<span class="string">'float32'</span>) </span><br><span class="line">X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>).astype(<span class="string">'float32'</span>) </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련셋, 검증셋 고르기</span></span><br><span class="line">train_rand_idxs = np.random.choice(<span class="number">50000</span>, <span class="number">700</span>)</span><br><span class="line">val_rand_idxs = np.random.choice(<span class="number">10000</span>, <span class="number">300</span>)</span><br><span class="line"></span><br><span class="line">X_train = X_train[train_rand_idxs]</span><br><span class="line">Y_train = Y_train[train_rand_idxs]</span><br><span class="line">X_val = X_val[val_rand_idxs]</span><br><span class="line">Y_val = Y_val[val_rand_idxs]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 라벨링 전환</span></span><br><span class="line"><span class="comment"># convert class vectors </span></span><br><span class="line"><span class="comment"># Lable의 categorical 값을 One-hot 형태로 변환 </span></span><br><span class="line"><span class="comment"># 예를 들어 [1, 3, 2, 0] 를 </span></span><br><span class="line"><span class="comment"># [[ 0., 1., 0., 0.], </span></span><br><span class="line"><span class="comment"># [ 0., 0., 0., 1.], </span></span><br><span class="line"><span class="comment"># [ 0., 0., 1., 0.], </span></span><br><span class="line"><span class="comment"># [ 1., 0., 0., 0.]] </span></span><br><span class="line"><span class="comment"># 로 변환하는 것을 One-hot 형태라고 함</span></span><br><span class="line">Y_train = np_utils.to_categorical(Y_train)</span><br><span class="line">Y_val = np_utils.to_categorical(Y_val)</span><br><span class="line">Y_test = np_utils.to_categorical(Y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 모델 구성하기</span></span><br><span class="line"><span class="comment"># 2.1) sequential 모델</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Conv2D(<span class="number">6</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>,input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>), padding=<span class="string">'same'</span>, strides=(<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(BatchNormalization())</span><br><span class="line">model.add(Conv2D(<span class="number">6</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>, strides=(<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">84</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 모델 엮기</span></span><br><span class="line">modified_optimizer = Adam(lr=<span class="number">0.005</span>)</span><br><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=modified_optimizer, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"><span class="comment"># model.compile(loss='mean_squared_error', optimizer=modified_optimizer, metrics=['accuracy'])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 모델 학습시키기</span></span><br><span class="line">tb_hist = keras.callbacks.TensorBoard(log_dir=<span class="string">'./graph'</span>, histogram_freq=<span class="number">0</span>, write_graph=<span class="keyword">True</span>, write_images=<span class="keyword">True</span>)</span><br><span class="line">model.fit(X_train, Y_train, epochs=<span class="number">20</span>, batch_size=<span class="number">10</span>, validation_data=(X_val, Y_val), callbacks=[tb_hist])</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight python&quot;&gt;&lt;figcaption&gt;&lt;span&gt;python&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;
      
    
    </summary>
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/categories/DeepLearning/"/>
    
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/tags/DeepLearning/"/>
    
      <category term="밑바닥부터 시작하는 딥러닝" scheme="https://ddulhddul.github.io/tags/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D/"/>
    
  </entry>
  
  <entry>
    <title>Chapter3. 신경망</title>
    <link href="https://ddulhddul.github.io/2018/01/21/DeepLearning/ml002/"/>
    <id>https://ddulhddul.github.io/2018/01/21/DeepLearning/ml002/</id>
    <published>2018-01-21T10:23:52.000Z</published>
    <updated>2019-06-06T10:04:52.484Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/deeplearning/cover.jpg" alt="밑바닥부터 시작하는 딥러닝"></p><ul><li>설치 내용<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; python -m pip install --upgrade pip</span><br><span class="line">&gt; pip install six</span><br><span class="line">&gt; pip install python-dateutil</span><br><span class="line">&gt; pip install pyparsing</span><br><span class="line">&gt; pip install numpy-1.14.0+mkl-cp36-cp36m-win32.whl</span><br><span class="line">&gt; pip install matplotlib-2.1.2-cp36-cp36m-win32.whl</span><br></pre></td></tr></table></figure></li></ul><p>신경망은 가중치 설정을 수동으로 하던 퍼셉트론에서 벗어나 가중치 매개변수 값을 학습한다.</p><hr><h1 id="3-1-퍼셉트론에서-신경망으로"><a href="#3-1-퍼셉트론에서-신경망으로" class="headerlink" title="3.1 퍼셉트론에서 신경망으로"></a>3.1 퍼셉트론에서 신경망으로</h1><h2 id="3-1-1-신경망의-예"><a href="#3-1-1-신경망의-예" class="headerlink" title="3.1.1 신경망의 예"></a>3.1.1 신경망의 예</h2><p>퍼셉트론과 다르지 않다.</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/300px-Colored_neural_network.svg.png" alt="신경망의 예"><br>출처 : <a href="https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/300px-Colored_neural_network.svg.png" target="_blank" rel="noopener">위키백과</a></p><h2 id="3-1-2-퍼셉트론-복습"><a href="#3-1-2-퍼셉트론-복습" class="headerlink" title="3.1.2 퍼셉트론 복습"></a>3.1.2 퍼셉트론 복습</h2><p><img src="/images/deeplearning/perceptronWithBias.PNG" alt="편향을 명시한 퍼셉트론"></p><figure class="highlight py"><figcaption><span>식 3.1</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = <span class="number">0</span> (b + w1*x1 + w2*x2 &lt;= <span class="number">0</span>)</span><br><span class="line">  = <span class="number">1</span> (b + w1*x1 + w2*x2 &gt; <span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight py"><figcaption><span>식 3.2</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y = h(b + w1*x1 + w2*x2)</span><br></pre></td></tr></table></figure><figure class="highlight py"><figcaption><span>식 3.3</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">h(x) = <span class="number">0</span> (x &lt;= <span class="number">0</span>)</span><br><span class="line">     = <span class="number">1</span> (x &gt; <span class="number">0</span>)</span><br></pre></td></tr></table></figure><blockquote><p>입력 신호의 총합을 출력 신호로 변환하는 함수를 일반적으로 <strong>활성화 함수</strong>(h(x)) 라고 한다.</p></blockquote><h2 id="3-1-3-활성화-함수의-등장"><a href="#3-1-3-활성화-함수의-등장" class="headerlink" title="3.1.3 활성화 함수의 등장"></a>3.1.3 활성화 함수의 등장</h2><p><img src="/images/deeplearning/activationF.PNG" alt="활성화 함수의 처리 과정"></p><p>가중치 신호를 조합한 결과가 a라는 노드가 되고, 활성화 함수 h()를 통과하여 y라는 노드로 변환</p><blockquote><p>일반적으로 단층 퍼셉트론은 단층 네트워크에서 계단함수를 활성화 함수로 사용한 모델. 다층 퍼셉트론은 신경망(여러층 및 시그모이드 함수 등의 매끈한 활성화 함수)을 가리킨다.</p></blockquote><hr><h1 id="3-2-활성화-함수"><a href="#3-2-활성화-함수" class="headerlink" title="3.2 활성화 함수"></a>3.2 활성화 함수</h1><h2 id="3-2-1-시그모이드-함수"><a href="#3-2-1-시그모이드-함수" class="headerlink" title="3.2.1 시그모이드 함수"></a>3.2.1 시그모이드 함수</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">h(x) = <span class="number">1</span> / (<span class="number">1</span> + exp(-x))</span><br></pre></td></tr></table></figure><ul><li>신경망 에서는 활성화 함수로 시그모이드 함수를 이용하여 신호를 변환하고 다음 뉴런에 전달.</li><li>앞장의 퍼셉트론과의 차이점은 활성화 함수 뿐.</li></ul><h2 id="3-2-2-계단-함수-구현하기"><a href="#3-2-2-계단-함수-구현하기" class="headerlink" title="3.2.2 계단 함수 구현하기"></a>3.2.2 계단 함수 구현하기</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">step_function</span><span class="params">(x)</span>:</span></span><br><span class="line">    y = x &gt; <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> y.astype(np.int)</span><br></pre></td></tr></table></figure><h2 id="3-2-3-계단-함수의-그래프"><a href="#3-2-3-계단-함수의-그래프" class="headerlink" title="3.2.3 계단 함수의 그래프"></a>3.2.3 계단 함수의 그래프</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pylab <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">step_function</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.array(x&gt;<span class="number">0</span>, dtype=np.int)</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">-5.0</span>, <span class="number">5.0</span>, <span class="number">0.1</span>) <span class="comment"># -5 ~ 5 0.1 단위</span></span><br><span class="line">y = step_function(x)</span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.ylim(<span class="number">-0.1</span>, <span class="number">1.1</span>) <span class="comment"># y축 범위 지정</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/deeplearning/chapter3.01stairs.PNG" alt="계단함수 그래프"></p><h2 id="3-2-4-시그모이드-함수-구현하기"><a href="#3-2-4-시그모이드-함수-구현하기" class="headerlink" title="3.2.4 시그모이드 함수 구현하기"></a>3.2.4 시그모이드 함수 구현하기</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pylab <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">-5.0</span>, <span class="number">5.0</span>, <span class="number">0.1</span>)</span><br><span class="line">y = sigmoid(x)</span><br><span class="line">plt.plot(x,y)</span><br><span class="line">plt.ylim(<span class="number">-0.1</span>, <span class="number">1.1</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/images/deeplearning/chapter3.02sigmoid.PNG" alt="시그모이드함수 그래프"></p><h2 id="3-2-5-시그모이드-함수와-계단-함수-비교"><a href="#3-2-5-시그모이드-함수와-계단-함수-비교" class="headerlink" title="3.2.5 시그모이드 함수와 계단 함수 비교"></a>3.2.5 시그모이드 함수와 계단 함수 비교</h2><ul><li><p>차이점</p><ul><li>매끄러움의 차이</li><li>계단 함수는 0과 1중 하나의 값을 돌려주는 반면, 시그모이드 함수는 실수를 return</li></ul></li><li><p>공통점</p><ul><li>입력이 중요하면 큰 값을 출력하고 중요하지 않으면 작은값을 출력</li><li>입력이 아무리 작거나 커도 출력은 0과 1사이</li><li>비선형 함수</li></ul></li></ul><h2 id="3-2-6-비선형-함수"><a href="#3-2-6-비선형-함수" class="headerlink" title="3.2.6 비선형 함수"></a>3.2.6 비선형 함수</h2><ul><li>신경망에서는 활성화 함수로 비선형 함수를 사용해야 한다.</li><li>신경망의 층을 깊게하는 이유</li><li>선형 함수의 문제는 층을 아무리 깊게 해도 ‘은닉층이 없는 네트워크’ 로도 똑같은 기능을 할 수 있다.</li></ul><h2 id="3-2-7-ReLU-함수"><a href="#3-2-7-ReLU-함수" class="headerlink" title="3.2.7 ReLU 함수"></a>3.2.7 ReLU 함수</h2><p>Rectified Linear Unit (렐루) : 정류된</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">h(x) = x (x &gt; <span class="number">0</span>)</span><br><span class="line">     = <span class="number">0</span> (x &lt;= <span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.maximun(<span class="number">0</span>,x)</span><br></pre></td></tr></table></figure><blockquote><p>활성화 함수로 책의 후반부에서 주로 ReLU함수 사용.</p></blockquote><ul><li>Why ?<ul><li>계산의 과정이 Simple, 계산을 빠르게 하기 위해. 6배 정도?</li><li>음수표현이나 실수표현이나 지수 연산이 없다.</li><li>vanishing gradient 를 방지.</li></ul></li></ul><hr><h1 id="3-3-다차원-배열의-계산"><a href="#3-3-다차원-배열의-계산" class="headerlink" title="3.3 다차원 배열의 계산"></a>3.3 다차원 배열의 계산</h1><h2 id="3-3-1-다차원-배열"><a href="#3-3-1-다차원-배열" class="headerlink" title="3.3.1 다차원 배열"></a>3.3.1 다차원 배열</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(A) <span class="comment"># [1 2 3 4]</span></span><br><span class="line">np.ndim(A) <span class="comment"># 배열의 차원 수 : 1</span></span><br><span class="line">A.shape <span class="comment"># 배열의 형상 : (4,)</span></span><br><span class="line">A.shape[<span class="number">0</span>] <span class="comment"># 4</span></span><br></pre></td></tr></table></figure><h2 id="3-3-2-행렬의-내적-행렬-곱"><a href="#3-3-2-행렬의-내적-행렬-곱" class="headerlink" title="3.3.2 행렬의 내적(행렬 곱)"></a>3.3.2 행렬의 내적(행렬 곱)</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.dot(A,B) <span class="comment"># 행렬의 내적</span></span><br></pre></td></tr></table></figure><ul><li>행렬의 곱에서는 대응하는 차원의 원소 수를 일치시켜라.</li></ul><h2 id="3-3-3-신경망의-내적"><a href="#3-3-3-신경망의-내적" class="headerlink" title="3.3.3 신경망의 내적"></a>3.3.3 신경망의 내적</h2><p>다차원 배열의 내적을 구해주는 np.dot 함수를 사용해, 단번에 결과를 계산할 수 있다.</p><hr><h1 id="3-4-3층-신경망-구현하기"><a href="#3-4-3층-신경망-구현하기" class="headerlink" title="3.4 3층 신경망 구현하기"></a>3.4 3층 신경망 구현하기</h1><h2 id="3-4-1-표기법-설명"><a href="#3-4-1-표기법-설명" class="headerlink" title="3.4.1 표기법 설명"></a>3.4.1 표기법 설명</h2><p>이번 절에서만 사용하는 표기이므로 패스</p><h2 id="3-4-2-각-층의-신호-전달-구현하기"><a href="#3-4-2-각-층의-신호-전달-구현하기" class="headerlink" title="3.4.2 각 층의 신호 전달 구현하기"></a>3.4.2 각 층의 신호 전달 구현하기</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">X = np.array([<span class="number">1.0</span>, <span class="number">0.5</span>])</span><br><span class="line"></span><br><span class="line">W1 = np.array([<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.5</span>], [<span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.6</span>])</span><br><span class="line">B1 = np.array([<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>])</span><br><span class="line">A1 = np.dot(X, W1) + B1 <span class="comment"># 가중치의 합</span></span><br><span class="line">Z1 = sigmoid(A1) <span class="comment"># 활성화 함수</span></span><br><span class="line"></span><br><span class="line">W2 = np.array([<span class="number">0.1</span>, <span class="number">0.4</span>], [<span class="number">0.2</span>, <span class="number">0.5</span>], [<span class="number">0.3</span>, <span class="number">0.6</span>])</span><br><span class="line">B2 = np.array([<span class="number">0.1</span>, <span class="number">0.2</span>])</span><br><span class="line">A2 = np.dot(Z1, W2) + B2</span><br><span class="line">Z2 = sigmoid(A2)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">identity_function</span><span class="params">(x)</span>:</span> <span class="comment"># 항등함수</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">W3 = np.array([<span class="number">0.1</span>, <span class="number">0.3</span>], [<span class="number">0.2</span>, <span class="number">0.4</span>])</span><br><span class="line">B3 = np.array([<span class="number">0.1</span>, <span class="number">0.2</span>])</span><br><span class="line">A3 = np.dot(Z2, W3) + B3</span><br><span class="line">Y = identity_function(A3) <span class="comment"># 혹은 Y = A3</span></span><br></pre></td></tr></table></figure><h2 id="3-4-3-구현-정리"><a href="#3-4-3-구현-정리" class="headerlink" title="3.4.3 구현 정리"></a>3.4.3 구현 정리</h2><hr><h1 id="3-5-출력층-설계하기"><a href="#3-5-출력층-설계하기" class="headerlink" title="3.5 출력층 설계하기"></a>3.5 출력층 설계하기</h1><p>일반적으로 회귀에는 항등함수, 분류에는 소프트맥스 함수를 사용</p><ul><li>분류와 회귀 ?<ul><li>분류 : 데이터가 어느 클래스에 속하느냐</li><li>회귀 : 입력 데이터의 (연속적인) 수치를 예측</li></ul></li></ul><h2 id="3-5-1-항등-함수와-소프트맥스-함수-구현하기"><a href="#3-5-1-항등-함수와-소프트맥스-함수-구현하기" class="headerlink" title="3.5.1 항등 함수와 소프트맥스 함수 구현하기"></a>3.5.1 항등 함수와 소프트맥스 함수 구현하기</h2><figure class="highlight py"><figcaption><span>소프트맥스 함수</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(a)</span>:</span></span><br><span class="line">    exp_a = np.exp(a)</span><br><span class="line">    sum_exp_a = np.sum(exp_a)</span><br><span class="line">    y = exp_a / sum_exp_a</span><br><span class="line">    <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><h2 id="3-5-2-소프트맥스-함수-구현-시-주의점"><a href="#3-5-2-소프트맥스-함수-구현-시-주의점" class="headerlink" title="3.5.2 소프트맥스 함수 구현 시 주의점"></a>3.5.2 소프트맥스 함수 구현 시 주의점</h2><p>Sum 부분에 오버플로 문제를 고려해야 한다.</p><figure class="highlight py"><figcaption><span>소프트맥스 함수 (overflow 고려)</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(a)</span>:</span></span><br><span class="line">    c = np.max(a)</span><br><span class="line">    exp_a = np.exp(a-c)</span><br><span class="line">    sum_exp_a = np.sum(exp_a)</span><br><span class="line">    y = exp_a / sum_exp_a</span><br><span class="line">    <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><h2 id="3-5-3-소프트맥스-함수의-특징"><a href="#3-5-3-소프트맥스-함수의-특징" class="headerlink" title="3.5.3 소프트맥스 함수의 특징"></a>3.5.3 소프트맥스 함수의 특징</h2><ul><li><p>소프트맥스 함수 ?</p><blockquote><p>입력 받은 값을 0~1 사이의 값으로 모두 정규화 하며 총합은 항상 1이 되는 특성을 가진 함수</p></blockquote></li><li><p>소프트맥스 함수의 출력을 확률로 해석할 수 있다.</p></li><li>소프트맥스 함수를 적용해도 각 원소의 대소 관계는 변하지 않는다.</li></ul><h2 id="3-5-4-출력층의-뉴런-수-정하기"><a href="#3-5-4-출력층의-뉴런-수-정하기" class="headerlink" title="3.5.4 출력층의 뉴런 수 정하기"></a>3.5.4 출력층의 뉴런 수 정하기</h2><p>분류에서는 분류하고 싶은 클래스 수로 설정하는것이 일반적</p><hr><h1 id="3-6-손글씨-숫자-인식"><a href="#3-6-손글씨-숫자-인식" class="headerlink" title="3.6 손글씨 숫자 인식"></a>3.6 손글씨 숫자 인식</h1><h2 id="3-6-1-MNIST-데이터셋"><a href="#3-6-1-MNIST-데이터셋" class="headerlink" title="3.6.1 MNIST 데이터셋"></a>3.6.1 MNIST 데이터셋</h2><p>MNIST : 손글씨 숫자 이미지 집합</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys, os</span><br><span class="line">sys.path.append(os.pardir) <span class="comment"># 부모 디렉터리의 파일을 가져올 수 있도록 설정</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> dataset.mnist <span class="keyword">import</span> load_mnist</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">img_show</span><span class="params">(img)</span>:</span></span><br><span class="line">    pil_img = Image.fromarray(np.uint8(img))</span><br><span class="line">    pil_img.show()</span><br><span class="line"></span><br><span class="line">(x_train, t_train), (x_test, t_text) = load_mnist(flatten=<span class="keyword">True</span>, normalize=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">img = x_train[<span class="number">0</span>]</span><br><span class="line">label = t_train[<span class="number">0</span>]</span><br><span class="line">print(label)</span><br><span class="line"></span><br><span class="line">print(img.shape)</span><br><span class="line">img = img.reshape(<span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">print(img.shape)</span><br><span class="line"></span><br><span class="line">img_show(img)</span><br></pre></td></tr></table></figure><h2 id="3-6-2-신경망의-추론-처리"><a href="#3-6-2-신경망의-추론-처리" class="headerlink" title="3.6.2 신경망의 추론 처리"></a>3.6.2 신경망의 추론 처리</h2><ul><li>이 신경망은 입력층 뉴런을 784(28*28)개, 출력층 뉴런을 10개로 구성</li><li>첫번째 은닉층에 50개의 뉴런, 두번째 은닉층에 100개의 뉴런을 배치 (임의로 정한 값)</li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">()</span>:</span></span><br><span class="line">    (x_train, t_train), (x_test, t_test) = \</span><br><span class="line">        load_mnist(normalize=<span class="keyword">True</span>, flatten = <span class="keyword">True</span>, one_hot_label=<span class="keyword">False</span>)</span><br><span class="line">    <span class="keyword">return</span> x_test, t_test</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_network</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"sample_weight.pkl"</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        network = pickle.load(f)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> network</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(network, x)</span>:</span></span><br><span class="line">    W1, W2, W3 = network[<span class="string">'W1'</span>], network[<span class="string">'W2'</span>], network[<span class="string">'W3'</span>]</span><br><span class="line">    b1, b2, b3 = network[<span class="string">'b1'</span>], network[<span class="string">'b2'</span>], network[<span class="string">'b3'</span>]</span><br><span class="line"></span><br><span class="line">    a1 = np.dot(x, W1) + b1</span><br><span class="line">    z1 = sigmoid(a1)</span><br><span class="line">    a2 = np.dot(x, W2) + b2</span><br><span class="line">    z2 = sigmoid(a2)</span><br><span class="line">    a3 = np.dot(x, W3) + b3</span><br><span class="line">    z3 = sigmoid(a3)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><h2 id="3-6-3-배치-처리"><a href="#3-6-3-배치-처리" class="headerlink" title="3.6.3 배치 처리"></a>3.6.3 배치 처리</h2><hr><h1 id="참고자료"><a href="#참고자료" class="headerlink" title="참고자료"></a>참고자료</h1><p><a href="https://github.com/Kitchu0401/codenotforfood/blob/master/machine-learning/neural-network.md" target="_blank" rel="noopener">https://github.com/Kitchu0401/codenotforfood/blob/master/machine-learning/neural-network.md</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/deeplearning/cover.jpg&quot; alt=&quot;밑바닥부터 시작하는 딥러닝&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;설치 내용&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gu
      
    
    </summary>
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/categories/DeepLearning/"/>
    
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/tags/DeepLearning/"/>
    
      <category term="밑바닥부터 시작하는 딥러닝" scheme="https://ddulhddul.github.io/tags/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D/"/>
    
  </entry>
  
  <entry>
    <title>Chapter2. 퍼셉트론</title>
    <link href="https://ddulhddul.github.io/2018/01/14/DeepLearning/ml001/"/>
    <id>https://ddulhddul.github.io/2018/01/14/DeepLearning/ml001/</id>
    <published>2018-01-14T02:23:52.000Z</published>
    <updated>2019-06-06T10:04:52.483Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/deeplearning/cover.jpg" alt="밑바닥부터 시작하는 딥러닝"></p><h2 id="퍼셉트론"><a href="#퍼셉트론" class="headerlink" title="퍼셉트론 ?"></a>퍼셉트론 ?</h2><ul><li>프랑크 로젠블라트가 1957 고안한 알고리즘.</li><li>신경망(딥러닝) 의 기원이 되는 알고리즘</li></ul><h1 id="2-1-퍼셉트론이란"><a href="#2-1-퍼셉트론이란" class="headerlink" title="2.1 퍼셉트론이란 ?"></a>2.1 퍼셉트론이란 ?</h1><ul><li>(흐름이 있는) 다수의 신호를 입력으로 받아 하나의 신호를 출력</li><li><strong>1이나 0</strong> 두가지 값을 가짐.</li></ul><p><img src="/images/deeplearning/perceptron.PNG" alt="퍼셉트론"></p><ul><li>가중치와 임계값<ul><li>가중치는 각 신호가 결과에 주는 영향력을 조절</li></ul></li></ul><h1 id="2-2-단순한-논리-회로"><a href="#2-2-단순한-논리-회로" class="headerlink" title="2.2 단순한 논리 회로"></a>2.2 단순한 논리 회로</h1><h2 id="2-2-1-AND-게이트"><a href="#2-2-1-AND-게이트" class="headerlink" title="2.2.1 AND 게이트"></a>2.2.1 AND 게이트</h2><ul><li>AND 게이트의 진리표</li></ul><table><thead><tr><th>x1</th><th>x2</th><th>y</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>0</td><td>0</td></tr><tr><td>0</td><td>1</td><td>0</td></tr><tr><td>1</td><td>1</td><td>1</td></tr></tbody></table><h2 id="2-2-2-NAND-게이트와-OR-게이트"><a href="#2-2-2-NAND-게이트와-OR-게이트" class="headerlink" title="2.2.2 NAND 게이트와 OR 게이트"></a>2.2.2 NAND 게이트와 OR 게이트</h2><p>NAND = NOT AND</p><ul><li>NAND 게이트의 진리표</li></ul><table><thead><tr><th>x1</th><th>x2</th><th>y</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>1</td></tr><tr><td>1</td><td>0</td><td>1</td></tr><tr><td>0</td><td>1</td><td>1</td></tr><tr><td>1</td><td>1</td><td>0</td></tr></tbody></table><ul><li>OR 게이트의 진리표</li></ul><table><thead><tr><th>x1</th><th>x2</th><th>y</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>0</td><td>1</td></tr><tr><td>0</td><td>1</td><td>1</td></tr><tr><td>1</td><td>1</td><td>1</td></tr></tbody></table><h1 id="2-3-퍼셉트론-구현하기"><a href="#2-3-퍼셉트론-구현하기" class="headerlink" title="2.3 퍼셉트론 구현하기"></a>2.3 퍼셉트론 구현하기</h1><h2 id="2-3-1-간단한-구현부터"><a href="#2-3-1-간단한-구현부터" class="headerlink" title="2.3.1 간단한 구현부터"></a>2.3.1 간단한 구현부터</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">AND</span><span class="params">(x1,x2)</span>:</span></span><br><span class="line">  w1, w2, theta = <span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.7</span></span><br><span class="line">  tmp = x1*w1 + x2*w2</span><br><span class="line">  <span class="keyword">if</span> tmp &lt;= theta:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">elif</span> tmp &gt; theta:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><h2 id="2-3-2-가중치와-편향-도입"><a href="#2-3-2-가중치와-편향-도입" class="headerlink" title="2.3.2 가중치와 편향 도입"></a>2.3.2 가중치와 편향 도입</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x = np.array([<span class="number">0</span>,<span class="number">1</span>])     <span class="comment"># 입력</span></span><br><span class="line">w = np.array([<span class="number">0.5</span>,<span class="number">0.5</span>]) <span class="comment"># 가중치</span></span><br><span class="line">b = <span class="number">-0.7</span>                <span class="comment"># 편향</span></span><br><span class="line">np.sum(w*x) + b         <span class="comment"># AND 게이트</span></span><br></pre></td></tr></table></figure><h2 id="2-3-3-가중와-편향-구현하기"><a href="#2-3-3-가중와-편향-구현하기" class="headerlink" title="2.3.3 가중와 편향 구현하기"></a>2.3.3 가중와 편향 구현하기</h2><ul><li>가중치와 편향을 도입한 AND 게이트</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">AND</span><span class="params">(x1,x2)</span>:</span></span><br><span class="line">  x = np.array([x2,x2])</span><br><span class="line">  w = np.array([<span class="number">0.5</span>,<span class="number">0.5</span>])</span><br><span class="line">  b = <span class="number">-0.7</span></span><br><span class="line">  tmp = np.sum(x*w) + b</span><br><span class="line">  <span class="keyword">if</span> tmp &lt;= <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><ul><li>가중치 w1, w2 는 <strong>각 입력 신호가 결과에 주는 영향력</strong>을 조절</li><li><p>편향은 <strong>뉴런이 얼마나 쉽게 활성화 하느냐</strong>를 조정</p></li><li><p>가중치와 편향을 도입한 NAND 게이트</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">NAND</span><span class="params">(x1,x2)</span>:</span></span><br><span class="line">  x = np.array([x2,x2])</span><br><span class="line">  w = np.array([<span class="number">-0.5</span>,<span class="number">-0.5</span>]) <span class="comment"># AND 와는 가중치(w,b) 만 다름</span></span><br><span class="line">  b = <span class="number">0.7</span></span><br><span class="line">  tmp = np.sum(x*w) + b</span><br><span class="line">  <span class="keyword">if</span> tmp &lt;= <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><ul><li>가중치와 편향을 도입한 OR 게이트</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">OR</span><span class="params">(x1,x2)</span>:</span></span><br><span class="line">  x = np.array([x2,x2])</span><br><span class="line">  w = np.array([<span class="number">0.5</span>,<span class="number">0.5</span>]) <span class="comment"># AND 와는 가중치(w,b) 만 다름</span></span><br><span class="line">  b = <span class="number">-0.2</span></span><br><span class="line">  tmp = np.sum(x*w) + b</span><br><span class="line">  <span class="keyword">if</span> tmp &lt;= <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><h1 id="2-4-퍼셉트론의-한계"><a href="#2-4-퍼셉트론의-한계" class="headerlink" title="2.4 퍼셉트론의 한계"></a>2.4 퍼셉트론의 한계</h1><h2 id="2-4-1-도전-XOR-게이트"><a href="#2-4-1-도전-XOR-게이트" class="headerlink" title="2.4.1 도전! XOR 게이트"></a>2.4.1 도전! XOR 게이트</h2><ul><li>XOR 게이트의 진리표</li></ul><table><thead><tr><th>x1</th><th>x2</th><th>y</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>0</td><td>1</td></tr><tr><td>0</td><td>1</td><td>1</td></tr><tr><td>1</td><td>1</td><td>0</td></tr></tbody></table><blockquote><p>XOR 게이트를 직선 하나로 표현하는 방법은 존재하지 않는다.</p></blockquote><h2 id="2-4-2-선형과-비선형"><a href="#2-4-2-선형과-비선형" class="headerlink" title="2.4.2 선형과 비선형"></a>2.4.2 선형과 비선형</h2><p>직선이라는 제약을 없앤다면 XOR 를 표현할 수 있다.</p><h1 id="2-5-다층-퍼셉트론이-충돌한다면"><a href="#2-5-다층-퍼셉트론이-충돌한다면" class="headerlink" title="2.5 다층 퍼셉트론이 충돌한다면"></a>2.5 다층 퍼셉트론이 충돌한다면</h1><p><strong>다층 퍼셉트론</strong>을 이용하면 XOR 를 표현할 수 있다. (층을 쌓는다.)</p><h2 id="2-5-1-기존-게이트-조합하기"><a href="#2-5-1-기존-게이트-조합하기" class="headerlink" title="2.5.1 기존 게이트 조합하기"></a>2.5.1 기존 게이트 조합하기</h2><p><img src="/images/deeplearning/xor.PNG" alt="XOR 표현"></p><ul><li>NAND 의 출력을 s1, OR 의 출력을 s2 로 진리표를 만들면</li></ul><table><thead><tr><th>x1</th><th>x2</th><th>s1</th><th>s2</th><th>y</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td></tr><tr><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td></tr><tr><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td></tr></tbody></table><h2 id="2-5-2-XOR-게이트-구현하기"><a href="#2-5-2-XOR-게이트-구현하기" class="headerlink" title="2.5.2 XOR 게이트 구현하기"></a>2.5.2 XOR 게이트 구현하기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">XOR</span><span class="params">(x1,x2)</span>:</span></span><br><span class="line">  s1 = NAND(x1,x2)</span><br><span class="line">  s2 = OR(x1,x2)</span><br><span class="line">  y = AND(s1,s2)</span><br><span class="line">  <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><ul><li>XOR 는 다층 구조의 네트워크</li><li>AND,NAND,OR 단층 퍼셉트론 / XOR 는 2층 퍼셉트론</li></ul><h1 id="2-6-NAND-에서-컴퓨터까지"><a href="#2-6-NAND-에서-컴퓨터까지" class="headerlink" title="2.6 NAND 에서 컴퓨터까지"></a>2.6 NAND 에서 컴퓨터까지</h1><ul><li>퍼셉트론을 이용하면 컴퓨터 마저 표현 가능</li><li>이론상 2층 퍼셉트론이면 컴퓨터를 만들 수 있다.<ul><li>비선형인 시그모이드 함수를 활성화 함수로 이용하면 가능(3장 참고)<blockquote><p>하지만 2층 퍼셉트론 구조에서 가중치를 적절하게 설정하여 컴퓨터를 만드는 것보다, 필요한 부품(모듈) 을 단계적으로 만드는 쪽이 자연스러운 방법임.</p></blockquote></li></ul></li></ul><hr><h1 id="참고자료"><a href="#참고자료" class="headerlink" title="참고자료"></a>참고자료</h1><ul><li>딥러닝의 역사<br><a href="http://solarisailab.com/archives/1206" target="_blank" rel="noopener">http://solarisailab.com/archives/1206</a></li></ul><div class="video-container"><iframe src="//www.youtube.com/embed/FwFduRA_L6Q" frameborder="0" allowfullscreen></iframe></div><ul><li><p>딥러닝 자습<br><a href="https://www.slideshare.net/yongho/ss-79607172" target="_blank" rel="noopener">https://www.slideshare.net/yongho/ss-79607172</a></p></li><li><p>딥러닝의 30가지 적용 사례<br><a href="https://brunch.co.kr/@itschloe1/23" target="_blank" rel="noopener">https://brunch.co.kr/@itschloe1/23</a></p></li><li><p>문과생도 이해하는 딥러닝<br><a href="http://sacko.tistory.com/10" target="_blank" rel="noopener">http://sacko.tistory.com/10</a></p></li><li><p>퍼셉트론 이용한 가위바위보 예제<br><a href="http://hanybin.blogspot.kr/2017/10/ai.html" target="_blank" rel="noopener">http://hanybin.blogspot.kr/2017/10/ai.html</a></p></li></ul><div class="video-container"><iframe src="//www.youtube.com/embed/Wsq8nXPbncM" frameborder="0" allowfullscreen></iframe></div><hr><figure class="highlight java"><figcaption><span>SingleLayerPerceptron.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SingleLayerPerceptron</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> numberOfNeurons;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">float</span>[] inputValues;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">float</span> learningRate;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">float</span> targetValue;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">boolean</span> useSigmoid = <span class="keyword">false</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">float</span>[] weights;</span><br><span class="line">    <span class="keyword">float</span> outputValue;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span>[] rawValues;</span><br><span class="line">    <span class="keyword">float</span> sumOfrawValues;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SingleLayerPerceptron</span><span class="params">(<span class="keyword">int</span> numberOfNeurons, <span class="keyword">float</span> learningRate, <span class="keyword">boolean</span> useSigmoid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.numberOfNeurons = numberOfNeurons;</span><br><span class="line">        <span class="keyword">this</span>.learningRate = learningRate;</span><br><span class="line">        <span class="keyword">this</span>.useSigmoid = useSigmoid;</span><br><span class="line">        inputValues = <span class="keyword">new</span> <span class="keyword">float</span>[numberOfNeurons];</span><br><span class="line">        weights = <span class="keyword">new</span> <span class="keyword">float</span>[numberOfNeurons];</span><br><span class="line">        rawValues = <span class="keyword">new</span> <span class="keyword">float</span>[numberOfNeurons];</span><br><span class="line">        sumOfrawValues = <span class="number">0f</span>;</span><br><span class="line">        outputValue = <span class="number">0f</span>;</span><br><span class="line"></span><br><span class="line">        Random r = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="comment">//initializing weights</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numberOfNeurons; i++)</span><br><span class="line">        &#123;</span><br><span class="line"><span class="comment">//            weights[i] = Random.Range(-0.5f, 0.5f);</span></span><br><span class="line">        weights[i] = (<span class="keyword">float</span>) (r.nextFloat()-<span class="number">0.5</span>);</span><br><span class="line">            System.out.println(<span class="string">"step: "</span> + i + <span class="string">", weight value: "</span> + weights[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">float</span> <span class="title">ProcessInputsToRawValue</span><span class="params">(<span class="keyword">float</span>[] inputValues)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        sumOfrawValues = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numberOfNeurons; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">this</span>.inputValues[i] = inputValues[i]; <span class="comment">//deep copy inputValues for futher processing</span></span><br><span class="line">            rawValues[i] = inputValues[i] * weights[i];</span><br><span class="line">            sumOfrawValues += rawValues[i];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sumOfrawValues;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">float</span> <span class="title">ActivationProcess</span><span class="params">(<span class="keyword">float</span> sumOfrawValues)</span> <span class="comment">//uses sigmoid function</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">float</span> activationValue = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (useSigmoid == <span class="keyword">true</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            activationValue = (<span class="keyword">float</span>) (<span class="number">1</span> / (<span class="number">1</span> + Math.exp(-sumOfrawValues)));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (sumOfrawValues &gt;= <span class="number">0.5f</span>)</span><br><span class="line">            &#123;                </span><br><span class="line">                activationValue = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (sumOfrawValues &lt; <span class="number">0.5f</span>)</span><br><span class="line">            &#123;             </span><br><span class="line">                activationValue = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//Debug.Log("ActivationValue is : " + activationValue);</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> activationValue;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">LearningProcess</span><span class="params">(<span class="keyword">float</span> sumOfrawValues, <span class="keyword">float</span> targetValue)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">float</span> difference = targetValue - ActivationProcess(sumOfrawValues);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numberOfNeurons; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            weights[i] = weights[i] + (inputValues[i] * learningRate * difference);</span><br><span class="line">            <span class="comment">//Debug.Log("step: " + i + ", modified weight value: " + weights[i]);</span></span><br><span class="line">        &#125;        </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">float</span> <span class="title">Execute</span><span class="params">(<span class="keyword">float</span>[] inputValues, <span class="keyword">float</span> targetValue)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        sumOfrawValues = ProcessInputsToRawValue(inputValues);</span><br><span class="line">        outputValue = ActivationProcess(sumOfrawValues);        </span><br><span class="line">        LearningProcess(sumOfrawValues, targetValue);                </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> outputValue;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">float</span> <span class="title">Test</span><span class="params">(<span class="keyword">float</span>[] inputValues)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">float</span> outputValue = ActivationProcess(ProcessInputsToRawValue(inputValues));</span><br><span class="line">        <span class="keyword">return</span> outputValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><figcaption><span>Main.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"><span class="comment">// int numberOfNeurons, float learningRate, boolean useSigmoid</span></span><br><span class="line">SingleLayerPerceptron s = <span class="keyword">new</span> SingleLayerPerceptron(<span class="number">3</span>, (<span class="keyword">float</span>) <span class="number">0.1</span>, <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">50</span>; i++) &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> targetValue = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">float</span>[] arr = floatArray(i);</span><br><span class="line"><span class="keyword">float</span> result = s.Execute(arr, targetValue);</span><br><span class="line">System.out.printf(<span class="string">"i= %s, arr=%s %s %s, result = %s \n"</span>, i,arr[<span class="number">0</span>],arr[<span class="number">1</span>],arr[<span class="number">2</span>],result);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">float</span>[] floatArray(<span class="keyword">int</span> i) &#123;</span><br><span class="line">Random r = <span class="keyword">new</span> Random();</span><br><span class="line">i = r.nextInt(<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(i%<span class="number">3</span> == <span class="number">0</span>)&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">float</span>[]&#123;<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>&#125;;</span><br><span class="line">&#125;<span class="keyword">else</span> <span class="keyword">if</span>(i%<span class="number">3</span> == <span class="number">1</span>)&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">float</span>[]&#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>&#125;;</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">float</span>[]&#123;<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>&#125;;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/deeplearning/cover.jpg&quot; alt=&quot;밑바닥부터 시작하는 딥러닝&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;퍼셉트론&quot;&gt;&lt;a href=&quot;#퍼셉트론&quot; class=&quot;headerlink&quot; title=&quot;퍼셉트론 ?&quot;&gt;&lt;/a&gt;퍼
      
    
    </summary>
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/categories/DeepLearning/"/>
    
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/tags/DeepLearning/"/>
    
      <category term="밑바닥부터 시작하는 딥러닝" scheme="https://ddulhddul.github.io/tags/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D/"/>
    
  </entry>
  
  <entry>
    <title>딥러닝 스터디 첫시간</title>
    <link href="https://ddulhddul.github.io/2018/01/09/DeepLearning/machineLearning/"/>
    <id>https://ddulhddul.github.io/2018/01/09/DeepLearning/machineLearning/</id>
    <published>2018-01-09T12:23:52.000Z</published>
    <updated>2019-06-06T10:04:52.482Z</updated>
    
    <content type="html"><![CDATA[<h1 id="책"><a href="#책" class="headerlink" title="책"></a>책</h1><p><a href="http://www.hanbit.co.kr/store/books/look.php?p_code=B8475831198" target="_blank" rel="noopener">http://www.hanbit.co.kr/store/books/look.php?p_code=B8475831198</a></p><h1 id="딥러닝"><a href="#딥러닝" class="headerlink" title="딥러닝 ?"></a>딥러닝 ?</h1><blockquote><p>AI 가 같이 나온다.<br>컴퓨터를 사람처럼 생각하게 만든다.</p></blockquote><ul><li>(데이터를 가지고 학습을 통하여) 어떠한 데이터 X를 넣었을때 원하는 결과값인 Y를 출력하게하는 함수를 만드는 것.</li></ul><h2 id="Neural-Network-NN-신경망"><a href="#Neural-Network-NN-신경망" class="headerlink" title="Neural Network (NN) : 신경망"></a>Neural Network (NN) : 신경망</h2><h2 id="어떻게-분류하느냐"><a href="#어떻게-분류하느냐" class="headerlink" title="어떻게 분류하느냐 ?"></a>어떻게 분류하느냐 ?</h2><p>개나리/코스모스/백합</p><ul><li><p>피쳐러닝</p><blockquote><p>색, 잎의개수, 크기, 모양</p></blockquote></li><li><p>Deep learning 은 Feature 를 <strong>스스로</strong> 뽑는다.</p></li></ul><h1 id="머신러닝-딥러닝-분류-종류"><a href="#머신러닝-딥러닝-분류-종류" class="headerlink" title="머신러닝 딥러닝 분류(종류)"></a>머신러닝 딥러닝 분류(종류)</h1><h2 id="supervised-learning"><a href="#supervised-learning" class="headerlink" title="supervised learning"></a>supervised learning</h2><ul><li>데이터가 정답이 다 있는</li></ul><h2 id="unsupervised-learning"><a href="#unsupervised-learning" class="headerlink" title="unsupervised learning"></a>unsupervised learning</h2><ul><li>답지가 없는, 데이터만 있는.. Artifact</li></ul><h2 id="reinforcement-learning"><a href="#reinforcement-learning" class="headerlink" title="reinforcement learning"></a>reinforcement learning</h2><ul><li>알파고, 자기혼자 학습</li></ul><h1 id="예제"><a href="#예제" class="headerlink" title="예제"></a>예제</h1><p><a href="http://www.bloter.net/archives/289626" target="_blank" rel="noopener">http://www.bloter.net/archives/289626</a></p><blockquote><p>caffe, tensorflow, theano, keras, …</p></blockquote><ul><li>다음 시간엔… 2장 요약…</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;책&quot;&gt;&lt;a href=&quot;#책&quot; class=&quot;headerlink&quot; title=&quot;책&quot;&gt;&lt;/a&gt;책&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;http://www.hanbit.co.kr/store/books/look.php?p_code=B8475831198&quot; 
      
    
    </summary>
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/categories/DeepLearning/"/>
    
    
      <category term="DeepLearning" scheme="https://ddulhddul.github.io/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>시작하세요! 리액트 프로그래밍</title>
    <link href="https://ddulhddul.github.io/2017/12/29/datas/react/startReactProgramming/"/>
    <id>https://ddulhddul.github.io/2017/12/29/datas/react/startReactProgramming/</id>
    <published>2017-12-29T10:42:52.000Z</published>
    <updated>2019-06-06T10:04:52.489Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/startReactProgramming/cover.jpg" alt="/images/startReactProgramming/cover.jpg"></p><h1 id="01-Hello-World"><a href="#01-Hello-World" class="headerlink" title="01. Hello World"></a>01. Hello World</h1><p><a href="https://react-cn.github.io/react/downloads.html" target="_blank" rel="noopener">리액트 다운로드 URL</a></p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ReactDOM.render(</span><br><span class="line">  React.DOM.h1(<span class="literal">null</span>, <span class="string">'hello world'</span>),</span><br><span class="line">  <span class="built_in">document</span>.getElementById(<span class="string">'app'</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ul><li><strong>‘app’ div</strong> 자리표시자의 내용이 리액트 앱에서 생성한 내용으로 대체된다.</li></ul><h2 id="작동원리"><a href="#작동원리" class="headerlink" title="작동원리"></a>작동원리</h2><ol><li><p>React 객체의 사용</p><ul><li>이 객체를 통해 모든 API에 접근할 수 있으며, API가 간소화되어있어 메서드는 그리 많지 않다.</li></ul></li><li><p>ReactDOM 객체의 사용</p><ul><li><strong>render()</strong>가 중요하다. 여러 다른 환경(HTML, 캔버스, 안드로이드, IOS) 에서 적절하게 렌더링하는 리액트 앱을 만들 수 있다.</li></ul></li><li><p>컴포넌트 개념</p><ul><li>UI 는 컴포넌트를 이용해 제작, 원하는 방법으로 이러한 컴포넌트를 조합.</li><li>리액트에서는 HTML DOM을 감싸는 래퍼를 제공하는데, <strong>React.DOM</strong> 객체를 통해 제공</li></ul></li><li><p>document.getElementById(‘app’)</p><ul><li>페이지 내에서 애플리케이션의 위치를 리액트에 알려준다.</li><li>이 호출은 DOM조작을 리액트의 세계로 연결하는 다리 역할을 한다.</li></ul></li></ol><h2 id="React-DOM"><a href="#React-DOM" class="headerlink" title="React.DOM.*"></a>React.DOM.*</h2><ul><li>React.DOM 객체를 통해 여러 html 요소를 리액트 컴포넌트로 이용할 수 있다.</li><li>React.DOM 과 ReactDOM은 다르다. 전자는 미리 만들어진 html요소의 컬렉션, 후자는 앱을 브라우저에서 렌더링하는 방법 중 하나.<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">React.DOM.h1(&#123;<span class="attr">id</span>: <span class="string">'my-heading'</span>&#125;, <span class="string">"hello world"</span>)</span><br><span class="line"><span class="comment">// 첫번째 인자는 컴포넌트로 전달하려는 프로퍼티</span></span><br><span class="line"><span class="comment">// 두번째 인자는 컴포넌트의 자식</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="특수한-DOM-속성"><a href="#특수한-DOM-속성" class="headerlink" title="특수한 DOM 속성"></a>특수한 DOM 속성</h2><ul><li>반드시 알아야할 DOM 속성 <strong>className, for, style</strong></li><li>class는 자바스크립트 예약어 이므로, 대신 className, htmlFor 가 필요.<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">React.DOM.h1(&#123;</span><br><span class="line">  className: <span class="string">'pretty'</span>,</span><br><span class="line">  htmlFor: <span class="string">'me'</span>,</span><br><span class="line">  style: &#123;</span><br><span class="line">    background: <span class="string">'black'</span>,</span><br><span class="line">    color: <span class="string">'white'</span>,</span><br><span class="line">    fontFamily: <span class="string">'Verdona'</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//css 프로퍼티를 다룰 때, 자바스크립트 API 이름을 사용. (CamelCase)</span></span><br><span class="line">&#125;, <span class="string">"hello"</span>)</span><br></pre></td></tr></table></figure></li></ul><h1 id="02-컴포넌트의-수명"><a href="#02-컴포넌트의-수명" class="headerlink" title="02. 컴포넌트의 수명"></a>02. 컴포넌트의 수명</h1><h2 id="최소요건"><a href="#최소요건" class="headerlink" title="최소요건"></a>최소요건</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//새로운 컴포넌트를 만드는 API</span></span><br><span class="line"><span class="keyword">var</span> MyComponent = React.createClass(&#123;</span><br><span class="line">    render: <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> React.DOM.h1(<span class="literal">null</span>, <span class="string">'hello'</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">ReactDOM.render(</span><br><span class="line">    React.createElement(MyComponent),</span><br><span class="line">    <span class="built_in">document</span>.getElementById(<span class="string">'app'</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ul><li>필수요건은 <strong>render()</strong> 메서드를 구현하는 것. 이 메서드는 리액트 컴포넌트를 반환해야 함.</li></ul><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ReactDOM.render(</span><br><span class="line">    React.createElement(<span class="string">'span'</span>, <span class="literal">null</span>, <span class="string">'hello'</span>),</span><br><span class="line">    <span class="built_in">document</span>.getElementById(<span class="string">'app'</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ul><li>React.DOM.* 메서드는 React.createElement() 를 감싸는 래퍼에 불과하다.</li></ul><h2 id="프로퍼티"><a href="#프로퍼티" class="headerlink" title="프로퍼티"></a>프로퍼티</h2><ul><li>모든 프로퍼티는 <strong>this.props</strong> 객체를 통해 이용할 수 있다.</li><li><p>컴포넌트를 렌더링할 때  프로퍼티를 전달하는 방법</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ReactDOM.render(</span><br><span class="line">    React.createElement(Component, &#123;</span><br><span class="line">        name: <span class="string">'ddulh'</span></span><br><span class="line">    &#125;, <span class="string">'hello'</span>),</span><br><span class="line">    <span class="built_in">document</span>.getElementById(<span class="string">'app'</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><p>this.props 는 <strong>읽기 전용</strong> 이라고 생각하자.</p></li></ul><h2 id="propTypes"><a href="#propTypes" class="headerlink" title="propTypes"></a>propTypes</h2><ul><li><p>컴포넌트가 받는 프로퍼티의 목록과 형식을 선언할 수 있다.</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> Component = React.createClass(&#123;</span><br><span class="line">    propTypes: &#123;</span><br><span class="line">        name: React.PropTypes.string.isRequired</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="comment">// 기본 프로퍼티 값</span></span><br><span class="line">    getDefaultProps: <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            name: <span class="string">''</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    render: <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> React.DOM.span(<span class="literal">null</span>, <span class="string">'hello'</span>+<span class="keyword">this</span>.props.name)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></li><li><p>리액트가 프로퍼티 값의 유효성을 <strong>런타임</strong>에 검사하므로 컴포넌트가 받는 데이터에 대해 걱정할 필요없이 render() 함수를 작성할 수 있다.</p></li><li>Object.keys(React.PropTypes)</li></ul><h2 id="상태"><a href="#상태" class="headerlink" title="상태"></a>상태</h2><ul><li>리액트가 기존의 브라우저 DOM 조작과 유지 관리에 비해 가지는 장점은 애플리케이션에서 데이터가 변경될 때, 데이터의 상태에 따라 UI를 재구축한다는 점.</li><li>render() 에서 UI를 만든 다음, 해당 데이터를 업데이트 하는데만 신경 쓰면 된다.</li><li>상태변경은 <strong>this.setState()</strong> 를 통해 한다. 호출될 경우, 리액트는 render() 메서드를 호출하고 UI를 업데이트한다.</li><li>항상 유효한 데이터로 작업할 수 있도록, 컴포넌트에서 getInitialState() 메서드를 구현<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">getInitialState()&#123;</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        name: <span class="keyword">this</span>.props.name</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="DOM-이벤트-참고사항"><a href="#DOM-이벤트-참고사항" class="headerlink" title="DOM 이벤트 참고사항"></a>DOM 이벤트 참고사항</h2><ul><li>리액트는 성능과 편의성, 유효성 유지를 위해 자체 합성 이벤트 시스템을 이용</li><li>브라우저 불일치 문제를 자연스럽게 해결.</li><li>또한 이벤트를 취소하는 API가 모든 브라우저에서 동일<ul><li>event.stopPropagation() 과 event.preventDefault() 가 이전 IE에서도 작동</li></ul></li><li>리액트는 이벤트핸들러에 캐멀표기법을 이용하므로 ON-CLICK 을 이용해야 한다.</li></ul><h2 id="프로퍼티와-상태"><a href="#프로퍼티와-상태" class="headerlink" title="프로퍼티와 상태"></a>프로퍼티와 상태</h2><ul><li>this.props: 프로퍼티는 바깥환경에서 컴포넌트를 구성하기 위한 매커니즘</li><li>this.state: 상태를 컴포넌트의 내부 데이터</li></ul><h2 id="외부에서-컴포넌트-접근"><a href="#외부에서-컴포넌트-접근" class="headerlink" title="외부에서 컴포넌트 접근"></a>외부에서 컴포넌트 접근</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> myTextAreaCounter = ReactDOM.render(</span><br><span class="line">    React.createElement(TextAreaCounter, &#123;</span><br><span class="line">        defaultValue: <span class="string">'ddulh'</span></span><br><span class="line">    &#125;)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 새로운 상태 설정 - 외부에서의 상태 변경은 가급적 권장되지 않음</span></span><br><span class="line">myTextAreaCounter.setState(&#123;<span class="attr">text</span>: <span class="string">'Hello ~~~'</span>&#125;)</span><br><span class="line"><span class="comment">// 리액트가 생성한 주 부모 DOM 노드에 대한 참조를 얻기</span></span><br><span class="line"><span class="keyword">var</span> reactAppNode = ReactDOM.findDOMNode(myTextAreaCounter)</span><br><span class="line"><span class="comment">// 프로퍼티와 상태에 접근</span></span><br><span class="line">myTextAreaCounter.props;</span><br><span class="line">myTextAreaCounter.state;</span><br></pre></td></tr></table></figure><h2 id="수명-주기-메서드"><a href="#수명-주기-메서드" class="headerlink" title="수명 주기 메서드"></a>수명 주기 메서드</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> logMixin = &#123;</span><br><span class="line">    _log: <span class="function"><span class="keyword">function</span>(<span class="params">methodName, args</span>)</span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="keyword">this</span>.name+ <span class="string">'::'</span>+methodName, args)</span><br><span class="line">    &#125;,</span><br><span class="line">    componentWillUpdate: <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="comment">// 컴포넌트의 render() 메서드가 호출되기 전에 실행</span></span><br><span class="line">        <span class="keyword">this</span>._log(<span class="string">'componentWillUpdate'</span>, <span class="built_in">arguments</span>)</span><br><span class="line">    &#125;,</span><br><span class="line">    componentDidUpdate: <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="comment">// render() 메서드가 작업을 완료하고 기반 DOM의 새로운 변경사항이 적용된 후에 실행</span></span><br><span class="line">        <span class="keyword">this</span>._log(<span class="string">'componentDidUpdate'</span>, <span class="built_in">arguments</span>)</span><br><span class="line">    &#125;,</span><br><span class="line">    componentWillMount: <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="comment">// 노드가 DOM에 삽입되기 전에 실행</span></span><br><span class="line">        <span class="keyword">this</span>._log(<span class="string">'componentWillMount'</span>, <span class="built_in">arguments</span>)</span><br><span class="line">    &#125;,</span><br><span class="line">    componentDidMount: <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="comment">// 노드가 DOM에 삽입된 후에 실행</span></span><br><span class="line">        <span class="keyword">this</span>._log(<span class="string">'componentDidMount'</span>, <span class="built_in">arguments</span>)</span><br><span class="line">    &#125;,</span><br><span class="line">    componentWillUnmount: <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="comment">// 컴포넌트가 DOM에서 제거되기 직전에 실행</span></span><br><span class="line">        <span class="keyword">this</span>._log(<span class="string">'componentWillUnmount'</span>, <span class="built_in">arguments</span>)</span><br><span class="line">    &#125;,</span><br><span class="line">    shouldComponentUpdate: <span class="function"><span class="keyword">function</span>(<span class="params">newProps, newState</span>)</span>&#123;</span><br><span class="line">        <span class="comment">// componentWillUpdate() 가 호출되기 전에 실행되며 return false; 를 통해 업데이트를 취소할 수 있다. (render가 실행되지 않게)</span></span><br><span class="line">        <span class="keyword">this</span>._log(<span class="string">'shouldComponentUpdate'</span>, <span class="built_in">arguments</span>)</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="믹스인-사용"><a href="#믹스인-사용" class="headerlink" title="믹스인 사용"></a>믹스인 사용</h2><ul><li>믹스인은 메서드와 프로퍼티의 컬렉션을 포함하는 자바스크립트 객체</li><li>다른 객체의 프로퍼티에 포함해서 사용한다.</li></ul><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> TextAreaCounter = React.createClass(&#123;</span><br><span class="line">    name: <span class="string">'TextAreaCounter'</span>,</span><br><span class="line">    mixins: [logMixin],</span><br><span class="line">    <span class="comment">// 나머지 부분..</span></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><h2 id="자식-컴포넌트-사용"><a href="#자식-컴포넌트-사용" class="headerlink" title="자식 컴포넌트 사용"></a>자식 컴포넌트 사용</h2><ul><li>자식 컴포넌트가 부모 컴포넌트보다 먼저 마운팅 되고 업데이트 된다.</li></ul><h2 id="성능을-위한-컴포넌트-업데이트-방지"><a href="#성능을-위한-컴포넌트-업데이트-방지" class="headerlink" title="성능을 위한 컴포넌트 업데이트 방지"></a>성능을 위한 컴포넌트 업데이트 방지</h2><ul><li>순수 컴포넌트: 자신의 render() 메서드에서 this.props 와 this.state만 사용하며 추가 함수 호출을 하지 않는 컴포넌트 클래스</li><li>이러한 컴포넌트에서 shouldComponentUpdate() 를 구현하여 프로세싱 파워를 절약 할 수 있다.<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">shouldComponentUpdate(nextProps, newState)&#123;</span><br><span class="line">    <span class="keyword">return</span> nextProps.count !== <span class="keyword">this</span>.props.count;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="PureRenderMixin"><a href="#PureRenderMixin" class="headerlink" title="PureRenderMixin"></a>PureRenderMixin</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;script src=<span class="string">"react/build/react-with-addons.js"</span>&gt;&lt;/script&gt;</span><br><span class="line"><span class="keyword">var</span> Counter = React.createClass(&#123;</span><br><span class="line">    name: <span class="string">'Counter'</span>,</span><br><span class="line">    mixins: [React.addons.PureRenderMixin],</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><ul><li>this.props와 nextProps 를 비교하고 this.state와 nextState를 비교하는 작업은 항상 해야하므로…</li><li>범용으로 쓸수 있는 <strong>React.addons.PUreRenderMixin</strong> // 리액트 애드온의 확장 버전에 포함돼 있다.</li></ul><h1 id="03-Excel-멋진-테이블-컴포넌트"><a href="#03-Excel-멋진-테이블-컴포넌트" class="headerlink" title="03. Excel: 멋진 테이블 컴포넌트"></a>03. Excel: 멋진 테이블 컴포넌트</h1><h2 id="데이터-준비"><a href="#데이터-준비" class="headerlink" title="[데이터 준비]"></a>[데이터 준비]</h2><p><a href="https://github.com/stoyan/reactbook/blob/master/chapters/03.01.table-th.html" target="_blank" rel="noopener">https://github.com/stoyan/reactbook/blob/master/chapters/03.01.table-th.html</a></p><h2 id="테이블-헤더-루프"><a href="#테이블-헤더-루프" class="headerlink" title="테이블 헤더 루프"></a>테이블 헤더 루프</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> Excel = React.createClass(&#123;</span><br><span class="line">    render: <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (</span><br><span class="line">            React.DOM.table(<span class="literal">null</span>,</span><br><span class="line">                React.DOM.thead(<span class="literal">null</span>,</span><br><span class="line">                    React.DOM.tr(<span class="literal">null</span>,</span><br><span class="line">                        <span class="keyword">this</span>.props.headers.map(<span class="function"><span class="keyword">function</span>(<span class="params">title</span>)</span>&#123;</span><br><span class="line">                            <span class="keyword">return</span> React.DOM.th(<span class="literal">null</span>, title)</span><br><span class="line">                        &#125;)</span><br><span class="line">                    )</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><h1 id="04-JSX"><a href="#04-JSX" class="headerlink" title="04. JSX"></a>04. JSX</h1><h2 id="Hello-JSX"><a href="#Hello-JSX" class="headerlink" title="Hello JSX"></a>Hello JSX</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ReactDOM.render(</span><br><span class="line">    &lt;h1 id=<span class="string">'my-heading'</span>&gt;</span><br><span class="line">        &lt;span&gt;&lt;em&gt;Hell&lt;/em&gt;o&lt;<span class="regexp">/span&gt; world!</span></span><br><span class="line"><span class="regexp">    &lt;/</span>h1&gt;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ul><li>유효한 자바스크립트 구문이 아니기 때문에, 이 상태로 브라우저에서 실행할 수는 없다. 순수 자바스크립트로 변환(트랜스파일) 해야한다.</li></ul><h2 id="바벨"><a href="#바벨" class="headerlink" title="바벨"></a>바벨</h2><ul><li>오픈소스 트랜스파일러</li><li>브라우저 내(클라이언트측) 변환을 수행하려면 browser.js 파일이 필요. 바벨6버전 이후로는 제공하지 않지만</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir ~/reactbook/babel</span><br><span class="line">$ cd ~/reactbook/babel</span><br><span class="line">$ curl https://cdnjs.cloudflare.com/ajax/libs/babel-core/5.8.34/browser.js &gt; browser.js</span><br></pre></td></tr></table></figure><h2 id="클라이언트-측"><a href="#클라이언트-측" class="headerlink" title="클라이언트 측"></a>클라이언트 측</h2><ul><li>JSX 트랜스파일을 처리하는 스크립트인 browser.js 포함</li><li>바벨이 작업할 부분을 알 수 있도록 JSX를 이용하는 script 태그에 마크업 추가<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"/babel/babel.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/babel"</span>&gt;</span><span class="undefined"> ... </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="JSX-변환"><a href="#JSX-변환" class="headerlink" title="JSX 변환"></a>JSX 변환</h2><ul><li><a href="https://babel.js.io/repl/" target="_blank" rel="noopener">https://babel.js.io/repl/</a></li><li><a href="https://facebook.github.io/react/html-jsx.html" target="_blank" rel="noopener">https://facebook.github.io/react/html-jsx.html</a></li></ul><h2 id="JSX-에서-자바스크립트-사용"><a href="#JSX-에서-자바스크립트-사용" class="headerlink" title="JSX 에서 자바스크립트 사용"></a>JSX 에서 자바스크립트 사용</h2><ul><li>간단하게 중괄호 안에 자바스크립트 코드를 넣으면 된다.<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;tr key=&#123;idx&#125;&gt;</span><br><span class="line">    &#123;</span><br><span class="line">        row.map(<span class="function"><span class="keyword">function</span>(<span class="params">cell, idx</span>)</span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="xml"><span class="tag">&lt;<span class="name">td</span> <span class="attr">key</span>=<span class="string">&#123;idx&#125;</span>&gt;</span>&#123;cell&#125;<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span></span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&lt;<span class="regexp">/tr&gt;</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="JSX-의-주석"><a href="#JSX-의-주석" class="headerlink" title="JSX 의 주석"></a>JSX 의 주석</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;h1&gt;</span><br><span class="line">    &#123;<span class="comment">/* asd */</span>&#125;</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// asd</span></span><br><span class="line">    &#125;</span><br><span class="line">&lt;<span class="regexp">/h1&gt;</span></span><br></pre></td></tr></table></figure><h2 id="XSS-방지"><a href="#XSS-방지" class="headerlink" title="XSS 방지"></a>XSS 방지</h2><ul><li>HTML 엔터티를 곧바로 사용하지 않는 이유는 XSS 공격을 방지하기 위해서다.</li><li>리액트는 XSS 공격을 방지하기 위해 모든 문장열을 이스케이프한다.</li></ul><h2 id="스프레드-속성"><a href="#스프레드-속성" class="headerlink" title="스프레드 속성"></a>스프레드 속성</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> attr = &#123;</span><br><span class="line">    href: <span class="string">'http://naver.com'</span>,</span><br><span class="line">    target: <span class="string">'_blank'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> (</span><br><span class="line">    &lt;a &#123;...attr&#125;&gt;Hello&lt;<span class="regexp">/a&gt;</span></span><br><span class="line"><span class="regexp">)</span></span><br></pre></td></tr></table></figure><h2 id="부모-대-자식-스프레드-속성"><a href="#부모-대-자식-스프레드-속성" class="headerlink" title="부모 대 자식 스프레드 속성"></a>부모 대 자식 스프레드 속성</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> (</span><br><span class="line">    &lt;a &#123;...this.props&#125;&gt;&#123;<span class="keyword">this</span>.props.children&#125;&lt;<span class="regexp">/a&gt;</span></span><br><span class="line"><span class="regexp">)</span></span><br></pre></td></tr></table></figure><h2 id="JSX-에서-여러-노드-변환"><a href="#JSX-에서-여러-노드-변환" class="headerlink" title="JSX 에서 여러 노드 변환"></a>JSX 에서 여러 노드 변환</h2><ul><li>render() 함수에서는 항상 단일 노드를 반환해야 한다.<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> Example = React.createClass(&#123;</span><br><span class="line">    render: <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="keyword">this</span>.props.children.length)</span><br><span class="line">        <span class="keyword">return</span> (</span><br><span class="line">            &lt;div&gt;</span><br><span class="line">                &#123;<span class="keyword">this</span>.props.children&#125;</span><br><span class="line">            &lt;<span class="regexp">/div&gt;</span></span><br><span class="line"><span class="regexp">        )</span></span><br><span class="line"><span class="regexp">    &#125;</span></span><br><span class="line"><span class="regexp">&#125;)</span></span><br><span class="line"><span class="regexp">ReactDOM.render(</span></span><br><span class="line"><span class="regexp">    &lt;Example&gt;</span></span><br><span class="line"><span class="regexp">        &lt;span key='great'&gt;Hello&lt;/</span>span&gt;</span><br><span class="line">        &#123;<span class="string">' '</span>&#125;</span><br><span class="line">        &lt;span key=<span class="string">'word'</span>&gt;World&lt;<span class="regexp">/span&gt;</span></span><br><span class="line"><span class="regexp">        !</span></span><br><span class="line"><span class="regexp">    &lt;/</span>Example&gt;,</span><br><span class="line">    <span class="built_in">document</span>.getElementById(<span class="string">'app'</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li></ul><h2 id="JSX와-HTML의-차이점"><a href="#JSX와-HTML의-차이점" class="headerlink" title="JSX와 HTML의 차이점"></a>JSX와 HTML의 차이점</h2><ol><li>className 과 htmlFor</li><li><p>style이 객체로 취급됨</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> style = &#123;</span><br><span class="line">    fontSize: <span class="string">'2em'</span>,</span><br><span class="line">    lineHeight: <span class="string">'1.6'</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> em = <span class="xml"><span class="tag">&lt;<span class="name">em</span> <span class="attr">style</span>=<span class="string">&#123;style&#125;</span> /&gt;</span>;</span></span><br></pre></td></tr></table></figure></li><li><p>닫는 태그</p><ul><li>HTMl 태그 중에는 닫을 필요가 없는 것이 있지만, JSX(XML) 에서는 항상 닫아야 한다.</li></ul></li><li>캐멀표기법으로 속성표기<ul><li>이 규칙의 예외는 data-와 aria- 접두사가 붙은 속성이며, 이들 속성은 HTML과 동일하게 사용된다.</li></ul></li></ol><h2 id="JSX와-폼"><a href="#JSX와-폼" class="headerlink" title="JSX와 폼"></a>JSX와 폼</h2><ol><li>ON-CHANGE 핸들러<ul><li>리액트에서는 ON-CHANGE 속성을 이용해 변경 이벤트를 구독할 수 있다.</li><li>라디오 버튼이나 체크박스의 checked 값이나 selected 값을 이용하는 것보다 훨씬 일관성 있다.</li></ul></li><li>value 와 defaultValue<ul><li>input 의 내용을 변경하면 value는 값이 바뀌지만, defaultValue는 유지된다.</li></ul></li><li>textare 태그와 value</li><li>select 태그와 value<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">select</span> <span class="attr">defaultValue</span>=<span class="string">&#123;&#123;</span>"<span class="attr">stay</span>", "<span class="attr">move</span>"&#125;&#125; <span class="attr">multiple</span>=<span class="string">&#123;true&#125;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"stay"</span>&gt;</span>Stay<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">option</span> <span class="attr">value</span>=<span class="string">"move"</span>&gt;</span>Move<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="JSX를-이용한-Excel-컴포넌트-수정"><a href="#JSX를-이용한-Excel-컴포넌트-수정" class="headerlink" title="JSX를 이용한 Excel 컴포넌트 수정"></a>JSX를 이용한 Excel 컴포넌트 수정</h2><p><a href="https://github.com/stoyan/reactbook/" target="_blank" rel="noopener">https://github.com/stoyan/reactbook/</a></p><h1 id="05-앱-개발을-위한-설정"><a href="#05-앱-개발을-위한-설정" class="headerlink" title="05. 앱 개발을 위한 설정"></a>05. 앱 개발을 위한 설정</h1><h2 id="기본-파트-앱"><a href="#기본-파트-앱" class="headerlink" title="기본 파트 앱"></a>기본 파트 앱</h2><ol><li>파일과 폴더<ul><li>/css, /js, /images 폴더와 모두 연결할 index.html 파일 필요</li><li>스크립트와 JSX 구분을 위한 /js/sourece/ 폴더와 브라우저 친화적인 스크립트를 위한 /js/build/  폴더가 필요</li><li>빌드를 수행할 명령줄 스크립트를 호스트하는 /scripts 카테고리</li></ul></li><li><p>index.html</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>App<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 모든 CSS를 포함하는 단일 bundle.css 파일 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span> <span class="attr">type</span>=<span class="string">"text/css"</span> <span class="attr">href</span>=<span class="string">"bundle.css"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 앱이 시작할 위치 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">'app'</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 모든 자바스크립트를 포함하는 단일 bundle.js 파일 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"bundle.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>CSS</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">html</span> &#123;</span><br><span class="line">  <span class="attribute">background</span>: white;</span><br><span class="line">  <span class="attribute">font</span>: <span class="number">16px</span> Arial;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="모듈"><a href="#모듈" class="headerlink" title="모듈"></a>모듈</h2><ul><li>널리 채용되고 있는 개념으로 CommonJS 가 있다.</li><li>작업이 완료되면 하나 이상의 심볼을 내보내는 파일에 코드를 포함한다.</li><li>모듈 하나가 항목 하나(리액트 컴포넌트 하나)를 내보내도록 하는 것이 관행이다.</li></ul><h2 id="ECMAScript-모듈"><a href="#ECMAScript-모듈" class="headerlink" title="ECMAScript 모듈"></a>ECMAScript 모듈</h2><ul><li>ECMAScript 사양은 이 개념을 발전시켜, require() 와 module.exports 에 의존하지 않는 새로운 구문을 제안한다.<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// source/app.js</span></span><br><span class="line"><span class="meta">'use strict'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> React <span class="keyword">from</span> <span class="string">'react'</span>;</span><br><span class="line"><span class="keyword">import</span> ReactDOM <span class="keyword">from</span> <span class="string">'react-dom'</span>;</span><br><span class="line"><span class="keyword">import</span> Logo <span class="keyword">from</span> <span class="string">'./components/Logo'</span>;</span><br><span class="line"></span><br><span class="line">ReactDOM.render(</span><br><span class="line">    &lt;h1&gt;</span><br><span class="line">        &lt;Logo /&gt; Welcome to the app!</span><br><span class="line">    &lt;<span class="regexp">/h1&gt;,</span></span><br><span class="line"><span class="regexp">    document.getElementById('app')</span></span><br><span class="line"><span class="regexp">)</span></span><br></pre></td></tr></table></figure></li></ul><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// source/components/Logo.js</span></span><br><span class="line"><span class="keyword">import</span> React <span class="keyword">from</span> <span class="string">'react'</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Logo</span> <span class="keyword">extends</span> <span class="title">React</span>.<span class="title">Component</span></span>&#123;</span><br><span class="line">    render()&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="xml"><span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">"Logo"</span> /&gt;</span>;</span></span><br><span class="line"><span class="xml">    &#125;</span></span><br><span class="line"><span class="xml">&#125;</span></span><br><span class="line"><span class="xml">export default Logo</span></span><br></pre></td></tr></table></figure><h2 id="필수-구성-요소-설치"><a href="#필수-구성-요소-설치" class="headerlink" title="필수 구성 요소 설치"></a>필수 구성 요소 설치</h2><ul><li>index.html 을 로드하고 작동하는지 확인하려면<ul><li>bundle.css 를 만든다.</li><li>브라우저가 코드를 이해할 수 있게 만든다 (트랜스파일링을 위해 바벨이 필요)</li><li>vundle.js 를 만든다. Browserify를 이용<ul><li>모든 종속성을 확인후 포함한다. (리액트, Logo.js 등)</li><li>require() 호출이 작동하도록 CommonJS 구현을 포함한다.</li><li>바벨은 모든 import문을 require() 함수 호출로 변환한다.</li></ul></li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install --global browserify babel-cli</span><br></pre></td></tr></table></figure><h2 id="리액트-및-기타-항목"><a href="#리액트-및-기타-항목" class="headerlink" title="리액트 및 기타 항목"></a>리액트 및 기타 항목</h2><ul><li>패키지를 로컬로 설치<ul><li>react</li><li>react-dom</li><li>babel-preset-react // 바벨에 JSX 지원 및 다른 리액트 기능을 제공</li><li>babel-preset-es2015 // 최신 자바스크립트 기능에 대한 지원을 제공<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install --save-dev react react-dom babel-preset-react babel-preset-es2015</span><br></pre></td></tr></table></figure></li></ul></li></ul><h2 id="빌드-시작"><a href="#빌드-시작" class="headerlink" title="빌드 시작"></a>빌드 시작</h2><p>빌드 프로세스는 <strong>CSS 연결, JS 트랜스파일, JS패키징</strong> 의 세 단계로 수행</p><ul><li><p>자바스크립트 트랜스파일</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## js/source 의 모든 파일을 리액트와 ES2015 기능을 이용해 트랜스파일한 후 결과는 js/build 로 복사</span></span><br><span class="line">$ babel --presets react,es2015 js/<span class="built_in">source</span> -d js/build</span><br></pre></td></tr></table></figure></li><li><p>자바스크립트 패키징</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## app.js 부터 시작해 모든 의존성을 찾고 결과를 bundle.js 로 기록하도록 명령</span></span><br><span class="line">$ browserify js/build/app.js -o bundle.js</span><br></pre></td></tr></table></figure></li><li><p>CSS 패키징</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat css/*/* css/*.css | sed <span class="string">'s/..\/..\/images/images/g'</span> &gt; bundle.css</span><br></pre></td></tr></table></figure></li></ul><h2 id="윈도우-버전"><a href="#윈도우-버전" class="headerlink" title="윈도우 버전"></a>윈도우 버전</h2><p>디렉터리 분리 문자가 다르다는 점을 주의<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ babel --presets react,es2015 js\<span class="built_in">source</span> -d js\build</span><br><span class="line">$ browserify js\build\app.js -o bundle.js</span><br><span class="line">$ <span class="built_in">type</span> css\components\* css\* &gt; bundle.css</span><br></pre></td></tr></table></figure></p><h2 id="개발-중-빌드하기"><a href="#개발-중-빌드하기" class="headerlink" title="개발 중 빌드하기"></a>개발 중 빌드하기</h2><p>디렉터리에 대한 변경 사항을 확인하고 스크립트를 자동 빌드</p><ul><li>scripts/build.sh<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># js 트랜스폼</span></span><br><span class="line">babel --presets react,es2015 js\<span class="built_in">source</span> -d js\build</span><br><span class="line"><span class="comment"># js 패키징</span></span><br><span class="line">browserify js\build\app.js -o bundle.js</span><br><span class="line"><span class="comment"># css 패키징</span></span><br><span class="line">cat css/*/* css/*.css | sed <span class="string">'s/..\/..\/images/images/g'</span> &gt; bundle.css</span><br><span class="line"><span class="comment"># 완료</span></span><br><span class="line">date; <span class="built_in">echo</span>;</span><br></pre></td></tr></table></figure></li></ul><h2 id="배포"><a href="#배포" class="headerlink" title="배포"></a>배포</h2><p>JS 축소기인 uglify-js 와 CSS 축소기 cssshrink 를 이용<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 마지막 버전을 정리</span></span><br><span class="line">rm -rf __deployme</span><br><span class="line">mkdir __deployme</span><br><span class="line"></span><br><span class="line"><span class="comment"># 빌드</span></span><br><span class="line">sh scripts/build.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 축소</span></span><br><span class="line">uglifyjs bundle.js -o __deployeme/bundle.js</span><br><span class="line">cssshrink bundle.css &gt; __deployme/bundle.css</span><br><span class="line"></span><br><span class="line"><span class="comment"># HTML 과 이미지 복사</span></span><br><span class="line">cp index.html __deployme/index.html</span><br><span class="line">cp -r images/ __deployme/images/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 완료</span></span><br><span class="line">date; <span class="built_in">echo</span>;</span><br></pre></td></tr></table></figure></p><h1 id="07-린트-플로우-테스트-반복"><a href="#07-린트-플로우-테스트-반복" class="headerlink" title="07. 린트, 플로우, 테스트 반복"></a>07. 린트, 플로우, 테스트 반복</h1><h2 id="package-json"><a href="#package-json" class="headerlink" title="package.json"></a>package.json</h2><h3 id="바벨-스크립트-구성"><a href="#바벨-스크립트-구성" class="headerlink" title="바벨, 스크립트 구성"></a>바벨, 스크립트 구성</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"name"</span>: <span class="string">"whinepad"</span>,</span><br><span class="line">  <span class="string">"version"</span>: <span class="string">"2.0.0"</span>,</span><br><span class="line">  <span class="string">"babel"</span> : &#123;</span><br><span class="line">    <span class="string">"presets"</span>:[</span><br><span class="line">      <span class="string">"es2015"</span>,</span><br><span class="line">      <span class="string">"react"</span></span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"scripts"</span>:&#123;</span><br><span class="line">    <span class="string">"build"</span>: <span class="string">"sh scripts/build.sh"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="ESLint"><a href="#ESLint" class="headerlink" title="ESLint"></a>ESLint</h2><ul><li>잠재적 위험이 될 수 있는 패턴을 검색</li></ul><h3 id="설정"><a href="#설정" class="headerlink" title="설정"></a>설정</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ npm i -g eslint eslint-plugin-react eslint-plugin-babel</span><br><span class="line"></span><br><span class="line">//package.json</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"eslintConfig"</span>: &#123;</span><br><span class="line">    <span class="string">"parser"</span>: <span class="string">"babel-eslint"</span>,</span><br><span class="line">    <span class="string">"plugin"</span>: [</span><br><span class="line">      <span class="string">"babel"</span>,</span><br><span class="line">      <span class="string">"react"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="string">"env"</span>: &#123;</span><br><span class="line">      <span class="string">"browser"</span>: <span class="literal">true</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"rules"</span>: &#123;</span><br><span class="line">      <span class="string">"react/jsx-uses-react"</span>: 1,</span><br><span class="line">      <span class="string">"comma-dangle"</span>: [2, <span class="string">"always-multiline"</span>]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="실행"><a href="#실행" class="headerlink" title="실행"></a>실행</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ eslint js/<span class="built_in">source</span></span><br></pre></td></tr></table></figure><h2 id="플로우"><a href="#플로우" class="headerlink" title="플로우"></a>플로우</h2><ul><li>자바스크립트용 정적 형식 검사기</li><li>/<em> @flow </em>/<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ npm install -g flow-bin</span><br><span class="line">$ <span class="built_in">cd</span> ~/reactbook/whinepad2</span><br><span class="line"></span><br><span class="line"><span class="comment">## .flowconfig</span></span><br><span class="line">[ignore]</span><br><span class="line">.*/react/node_modules/.*</span><br><span class="line"></span><br><span class="line">[include]</span><br><span class="line">node_modules/react</span><br><span class="line">node_modules/react-dom</span><br><span class="line">node_modules/classnames</span><br><span class="line"></span><br><span class="line">[libs]</span><br><span class="line"></span><br><span class="line">[options]</span><br></pre></td></tr></table></figure></li></ul><h2 id="실행-1"><a href="#실행-1" class="headerlink" title="실행"></a>실행</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ flow</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/startReactProgramming/cover.jpg&quot; alt=&quot;/images/startReactProgramming/cover.jpg&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;01-Hello-World&quot;&gt;&lt;a href=&quot;#0
      
    
    </summary>
    
      <category term="자료정리" scheme="https://ddulhddul.github.io/categories/%EC%9E%90%EB%A3%8C%EC%A0%95%EB%A6%AC/"/>
    
      <category term="react" scheme="https://ddulhddul.github.io/categories/%EC%9E%90%EB%A3%8C%EC%A0%95%EB%A6%AC/react/"/>
    
    
      <category term="javascript" scheme="https://ddulhddul.github.io/tags/javascript/"/>
    
      <category term="react" scheme="https://ddulhddul.github.io/tags/react/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://ddulhddul.github.io/2017/12/28/hello-world/"/>
    <id>https://ddulhddul.github.io/2017/12/28/hello-world/</id>
    <published>2017-12-27T15:29:35.370Z</published>
    <updated>2017-12-27T15:29:35.372Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
