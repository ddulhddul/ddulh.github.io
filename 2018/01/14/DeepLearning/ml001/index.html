<!DOCTYPE html><html prefix="og: http://ogp.me/ns#"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title>Chapter2. 퍼셉트론 · ddulh's</title><meta name="description" content="잡념"><meta name="og:title" content="Chapter2. 퍼셉트론"><meta name="og:type" content="website"><meta name="og:url" content="https://ddulhddul.github.io/2018/01/14/DeepLearning/ml001/"><meta name="og:image" content="http://image.toast.com/aaaaahq/hola_cover.JPG"><meta name="og:description" content="잡념"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/css/chiangmai.css"><meta name="steem:author" content="@stunstunstun"><link rel="search" type="application/opensearchdescription+xml" href="https://ddulhddul.github.io/atom.xml" title="ddulh's"></head><body class="post"><div id="fb-root"></div><div class="wrap"><header><nav class="navi-post"><a class="navi-post-back" href="javascript:history.back()"><i class="fa fa-arrow-left" aria-hidden="true"></i></a><a class="navi-post-home" href="/"><i class="fa fa-home" aria-hidden="true"></i></a></nav></header><main class="post"><div class="post"><article class="post-block"><h1 class="post-title">Chapter2. 퍼셉트론</h1><div class="post-info"><div class="post-info-details"><div class="post-categories"><a href="/categories/DeepLearning" target="_self"><span>DEEPLEARNING</span></a></div><div class="post-date">Jan 14, 2018</div></div></div><div class="post-share"><div class="fb-like" data-href="https://ddulhddul.github.io/2018/01/14/DeepLearning/ml001/" data-layout="button_count" data-action="like" data-size="small" data-show-faces="true" data-share="false">                 </div><div class="fb-share-button" data-href="https://ddulhddul.github.io/2018/01/14/DeepLearning/ml001/" data-layout="button" data-size="small" data-mobile-iframe="true"></div></div><div class="post-content"><p><img src="/images/deeplearning/cover.jpg" alt="밑바닥부터 시작하는 딥러닝"></p>
<h2 id="퍼셉트론"><a href="#퍼셉트론" class="headerlink" title="퍼셉트론 ?"></a>퍼셉트론 ?</h2><ul>
<li>프랑크 로젠블라트가 1957 고안한 알고리즘.</li>
<li>신경망(딥러닝) 의 기원이 되는 알고리즘</li>
</ul>
<h1 id="2-1-퍼셉트론이란"><a href="#2-1-퍼셉트론이란" class="headerlink" title="2.1 퍼셉트론이란 ?"></a>2.1 퍼셉트론이란 ?</h1><ul>
<li>(흐름이 있는) 다수의 신호를 입력으로 받아 하나의 신호를 출력</li>
<li><strong>1이나 0</strong> 두가지 값을 가짐.</li>
</ul>
<p><img src="/images/deeplearning/perceptron.PNG" alt="퍼셉트론"></p>
<ul>
<li>가중치와 임계값<ul>
<li>가중치는 각 신호가 결과에 주는 영향력을 조절</li>
</ul>
</li>
</ul>
<h1 id="2-2-단순한-논리-회로"><a href="#2-2-단순한-논리-회로" class="headerlink" title="2.2 단순한 논리 회로"></a>2.2 단순한 논리 회로</h1><h2 id="2-2-1-AND-게이트"><a href="#2-2-1-AND-게이트" class="headerlink" title="2.2.1 AND 게이트"></a>2.2.1 AND 게이트</h2><ul>
<li>AND 게이트의 진리표</li>
</ul>
<table>
<thead>
<tr>
<th>x1</th>
<th>x2</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
<h2 id="2-2-2-NAND-게이트와-OR-게이트"><a href="#2-2-2-NAND-게이트와-OR-게이트" class="headerlink" title="2.2.2 NAND 게이트와 OR 게이트"></a>2.2.2 NAND 게이트와 OR 게이트</h2><p>NAND = NOT AND</p>
<ul>
<li>NAND 게이트의 진리표</li>
</ul>
<table>
<thead>
<tr>
<th>x1</th>
<th>x2</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<ul>
<li>OR 게이트의 진리표</li>
</ul>
<table>
<thead>
<tr>
<th>x1</th>
<th>x2</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
<h1 id="2-3-퍼셉트론-구현하기"><a href="#2-3-퍼셉트론-구현하기" class="headerlink" title="2.3 퍼셉트론 구현하기"></a>2.3 퍼셉트론 구현하기</h1><h2 id="2-3-1-간단한-구현부터"><a href="#2-3-1-간단한-구현부터" class="headerlink" title="2.3.1 간단한 구현부터"></a>2.3.1 간단한 구현부터</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">AND</span><span class="params">(x1,x2)</span>:</span></span><br><span class="line">  w1, w2, theta = <span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.7</span></span><br><span class="line">  tmp = x1*w1 + x2*w2</span><br><span class="line">  <span class="keyword">if</span> tmp &lt;= theta:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">elif</span> tmp &gt; theta:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h2 id="2-3-2-가중치와-편향-도입"><a href="#2-3-2-가중치와-편향-도입" class="headerlink" title="2.3.2 가중치와 편향 도입"></a>2.3.2 가중치와 편향 도입</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x = np.array([<span class="number">0</span>,<span class="number">1</span>])     <span class="comment"># 입력</span></span><br><span class="line">w = np.array([<span class="number">0.5</span>,<span class="number">0.5</span>]) <span class="comment"># 가중치</span></span><br><span class="line">b = <span class="number">-0.7</span>                <span class="comment"># 편향</span></span><br><span class="line">np.sum(w*x) + b         <span class="comment"># AND 게이트</span></span><br></pre></td></tr></table></figure>
<h2 id="2-3-3-가중와-편향-구현하기"><a href="#2-3-3-가중와-편향-구현하기" class="headerlink" title="2.3.3 가중와 편향 구현하기"></a>2.3.3 가중와 편향 구현하기</h2><ul>
<li>가중치와 편향을 도입한 AND 게이트</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">AND</span><span class="params">(x1,x2)</span>:</span></span><br><span class="line">  x = np.array([x2,x2])</span><br><span class="line">  w = np.array([<span class="number">0.5</span>,<span class="number">0.5</span>])</span><br><span class="line">  b = <span class="number">-0.7</span></span><br><span class="line">  tmp = np.sum(x*w) + b</span><br><span class="line">  <span class="keyword">if</span> tmp &lt;= <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>
<ul>
<li>가중치 w1, w2 는 <strong>각 입력 신호가 결과에 주는 영향력</strong>을 조절</li>
<li><p>편향은 <strong>뉴런이 얼마나 쉽게 활성화 하느냐</strong>를 조정</p>
</li>
<li><p>가중치와 편향을 도입한 NAND 게이트</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">NAND</span><span class="params">(x1,x2)</span>:</span></span><br><span class="line">  x = np.array([x2,x2])</span><br><span class="line">  w = np.array([<span class="number">-0.5</span>,<span class="number">-0.5</span>]) <span class="comment"># AND 와는 가중치(w,b) 만 다름</span></span><br><span class="line">  b = <span class="number">0.7</span></span><br><span class="line">  tmp = np.sum(x*w) + b</span><br><span class="line">  <span class="keyword">if</span> tmp &lt;= <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>
<ul>
<li>가중치와 편향을 도입한 OR 게이트</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">OR</span><span class="params">(x1,x2)</span>:</span></span><br><span class="line">  x = np.array([x2,x2])</span><br><span class="line">  w = np.array([<span class="number">0.5</span>,<span class="number">0.5</span>]) <span class="comment"># AND 와는 가중치(w,b) 만 다름</span></span><br><span class="line">  b = <span class="number">-0.2</span></span><br><span class="line">  tmp = np.sum(x*w) + b</span><br><span class="line">  <span class="keyword">if</span> tmp &lt;= <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h1 id="2-4-퍼셉트론의-한계"><a href="#2-4-퍼셉트론의-한계" class="headerlink" title="2.4 퍼셉트론의 한계"></a>2.4 퍼셉트론의 한계</h1><h2 id="2-4-1-도전-XOR-게이트"><a href="#2-4-1-도전-XOR-게이트" class="headerlink" title="2.4.1 도전! XOR 게이트"></a>2.4.1 도전! XOR 게이트</h2><ul>
<li>XOR 게이트의 진리표</li>
</ul>
<table>
<thead>
<tr>
<th>x1</th>
<th>x2</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<blockquote>
<p>XOR 게이트를 직선 하나로 표현하는 방법은 존재하지 않는다.</p>
</blockquote>
<h2 id="2-4-2-선형과-비선형"><a href="#2-4-2-선형과-비선형" class="headerlink" title="2.4.2 선형과 비선형"></a>2.4.2 선형과 비선형</h2><p>직선이라는 제약을 없앤다면 XOR 를 표현할 수 있다.</p>
<h1 id="2-5-다층-퍼셉트론이-충돌한다면"><a href="#2-5-다층-퍼셉트론이-충돌한다면" class="headerlink" title="2.5 다층 퍼셉트론이 충돌한다면"></a>2.5 다층 퍼셉트론이 충돌한다면</h1><p><strong>다층 퍼셉트론</strong>을 이용하면 XOR 를 표현할 수 있다. (층을 쌓는다.)</p>
<h2 id="2-5-1-기존-게이트-조합하기"><a href="#2-5-1-기존-게이트-조합하기" class="headerlink" title="2.5.1 기존 게이트 조합하기"></a>2.5.1 기존 게이트 조합하기</h2><p><img src="/images/deeplearning/xor.PNG" alt="XOR 표현"></p>
<ul>
<li>NAND 의 출력을 s1, OR 의 출력을 s2 로 진리표를 만들면</li>
</ul>
<table>
<thead>
<tr>
<th>x1</th>
<th>x2</th>
<th>s1</th>
<th>s2</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<h2 id="2-5-2-XOR-게이트-구현하기"><a href="#2-5-2-XOR-게이트-구현하기" class="headerlink" title="2.5.2 XOR 게이트 구현하기"></a>2.5.2 XOR 게이트 구현하기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">XOR</span><span class="params">(x1,x2)</span>:</span></span><br><span class="line">  s1 = NAND(x1,x2)</span><br><span class="line">  s2 = OR(x1,x2)</span><br><span class="line">  y = AND(s1,s2)</span><br><span class="line">  <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>
<ul>
<li>XOR 는 다층 구조의 네트워크</li>
<li>AND,NAND,OR 단층 퍼셉트론 / XOR 는 2층 퍼셉트론</li>
</ul>
<h1 id="2-6-NAND-에서-컴퓨터까지"><a href="#2-6-NAND-에서-컴퓨터까지" class="headerlink" title="2.6 NAND 에서 컴퓨터까지"></a>2.6 NAND 에서 컴퓨터까지</h1><ul>
<li>퍼셉트론을 이용하면 컴퓨터 마저 표현 가능</li>
<li>이론상 2층 퍼셉트론이면 컴퓨터를 만들 수 있다.<ul>
<li>비선형인 시그모이드 함수를 활성화 함수로 이용하면 가능(3장 참고)<blockquote>
<p>하지만 2층 퍼셉트론 구조에서 가중치를 적절하게 설정하여 컴퓨터를 만드는 것보다, 필요한 부품(모듈) 을 단계적으로 만드는 쪽이 자연스러운 방법임.</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<hr>
<h1 id="참고자료"><a href="#참고자료" class="headerlink" title="참고자료"></a>참고자료</h1><ul>
<li>딥러닝의 역사<br><a href="http://solarisailab.com/archives/1206" target="_blank" rel="noopener">http://solarisailab.com/archives/1206</a></li>
</ul>
<div class="video-container"><iframe src="//www.youtube.com/embed/FwFduRA_L6Q" frameborder="0" allowfullscreen></iframe></div>
<ul>
<li><p>딥러닝 자습<br><a href="https://www.slideshare.net/yongho/ss-79607172" target="_blank" rel="noopener">https://www.slideshare.net/yongho/ss-79607172</a></p>
</li>
<li><p>딥러닝의 30가지 적용 사례<br><a href="https://brunch.co.kr/@itschloe1/23" target="_blank" rel="noopener">https://brunch.co.kr/@itschloe1/23</a></p>
</li>
<li><p>문과생도 이해하는 딥러닝<br><a href="http://sacko.tistory.com/10" target="_blank" rel="noopener">http://sacko.tistory.com/10</a></p>
</li>
<li><p>퍼셉트론 이용한 가위바위보 예제<br><a href="http://hanybin.blogspot.kr/2017/10/ai.html" target="_blank" rel="noopener">http://hanybin.blogspot.kr/2017/10/ai.html</a></p>
</li>
</ul>
<div class="video-container"><iframe src="//www.youtube.com/embed/Wsq8nXPbncM" frameborder="0" allowfullscreen></iframe></div>
<hr>
<figure class="highlight java"><figcaption><span>SingleLayerPerceptron.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SingleLayerPerceptron</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> numberOfNeurons;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">float</span>[] inputValues;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">float</span> learningRate;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">float</span> targetValue;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">boolean</span> useSigmoid = <span class="keyword">false</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">float</span>[] weights;</span><br><span class="line">    <span class="keyword">float</span> outputValue;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span>[] rawValues;</span><br><span class="line">    <span class="keyword">float</span> sumOfrawValues;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SingleLayerPerceptron</span><span class="params">(<span class="keyword">int</span> numberOfNeurons, <span class="keyword">float</span> learningRate, <span class="keyword">boolean</span> useSigmoid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.numberOfNeurons = numberOfNeurons;</span><br><span class="line">        <span class="keyword">this</span>.learningRate = learningRate;</span><br><span class="line">        <span class="keyword">this</span>.useSigmoid = useSigmoid;</span><br><span class="line">        inputValues = <span class="keyword">new</span> <span class="keyword">float</span>[numberOfNeurons];</span><br><span class="line">        weights = <span class="keyword">new</span> <span class="keyword">float</span>[numberOfNeurons];</span><br><span class="line">        rawValues = <span class="keyword">new</span> <span class="keyword">float</span>[numberOfNeurons];</span><br><span class="line">        sumOfrawValues = <span class="number">0f</span>;</span><br><span class="line">        outputValue = <span class="number">0f</span>;</span><br><span class="line"></span><br><span class="line">        Random r = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="comment">//initializing weights</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numberOfNeurons; i++)</span><br><span class="line">        &#123;</span><br><span class="line"><span class="comment">//            weights[i] = Random.Range(-0.5f, 0.5f);</span></span><br><span class="line">        	weights[i] = (<span class="keyword">float</span>) (r.nextFloat()-<span class="number">0.5</span>);</span><br><span class="line">            System.out.println(<span class="string">"step: "</span> + i + <span class="string">", weight value: "</span> + weights[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">float</span> <span class="title">ProcessInputsToRawValue</span><span class="params">(<span class="keyword">float</span>[] inputValues)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        sumOfrawValues = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numberOfNeurons; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">this</span>.inputValues[i] = inputValues[i]; <span class="comment">//deep copy inputValues for futher processing</span></span><br><span class="line">            rawValues[i] = inputValues[i] * weights[i];</span><br><span class="line">            sumOfrawValues += rawValues[i];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sumOfrawValues;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">float</span> <span class="title">ActivationProcess</span><span class="params">(<span class="keyword">float</span> sumOfrawValues)</span> <span class="comment">//uses sigmoid function</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">float</span> activationValue = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (useSigmoid == <span class="keyword">true</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            activationValue = (<span class="keyword">float</span>) (<span class="number">1</span> / (<span class="number">1</span> + Math.exp(-sumOfrawValues)));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (sumOfrawValues &gt;= <span class="number">0.5f</span>)</span><br><span class="line">            &#123;                </span><br><span class="line">                activationValue = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (sumOfrawValues &lt; <span class="number">0.5f</span>)</span><br><span class="line">            &#123;             </span><br><span class="line">                activationValue = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//Debug.Log("ActivationValue is : " + activationValue);</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> activationValue;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">LearningProcess</span><span class="params">(<span class="keyword">float</span> sumOfrawValues, <span class="keyword">float</span> targetValue)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">float</span> difference = targetValue - ActivationProcess(sumOfrawValues);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numberOfNeurons; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            weights[i] = weights[i] + (inputValues[i] * learningRate * difference);</span><br><span class="line">            <span class="comment">//Debug.Log("step: " + i + ", modified weight value: " + weights[i]);</span></span><br><span class="line">        &#125;        </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">float</span> <span class="title">Execute</span><span class="params">(<span class="keyword">float</span>[] inputValues, <span class="keyword">float</span> targetValue)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        sumOfrawValues = ProcessInputsToRawValue(inputValues);</span><br><span class="line">        outputValue = ActivationProcess(sumOfrawValues);        </span><br><span class="line">        LearningProcess(sumOfrawValues, targetValue);                </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> outputValue;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">float</span> <span class="title">Test</span><span class="params">(<span class="keyword">float</span>[] inputValues)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">float</span> outputValue = ActivationProcess(ProcessInputsToRawValue(inputValues));</span><br><span class="line">        <span class="keyword">return</span> outputValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><figcaption><span>Main.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		<span class="comment">// int numberOfNeurons, float learningRate, boolean useSigmoid</span></span><br><span class="line">		SingleLayerPerceptron s = <span class="keyword">new</span> SingleLayerPerceptron(<span class="number">3</span>, (<span class="keyword">float</span>) <span class="number">0.1</span>, <span class="keyword">true</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">50</span>; i++) &#123;</span><br><span class="line">			</span><br><span class="line">			<span class="keyword">int</span> targetValue = <span class="number">1</span>;</span><br><span class="line">			<span class="keyword">float</span>[] arr = floatArray(i);</span><br><span class="line">			<span class="keyword">float</span> result = s.Execute(arr, targetValue);</span><br><span class="line">			System.out.printf(<span class="string">"i= %s, arr=%s %s %s, result = %s \n"</span>, i,arr[<span class="number">0</span>],arr[<span class="number">1</span>],arr[<span class="number">2</span>],result);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">float</span>[] floatArray(<span class="keyword">int</span> i) &#123;</span><br><span class="line">		Random r = <span class="keyword">new</span> Random();</span><br><span class="line">		i = r.nextInt(<span class="number">3</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">if</span>(i%<span class="number">3</span> == <span class="number">0</span>)&#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">float</span>[]&#123;<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>&#125;;</span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span>(i%<span class="number">3</span> == <span class="number">1</span>)&#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">float</span>[]&#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>&#125;;</span><br><span class="line">		&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">float</span>[]&#123;<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>&#125;;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
</div></article></div></main><footer><div class="paginator"><a class="prev" href="/2018/01/09/DeepLearning/machineLearning/"><i class="fa fa-arrow-left" aria-hidden="true"></i></a><a class="next" href="/2018/01/21/DeepLearning/ml002/"><i class="fa fa-arrow-right" aria-hidden="true"></i></a></div><div class="copyright"><p>© 2012 - 2021 <a href="https://github.com/stunstunstun" target="_blank">Minhyeok Jung</a>. Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/stunstunstun/hexo-theme-chiangmai" target="_blank">hexo-theme-chiangmai</a>.</p></div></footer></div></body></html>